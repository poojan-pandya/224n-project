{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f63fabf442c4054b224f0e34a021ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b67cf55f07d64504accfd73ecef4315a",
              "IPY_MODEL_829644dfee4545519b2c21a7433732f1",
              "IPY_MODEL_5f24939d39e64f5d9ebbdadfe77af760"
            ],
            "layout": "IPY_MODEL_40f40585ea834df9bbe1534d7b504e6a"
          }
        },
        "b67cf55f07d64504accfd73ecef4315a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e2dd4203cce4171b770dfceb8d22c19",
            "placeholder": "​",
            "style": "IPY_MODEL_d7f3774872024c398603ff39efb87eba",
            "value": "Map: 100%"
          }
        },
        "829644dfee4545519b2c21a7433732f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_569770a3b04540658f9b33edb2b296fa",
            "max": 81614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e60356f7893e4c0598212602f18ded2e",
            "value": 81614
          }
        },
        "5f24939d39e64f5d9ebbdadfe77af760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2852c5bd1b24042985a8ef8b0b193ad",
            "placeholder": "​",
            "style": "IPY_MODEL_553a5ae266f64e6ba433bde5a82f8631",
            "value": " 81614/81614 [03:28&lt;00:00, 416.52 examples/s]"
          }
        },
        "40f40585ea834df9bbe1534d7b504e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3e2dd4203cce4171b770dfceb8d22c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7f3774872024c398603ff39efb87eba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "569770a3b04540658f9b33edb2b296fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60356f7893e4c0598212602f18ded2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2852c5bd1b24042985a8ef8b0b193ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553a5ae266f64e6ba433bde5a82f8631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae1e00a36d394b66900abe72ebcdeaa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_172cac53159146d0ac64ac329ad7ca9a",
              "IPY_MODEL_11e2515b29d54661b3f60401d93e42ec",
              "IPY_MODEL_f8b087df5e5a44b28a7c6bc6ed609604"
            ],
            "layout": "IPY_MODEL_baf5c1da5a894647be22fcda2072cecd"
          }
        },
        "172cac53159146d0ac64ac329ad7ca9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a573705d98d241f6960796e8689c7af2",
            "placeholder": "​",
            "style": "IPY_MODEL_a20256094c40467fb95223b8702422fe",
            "value": "Map: 100%"
          }
        },
        "11e2515b29d54661b3f60401d93e42ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17987f28150b47799b83ee7f1338a45f",
            "max": 998,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d85bb6a74dda474683b3382e0d51549d",
            "value": 998
          }
        },
        "f8b087df5e5a44b28a7c6bc6ed609604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554ba96e2ee24c5e956f56c36c2b9c38",
            "placeholder": "​",
            "style": "IPY_MODEL_5d7d9d988c4447b29dfc497ba7d8d6e1",
            "value": " 998/998 [00:02&lt;00:00, 442.53 examples/s]"
          }
        },
        "baf5c1da5a894647be22fcda2072cecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a573705d98d241f6960796e8689c7af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a20256094c40467fb95223b8702422fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17987f28150b47799b83ee7f1338a45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85bb6a74dda474683b3382e0d51549d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "554ba96e2ee24c5e956f56c36c2b9c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7d9d988c4447b29dfc497ba7d8d6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### GAN Attempt!"
      ],
      "metadata": {
        "id": "l2vionRRzF_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab pip installs\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "JADRaL5b276C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AWS pip installs\n",
        "!pip install torch\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "OF75rc8BBssA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Setup\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ESRs9D8S2gd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/CS\\ 224N\\ Project\n",
        "%ls # verify that you are in the right directory"
      ],
      "metadata": {
        "id": "txGRbtkd4IWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define the generator (use the pre-trained BART implementation)\n",
        "\"\"\"\n",
        "\n",
        "# bart-base checkpoint pre-trained on our dataset\n",
        "# (can also try generically pre-trained bart base)\n",
        "model_dir = 'bart-base-checkpoint-204000'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
        "print(netG)"
      ],
      "metadata": {
        "id": "0RgiUTBezH2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c177ee-e699-4ef8-f3a5-535d933d87a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartForConditionalGeneration(\n",
            "  (model): BartModel(\n",
            "    (shared): Embedding(50265, 768, padding_idx=1)\n",
            "    (encoder): BartEncoder(\n",
            "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): BartDecoder(\n",
            "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define convolutional discriminator\n",
        "\"\"\"\n",
        "\n",
        "nc = 1\n",
        "ndf = 64\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            #Reshaping input\n",
        "            nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 320 --> 1, 1, 64, 64\n",
        "            # input is (nc) x 64 x 64 | our input is 1 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        #print(len(input.shape))\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "XBPd1v0Q34Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngpu = 1\n",
        "netD = Discriminator(ngpu).to(device)"
      ],
      "metadata": {
        "id": "F4fElnOc_aAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loss functions and optimizers\n",
        "\"\"\"\n",
        "# Size of generator input\n",
        "nz = 512\n",
        "# Optim params\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "mLLWvDY-7M96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0gynyNom7B"
      },
      "source": [
        "train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n",
        "valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n",
        "test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_txt = Dataset.from_pandas(train_df)\n",
        "validation_data_txt = Dataset.from_pandas(valid_df)\n",
        "test_data_txt = Dataset.from_pandas(test_df)\n",
        "print(train_data_txt)\n",
        "print(validation_data_txt)\n",
        "print(test_data_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf4cgIQL9uCA",
        "outputId": "9f8ff747-b72d-4350-d8cd-f28376ab274e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'comments'],\n",
            "    num_rows: 81614\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'comments'],\n",
            "    num_rows: 998\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'comments'],\n",
            "    num_rows: 998\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preprocess\n",
        "\"\"\"\n",
        "\n",
        "encoder_max_length = 256  # changed from 256\n",
        "decoder_max_length = 64  # changed from 64\n",
        "\n",
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    source, target = batch[\"text\"], batch[\"comments\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "\n",
        "train_data = train_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=train_data_txt.column_names,\n",
        ")\n",
        "\n",
        "validation_data = validation_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=validation_data_txt.column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4f63fabf442c4054b224f0e34a021ad3",
            "b67cf55f07d64504accfd73ecef4315a",
            "829644dfee4545519b2c21a7433732f1",
            "5f24939d39e64f5d9ebbdadfe77af760",
            "40f40585ea834df9bbe1534d7b504e6a",
            "3e2dd4203cce4171b770dfceb8d22c19",
            "d7f3774872024c398603ff39efb87eba",
            "569770a3b04540658f9b33edb2b296fa",
            "e60356f7893e4c0598212602f18ded2e",
            "a2852c5bd1b24042985a8ef8b0b193ad",
            "553a5ae266f64e6ba433bde5a82f8631",
            "ae1e00a36d394b66900abe72ebcdeaa2",
            "172cac53159146d0ac64ac329ad7ca9a",
            "11e2515b29d54661b3f60401d93e42ec",
            "f8b087df5e5a44b28a7c6bc6ed609604",
            "baf5c1da5a894647be22fcda2072cecd",
            "a573705d98d241f6960796e8689c7af2",
            "a20256094c40467fb95223b8702422fe",
            "17987f28150b47799b83ee7f1338a45f",
            "d85bb6a74dda474683b3382e0d51549d",
            "554ba96e2ee24c5e956f56c36c2b9c38",
            "5d7d9d988c4447b29dfc497ba7d8d6e1"
          ]
        },
        "id": "wvBpN-KNAJ4x",
        "outputId": "4443d90c-6a27-4398-a7be-2ae404ab5778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/81614 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f63fabf442c4054b224f0e34a021ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/998 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae1e00a36d394b66900abe72ebcdeaa2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRueMmaYFamD",
        "outputId": "234a26e2-6605-42d7-d0f1-b04120b04d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 81614\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVc3xgHXFdk4",
        "outputId": "d2a5f244-b617-4071-95d6-53f96b46f2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_validation_index = 17\n",
        "fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n",
        "fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "aYSn2PZcA4Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                         shuffle=True)\n",
        "for i, data in enumerate(dataloader, 0):\n",
        "  print(torch.stack(data['attention_mask']).shape)\n",
        "  break\n"
      ],
      "metadata": {
        "id": "OTM_7TRDEuwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f817315-f8a7-49ec-d03a-c88894e30016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "num_epochs = 1\n",
        "max_input_length = 512\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # todo: batch this/use a dataloader\n",
        "    for i in range(len(validation_data)):\n",
        "        data = validation_data[i]\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = torch.tensor(data['input_ids'] + data['labels'], dtype=torch.float32)\n",
        "        real_cpu = real_cpu.view(1, 1, 1, 64 + 256) # label size + encoder size\n",
        "        real_cpu = real_cpu.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        #discriminator will train off of true comments in the real batch pass\n",
        "\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1) \n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "\n",
        "        inputs = valid_df.iloc[i]['text']\n",
        "        generator_input = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "        fake = netG.generate(**generator_input, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n",
        "        inp_tensor = torch.tensor(data['input_ids'], dtype=torch.long).unsqueeze(0)\n",
        "        fake = torch.cat((inp_tensor, fake), dim=1)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        #print(fake.shape)\n",
        "        fake = fake.type(torch.float32)\n",
        "        fake = fake.view(1, 1, 1, -1)\n",
        "        fake = fake.detach().to(device)\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 5 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(validation_data),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        if iters == 5: netG.save_pretrained('banana/hf-save-initial')\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n",
        "            netG.save_pretrained('banana/hf-save-initial')\n",
        "            with torch.no_grad():\n",
        "                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n",
        "            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "netG.save_pretrained('banana/hf-save-initial')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7CIqDPACJV9",
        "outputId": "2ef82bcc-5c5f-4863-c6ca-dd93ba51ea8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop...\n",
            "[0/1][0/998]\tLoss_D: 1.0253\tLoss_G: 8.5171\tD(x): 0.7552\tD(G(z)): 0.5251 / 0.0002\n",
            "[0/1][5/998]\tLoss_D: 0.8788\tLoss_G: 5.8979\tD(x): 0.9154\tD(G(z)): 0.5463 / 0.0027\n",
            "[0/1][10/998]\tLoss_D: 1.1790\tLoss_G: 5.6877\tD(x): 0.9993\tD(G(z)): 0.6922 / 0.0034\n",
            "[0/1][15/998]\tLoss_D: 1.5726\tLoss_G: 4.6759\tD(x): 0.5287\tD(G(z)): 0.6075 / 0.0093\n",
            "[0/1][20/998]\tLoss_D: 1.4517\tLoss_G: 6.2196\tD(x): 0.5485\tD(G(z)): 0.5731 / 0.0020\n",
            "[0/1][25/998]\tLoss_D: 2.9269\tLoss_G: 4.0427\tD(x): 0.2520\tD(G(z)): 0.7875 / 0.0175\n",
            "[0/1][30/998]\tLoss_D: 4.5951\tLoss_G: 2.3106\tD(x): 0.3571\tD(G(z)): 0.9717 / 0.0992\n",
            "[0/1][35/998]\tLoss_D: 2.4031\tLoss_G: 2.9722\tD(x): 0.2478\tD(G(z)): 0.6351 / 0.0512\n",
            "[0/1][40/998]\tLoss_D: 6.0905\tLoss_G: 2.1041\tD(x): 0.0395\tD(G(z)): 0.9427 / 0.1220\n",
            "[0/1][45/998]\tLoss_D: 0.3398\tLoss_G: 2.9652\tD(x): 0.7584\tD(G(z)): 0.0613 / 0.0516\n",
            "[0/1][50/998]\tLoss_D: 5.6027\tLoss_G: 2.0141\tD(x): 0.0530\tD(G(z)): 0.9304 / 0.1334\n",
            "[0/1][55/998]\tLoss_D: 3.1806\tLoss_G: 2.4668\tD(x): 0.1998\tD(G(z)): 0.7920 / 0.0849\n",
            "[0/1][60/998]\tLoss_D: 1.0920\tLoss_G: 2.5327\tD(x): 0.6034\tD(G(z)): 0.4439 / 0.0794\n",
            "[0/1][65/998]\tLoss_D: 2.2466\tLoss_G: 1.8235\tD(x): 0.6239\tD(G(z)): 0.8305 / 0.1615\n",
            "[0/1][70/998]\tLoss_D: 1.1201\tLoss_G: 2.3806\tD(x): 0.6761\tD(G(z)): 0.5175 / 0.0925\n",
            "[0/1][75/998]\tLoss_D: 0.2807\tLoss_G: 2.6841\tD(x): 0.8490\tD(G(z)): 0.1104 / 0.0683\n",
            "[0/1][80/998]\tLoss_D: 0.4070\tLoss_G: 2.3658\tD(x): 0.9066\tD(G(z)): 0.2658 / 0.0939\n",
            "[0/1][85/998]\tLoss_D: 1.2454\tLoss_G: 2.6585\tD(x): 0.6865\tD(G(z)): 0.5807 / 0.0701\n",
            "[0/1][90/998]\tLoss_D: 1.4737\tLoss_G: 0.3494\tD(x): 0.2979\tD(G(z)): 0.2310 / 0.7051\n",
            "[0/1][95/998]\tLoss_D: 0.4812\tLoss_G: 2.7928\tD(x): 0.9544\tD(G(z)): 0.3524 / 0.0612\n",
            "[0/1][100/998]\tLoss_D: 0.7982\tLoss_G: 2.3251\tD(x): 0.6010\tD(G(z)): 0.2510 / 0.0978\n",
            "[0/1][105/998]\tLoss_D: 0.1339\tLoss_G: 2.6025\tD(x): 0.9832\tD(G(z)): 0.1103 / 0.0741\n",
            "[0/1][110/998]\tLoss_D: 1.7467\tLoss_G: 2.3048\tD(x): 0.5807\tD(G(z)): 0.6998 / 0.0998\n",
            "[0/1][115/998]\tLoss_D: 0.3312\tLoss_G: 2.1887\tD(x): 0.8316\tD(G(z)): 0.1365 / 0.1121\n",
            "[0/1][120/998]\tLoss_D: 1.7344\tLoss_G: 0.5985\tD(x): 0.2233\tD(G(z)): 0.2094 / 0.5497\n",
            "[0/1][125/998]\tLoss_D: 1.3887\tLoss_G: 1.1724\tD(x): 0.7313\tD(G(z)): 0.6589 / 0.3096\n",
            "[0/1][130/998]\tLoss_D: 1.2939\tLoss_G: 1.8945\tD(x): 0.5105\tD(G(z)): 0.4629 / 0.1504\n",
            "[0/1][135/998]\tLoss_D: 1.6753\tLoss_G: 2.1326\tD(x): 0.2318\tD(G(z)): 0.1922 / 0.1185\n",
            "[0/1][140/998]\tLoss_D: 2.0905\tLoss_G: 1.1593\tD(x): 0.5841\tD(G(z)): 0.7884 / 0.3137\n",
            "[0/1][145/998]\tLoss_D: 2.5066\tLoss_G: 0.7104\tD(x): 0.4379\tD(G(z)): 0.8138 / 0.4915\n",
            "[0/1][150/998]\tLoss_D: 2.7338\tLoss_G: 0.9812\tD(x): 0.0697\tD(G(z)): 0.0674 / 0.3749\n",
            "[0/1][155/998]\tLoss_D: 0.7359\tLoss_G: 1.6359\tD(x): 0.9106\tD(G(z)): 0.4739 / 0.1948\n",
            "[0/1][160/998]\tLoss_D: 2.2340\tLoss_G: 0.8536\tD(x): 0.9026\tD(G(z)): 0.8813 / 0.4259\n",
            "[0/1][165/998]\tLoss_D: 0.1574\tLoss_G: 2.9383\tD(x): 0.9218\tD(G(z)): 0.0731 / 0.0530\n",
            "[0/1][170/998]\tLoss_D: 2.7068\tLoss_G: 1.7447\tD(x): 0.0973\tD(G(z)): 0.3140 / 0.1747\n",
            "[0/1][175/998]\tLoss_D: 1.5271\tLoss_G: 1.9249\tD(x): 0.3376\tD(G(z)): 0.3568 / 0.1459\n",
            "[0/1][180/998]\tLoss_D: 1.5046\tLoss_G: 2.1498\tD(x): 0.2483\tD(G(z)): 0.1054 / 0.1165\n",
            "[0/1][185/998]\tLoss_D: 0.4850\tLoss_G: 2.1274\tD(x): 0.8160\tD(G(z)): 0.2455 / 0.1192\n",
            "[0/1][190/998]\tLoss_D: 1.2219\tLoss_G: 1.6531\tD(x): 0.6983\tD(G(z)): 0.5780 / 0.1914\n",
            "[0/1][195/998]\tLoss_D: 1.3672\tLoss_G: 1.5849\tD(x): 0.4339\tD(G(z)): 0.4128 / 0.2050\n",
            "[0/1][200/998]\tLoss_D: 1.2064\tLoss_G: 1.8283\tD(x): 0.3810\tD(G(z)): 0.2145 / 0.1607\n",
            "[0/1][205/998]\tLoss_D: 1.4149\tLoss_G: 1.7774\tD(x): 0.3606\tD(G(z)): 0.3263 / 0.1691\n",
            "[0/1][210/998]\tLoss_D: 2.4930\tLoss_G: 1.1860\tD(x): 0.5194\tD(G(z)): 0.8408 / 0.3054\n",
            "[0/1][215/998]\tLoss_D: 1.5472\tLoss_G: 1.7647\tD(x): 0.5837\tD(G(z)): 0.6354 / 0.1712\n",
            "[0/1][220/998]\tLoss_D: 0.6575\tLoss_G: 1.9294\tD(x): 0.9296\tD(G(z)): 0.4426 / 0.1452\n",
            "[0/1][225/998]\tLoss_D: 1.0238\tLoss_G: 3.0032\tD(x): 0.3769\tD(G(z)): 0.0469 / 0.0496\n",
            "[0/1][230/998]\tLoss_D: 3.2442\tLoss_G: 1.2395\tD(x): 0.1069\tD(G(z)): 0.6352 / 0.2895\n",
            "[0/1][235/998]\tLoss_D: 0.7310\tLoss_G: 2.4193\tD(x): 0.9574\tD(G(z)): 0.4971 / 0.0890\n",
            "[0/1][240/998]\tLoss_D: 1.6157\tLoss_G: 1.3135\tD(x): 0.5217\tD(G(z)): 0.6190 / 0.2689\n",
            "[0/1][245/998]\tLoss_D: 0.4938\tLoss_G: 1.7693\tD(x): 0.9859\tD(G(z)): 0.3810 / 0.1704\n",
            "[0/1][250/998]\tLoss_D: 1.2238\tLoss_G: 1.9582\tD(x): 0.4374\tD(G(z)): 0.3276 / 0.1411\n",
            "[0/1][255/998]\tLoss_D: 1.4236\tLoss_G: 1.1738\tD(x): 0.8586\tD(G(z)): 0.7195 / 0.3092\n",
            "[0/1][260/998]\tLoss_D: 0.5253\tLoss_G: 2.1779\tD(x): 0.8899\tD(G(z)): 0.3354 / 0.1133\n",
            "[0/1][265/998]\tLoss_D: 0.5261\tLoss_G: 1.8047\tD(x): 0.7930\tD(G(z)): 0.2549 / 0.1645\n",
            "[0/1][270/998]\tLoss_D: 0.9299\tLoss_G: 1.5364\tD(x): 0.7586\tD(G(z)): 0.4798 / 0.2152\n",
            "[0/1][275/998]\tLoss_D: 0.4436\tLoss_G: 2.7063\tD(x): 0.7029\tD(G(z)): 0.0871 / 0.0668\n",
            "[0/1][280/998]\tLoss_D: 1.0374\tLoss_G: 1.3939\tD(x): 0.7912\tD(G(z)): 0.5521 / 0.2481\n",
            "[0/1][285/998]\tLoss_D: 0.5533\tLoss_G: 1.5795\tD(x): 0.9864\tD(G(z)): 0.4170 / 0.2061\n",
            "[0/1][290/998]\tLoss_D: 1.2447\tLoss_G: 1.1791\tD(x): 0.8793\tD(G(z)): 0.6724 / 0.3076\n",
            "[0/1][295/998]\tLoss_D: 0.4511\tLoss_G: 2.2395\tD(x): 0.7685\tD(G(z)): 0.1712 / 0.1065\n",
            "[0/1][300/998]\tLoss_D: 1.3168\tLoss_G: 0.6182\tD(x): 0.5206\tD(G(z)): 0.4852 / 0.5389\n",
            "[0/1][305/998]\tLoss_D: 1.5669\tLoss_G: 1.2059\tD(x): 0.6682\tD(G(z)): 0.6877 / 0.2994\n",
            "[0/1][310/998]\tLoss_D: 2.7060\tLoss_G: 0.8420\tD(x): 0.2633\tD(G(z)): 0.7462 / 0.4308\n",
            "[0/1][315/998]\tLoss_D: 0.3998\tLoss_G: 2.3858\tD(x): 0.8231\tD(G(z)): 0.1855 / 0.0920\n",
            "[0/1][320/998]\tLoss_D: 2.3144\tLoss_G: 1.6003\tD(x): 0.2606\tD(G(z)): 0.6208 / 0.2018\n",
            "[0/1][325/998]\tLoss_D: 1.6965\tLoss_G: 0.8175\tD(x): 0.4169\tD(G(z)): 0.5603 / 0.4415\n",
            "[0/1][330/998]\tLoss_D: 0.7468\tLoss_G: 1.6745\tD(x): 0.8161\tD(G(z)): 0.4193 / 0.1874\n",
            "[0/1][335/998]\tLoss_D: 1.6974\tLoss_G: 1.8796\tD(x): 0.3193\tD(G(z)): 0.4264 / 0.1527\n",
            "[0/1][340/998]\tLoss_D: 1.4934\tLoss_G: 1.3316\tD(x): 0.9325\tD(G(z)): 0.7591 / 0.2641\n",
            "[0/1][345/998]\tLoss_D: 0.9311\tLoss_G: 2.3625\tD(x): 0.4400\tD(G(z)): 0.1042 / 0.0942\n",
            "[0/1][350/998]\tLoss_D: 3.1002\tLoss_G: 1.1529\tD(x): 0.1432\tD(G(z)): 0.6854 / 0.3157\n",
            "[0/1][355/998]\tLoss_D: 1.5405\tLoss_G: 0.7984\tD(x): 0.6147\tD(G(z)): 0.6514 / 0.4501\n",
            "[0/1][360/998]\tLoss_D: 1.1216\tLoss_G: 2.1917\tD(x): 0.4130\tD(G(z)): 0.2112 / 0.1117\n",
            "[0/1][365/998]\tLoss_D: 1.3825\tLoss_G: 0.8434\tD(x): 0.4507\tD(G(z)): 0.4432 / 0.4302\n",
            "[0/1][370/998]\tLoss_D: 3.9480\tLoss_G: 0.9575\tD(x): 0.1248\tD(G(z)): 0.8454 / 0.3839\n",
            "[0/1][375/998]\tLoss_D: 1.0117\tLoss_G: 1.5770\tD(x): 0.7787\tD(G(z)): 0.5330 / 0.2066\n",
            "[0/1][380/998]\tLoss_D: 0.8376\tLoss_G: 1.7868\tD(x): 0.6397\tD(G(z)): 0.3235 / 0.1675\n",
            "[0/1][385/998]\tLoss_D: 1.9206\tLoss_G: 1.3399\tD(x): 0.2883\tD(G(z)): 0.4917 / 0.2619\n",
            "[0/1][390/998]\tLoss_D: 1.4136\tLoss_G: 0.9639\tD(x): 0.5621\tD(G(z)): 0.5672 / 0.3814\n",
            "[0/1][395/998]\tLoss_D: 2.6936\tLoss_G: 1.2573\tD(x): 0.0985\tD(G(z)): 0.3131 / 0.2844\n",
            "[0/1][400/998]\tLoss_D: 1.5282\tLoss_G: 1.1491\tD(x): 0.7036\tD(G(z)): 0.6917 / 0.3169\n",
            "[0/1][405/998]\tLoss_D: 0.1499\tLoss_G: 3.5753\tD(x): 0.8884\tD(G(z)): 0.0311 / 0.0280\n",
            "[0/1][410/998]\tLoss_D: 2.9559\tLoss_G: 1.3368\tD(x): 0.1628\tD(G(z)): 0.6804 / 0.2627\n",
            "[0/1][415/998]\tLoss_D: 0.7729\tLoss_G: 1.9564\tD(x): 0.5569\tD(G(z)): 0.1710 / 0.1414\n",
            "[0/1][420/998]\tLoss_D: 0.5374\tLoss_G: 1.7685\tD(x): 0.9147\tD(G(z)): 0.3613 / 0.1706\n",
            "[0/1][425/998]\tLoss_D: 0.2408\tLoss_G: 3.4892\tD(x): 0.8148\tD(G(z)): 0.0354 / 0.0305\n",
            "[0/1][430/998]\tLoss_D: 3.7767\tLoss_G: 0.5165\tD(x): 0.1333\tD(G(z)): 0.8283 / 0.5966\n",
            "[0/1][435/998]\tLoss_D: 0.3096\tLoss_G: 1.8503\tD(x): 0.9584\tD(G(z)): 0.2344 / 0.1572\n",
            "[0/1][440/998]\tLoss_D: 3.9917\tLoss_G: 0.1052\tD(x): 0.9185\tD(G(z)): 0.9799 / 0.9002\n",
            "[0/1][445/998]\tLoss_D: 1.4038\tLoss_G: 1.2184\tD(x): 0.7549\tD(G(z)): 0.6746 / 0.2957\n",
            "[0/1][450/998]\tLoss_D: 3.7478\tLoss_G: 0.5391\tD(x): 0.1548\tD(G(z)): 0.8478 / 0.5833\n",
            "[0/1][455/998]\tLoss_D: 2.6701\tLoss_G: 1.1115\tD(x): 0.1838\tD(G(z)): 0.6233 / 0.3291\n",
            "[0/1][460/998]\tLoss_D: 1.2833\tLoss_G: 1.1293\tD(x): 0.5788\tD(G(z)): 0.5212 / 0.3233\n",
            "[0/1][465/998]\tLoss_D: 1.3526\tLoss_G: 2.5423\tD(x): 0.2807\tD(G(z)): 0.0788 / 0.0787\n",
            "[0/1][470/998]\tLoss_D: 1.3448\tLoss_G: 1.3245\tD(x): 0.5643\tD(G(z)): 0.5382 / 0.2659\n",
            "[0/1][475/998]\tLoss_D: 1.1711\tLoss_G: 1.2351\tD(x): 0.5861\tD(G(z)): 0.4710 / 0.2908\n",
            "[0/1][480/998]\tLoss_D: 1.7409\tLoss_G: 0.6593\tD(x): 0.6047\tD(G(z)): 0.7100 / 0.5172\n",
            "[0/1][485/998]\tLoss_D: 1.5055\tLoss_G: 1.0051\tD(x): 0.8577\tD(G(z)): 0.7413 / 0.3660\n",
            "[0/1][490/998]\tLoss_D: 1.7324\tLoss_G: 0.8223\tD(x): 0.3046\tD(G(z)): 0.4193 / 0.4394\n",
            "[0/1][495/998]\tLoss_D: 1.7564\tLoss_G: 1.1072\tD(x): 0.3655\tD(G(z)): 0.5276 / 0.3305\n",
            "[0/1][500/998]\tLoss_D: 1.2532\tLoss_G: 0.8840\tD(x): 0.6587\tD(G(z)): 0.5664 / 0.4131\n",
            "[0/1][505/998]\tLoss_D: 1.8693\tLoss_G: 1.0105\tD(x): 0.2187\tD(G(z)): 0.2947 / 0.3640\n",
            "[0/1][510/998]\tLoss_D: 1.3995\tLoss_G: 1.0561\tD(x): 0.6940\tD(G(z)): 0.6445 / 0.3478\n",
            "[0/1][515/998]\tLoss_D: 1.7266\tLoss_G: 1.2609\tD(x): 0.5324\tD(G(z)): 0.6659 / 0.2834\n",
            "[0/1][520/998]\tLoss_D: 1.4619\tLoss_G: 1.1388\tD(x): 0.3817\tD(G(z)): 0.3928 / 0.3202\n",
            "[0/1][525/998]\tLoss_D: 1.3719\tLoss_G: 1.3358\tD(x): 0.7930\tD(G(z)): 0.6801 / 0.2630\n",
            "[0/1][530/998]\tLoss_D: 0.5347\tLoss_G: 2.0697\tD(x): 0.7505\tD(G(z)): 0.2194 / 0.1262\n",
            "[0/1][535/998]\tLoss_D: 1.7212\tLoss_G: 1.6131\tD(x): 0.2392\tD(G(z)): 0.2525 / 0.1993\n",
            "[0/1][540/998]\tLoss_D: 0.4173\tLoss_G: 2.1667\tD(x): 0.7808\tD(G(z)): 0.1562 / 0.1146\n",
            "[0/1][545/998]\tLoss_D: 1.5757\tLoss_G: 1.4681\tD(x): 0.4685\tD(G(z)): 0.5584 / 0.2304\n",
            "[0/1][550/998]\tLoss_D: 0.3226\tLoss_G: 3.1075\tD(x): 0.7604\tD(G(z)): 0.0475 / 0.0447\n",
            "[0/1][555/998]\tLoss_D: 0.3974\tLoss_G: 1.6651\tD(x): 0.9683\tD(G(z)): 0.3059 / 0.1892\n",
            "[0/1][560/998]\tLoss_D: 3.2060\tLoss_G: 0.7653\tD(x): 0.3031\tD(G(z)): 0.8663 / 0.4652\n",
            "[0/1][565/998]\tLoss_D: 0.7063\tLoss_G: 1.6904\tD(x): 0.7020\tD(G(z)): 0.2970 / 0.1845\n",
            "[0/1][570/998]\tLoss_D: 2.1695\tLoss_G: 2.0683\tD(x): 0.1314\tD(G(z)): 0.1303 / 0.1264\n",
            "[0/1][575/998]\tLoss_D: 0.9935\tLoss_G: 1.0382\tD(x): 0.7818\tD(G(z)): 0.5264 / 0.3541\n",
            "[0/1][580/998]\tLoss_D: 0.7039\tLoss_G: 1.4266\tD(x): 0.7988\tD(G(z)): 0.3807 / 0.2401\n",
            "[0/1][585/998]\tLoss_D: 2.9262\tLoss_G: 0.2672\tD(x): 0.9484\tD(G(z)): 0.9435 / 0.7655\n",
            "[0/1][590/998]\tLoss_D: 1.2696\tLoss_G: 1.2261\tD(x): 0.5331\tD(G(z)): 0.4730 / 0.2934\n",
            "[0/1][595/998]\tLoss_D: 2.2766\tLoss_G: 0.8964\tD(x): 0.4303\tD(G(z)): 0.7615 / 0.4080\n",
            "[0/1][600/998]\tLoss_D: 0.4372\tLoss_G: 2.1787\tD(x): 0.7848\tD(G(z)): 0.1771 / 0.1132\n",
            "[0/1][605/998]\tLoss_D: 0.8868\tLoss_G: 1.4788\tD(x): 0.6904\tD(G(z)): 0.4033 / 0.2279\n",
            "[0/1][610/998]\tLoss_D: 1.1068\tLoss_G: 1.6120\tD(x): 0.4505\tD(G(z)): 0.2662 / 0.1995\n",
            "[0/1][615/998]\tLoss_D: 2.1752\tLoss_G: 1.0400\tD(x): 0.1448\tD(G(z)): 0.2157 / 0.3535\n",
            "[0/1][620/998]\tLoss_D: 0.5559\tLoss_G: 2.1736\tD(x): 0.6639\tD(G(z)): 0.1362 / 0.1138\n",
            "[0/1][625/998]\tLoss_D: 0.5220\tLoss_G: 1.8235\tD(x): 0.8602\tD(G(z)): 0.3103 / 0.1615\n",
            "[0/1][630/998]\tLoss_D: 1.1807\tLoss_G: 1.7291\tD(x): 0.5777\tD(G(z)): 0.4685 / 0.1774\n",
            "[0/1][635/998]\tLoss_D: 0.3203\tLoss_G: 1.8863\tD(x): 0.9108\tD(G(z)): 0.2030 / 0.1516\n",
            "[0/1][640/998]\tLoss_D: 0.6103\tLoss_G: 3.6892\tD(x): 0.5560\tD(G(z)): 0.0231 / 0.0250\n",
            "[0/1][645/998]\tLoss_D: 1.2402\tLoss_G: 1.3315\tD(x): 0.5777\tD(G(z)): 0.4992 / 0.2641\n",
            "[0/1][650/998]\tLoss_D: 2.1845\tLoss_G: 1.1444\tD(x): 0.3136\tD(G(z)): 0.6411 / 0.3184\n",
            "[0/1][655/998]\tLoss_D: 0.9037\tLoss_G: 1.5608\tD(x): 0.4989\tD(G(z)): 0.1881 / 0.2100\n",
            "[0/1][660/998]\tLoss_D: 1.8325\tLoss_G: 0.7552\tD(x): 0.4553\tD(G(z)): 0.6485 / 0.4699\n",
            "[0/1][665/998]\tLoss_D: 2.4277\tLoss_G: 1.3453\tD(x): 0.1399\tD(G(z)): 0.3693 / 0.2605\n",
            "[0/1][670/998]\tLoss_D: 1.1870\tLoss_G: 1.0435\tD(x): 0.6560\tD(G(z)): 0.5349 / 0.3522\n",
            "[0/1][675/998]\tLoss_D: 0.8812\tLoss_G: 1.8962\tD(x): 0.4883\tD(G(z)): 0.1516 / 0.1501\n",
            "[0/1][680/998]\tLoss_D: 1.3984\tLoss_G: 1.5000\tD(x): 0.3419\tD(G(z)): 0.2776 / 0.2231\n",
            "[0/1][685/998]\tLoss_D: 0.4964\tLoss_G: 1.7005\tD(x): 0.8622\tD(G(z)): 0.2940 / 0.1826\n",
            "[0/1][690/998]\tLoss_D: 1.0463\tLoss_G: 1.3889\tD(x): 0.5372\tD(G(z)): 0.3462 / 0.2494\n",
            "[0/1][695/998]\tLoss_D: 0.1988\tLoss_G: 2.6593\tD(x): 0.8988\tD(G(z)): 0.0880 / 0.0700\n",
            "[0/1][700/998]\tLoss_D: 1.5852\tLoss_G: 1.4684\tD(x): 0.3228\tD(G(z)): 0.3653 / 0.2303\n",
            "[0/1][705/998]\tLoss_D: 1.6411\tLoss_G: 1.4577\tD(x): 0.4890\tD(G(z)): 0.6038 / 0.2328\n",
            "[0/1][710/998]\tLoss_D: 1.9958\tLoss_G: 0.9790\tD(x): 0.6556\tD(G(z)): 0.7927 / 0.3757\n",
            "[0/1][715/998]\tLoss_D: 1.7124\tLoss_G: 0.7234\tD(x): 0.5720\tD(G(z)): 0.6846 / 0.4851\n",
            "[0/1][720/998]\tLoss_D: 1.3890\tLoss_G: 1.4738\tD(x): 0.8991\tD(G(z)): 0.7227 / 0.2291\n",
            "[0/1][725/998]\tLoss_D: 0.4359\tLoss_G: 1.7861\tD(x): 0.7923\tD(G(z)): 0.1838 / 0.1676\n",
            "[0/1][730/998]\tLoss_D: 0.8535\tLoss_G: 1.2682\tD(x): 0.6954\tD(G(z)): 0.3875 / 0.2813\n",
            "[0/1][735/998]\tLoss_D: 0.8370\tLoss_G: 1.7869\tD(x): 0.6153\tD(G(z)): 0.2962 / 0.1675\n",
            "[0/1][740/998]\tLoss_D: 1.3500\tLoss_G: 2.0460\tD(x): 0.3139\tD(G(z)): 0.1743 / 0.1293\n",
            "[0/1][745/998]\tLoss_D: 0.3785\tLoss_G: 1.6539\tD(x): 0.9705\tD(G(z)): 0.2943 / 0.1913\n",
            "[0/1][750/998]\tLoss_D: 3.3202\tLoss_G: 0.4007\tD(x): 0.9533\tD(G(z)): 0.9621 / 0.6698\n",
            "[0/1][755/998]\tLoss_D: 0.3831\tLoss_G: 1.9073\tD(x): 0.9708\tD(G(z)): 0.2977 / 0.1485\n",
            "[0/1][760/998]\tLoss_D: 1.0761\tLoss_G: 1.8862\tD(x): 0.4164\tD(G(z)): 0.1812 / 0.1516\n",
            "[0/1][765/998]\tLoss_D: 3.0771\tLoss_G: 2.0630\tD(x): 0.0523\tD(G(z)): 0.1195 / 0.1271\n",
            "[0/1][770/998]\tLoss_D: 1.8136\tLoss_G: 1.7254\tD(x): 0.2046\tD(G(z)): 0.2030 / 0.1781\n",
            "[0/1][775/998]\tLoss_D: 0.7397\tLoss_G: 1.3503\tD(x): 0.8612\tD(G(z)): 0.4458 / 0.2592\n",
            "[0/1][780/998]\tLoss_D: 1.5314\tLoss_G: 1.4788\tD(x): 0.3188\tD(G(z)): 0.3218 / 0.2279\n",
            "[0/1][785/998]\tLoss_D: 1.4737\tLoss_G: 0.8918\tD(x): 0.9569\tD(G(z)): 0.7606 / 0.4099\n",
            "[0/1][790/998]\tLoss_D: 1.6994\tLoss_G: 1.3941\tD(x): 0.3069\tD(G(z)): 0.4044 / 0.2480\n",
            "[0/1][795/998]\tLoss_D: 0.3379\tLoss_G: 1.9166\tD(x): 0.9234\tD(G(z)): 0.2276 / 0.1471\n",
            "[0/1][800/998]\tLoss_D: 0.8167\tLoss_G: 1.1594\tD(x): 0.8019\tD(G(z)): 0.4490 / 0.3137\n",
            "[0/1][805/998]\tLoss_D: 1.6553\tLoss_G: 1.1228\tD(x): 0.4572\tD(G(z)): 0.5822 / 0.3254\n",
            "[0/1][810/998]\tLoss_D: 1.6745\tLoss_G: 2.5174\tD(x): 0.1996\tD(G(z)): 0.0612 / 0.0807\n",
            "[0/1][815/998]\tLoss_D: 0.9061\tLoss_G: 1.8198\tD(x): 0.5206\tD(G(z)): 0.2238 / 0.1621\n",
            "[0/1][820/998]\tLoss_D: 3.6626\tLoss_G: 1.7477\tD(x): 0.0966\tD(G(z)): 0.7343 / 0.1742\n",
            "[0/1][825/998]\tLoss_D: 1.6093\tLoss_G: 0.9878\tD(x): 0.2604\tD(G(z)): 0.2320 / 0.3724\n",
            "[0/1][830/998]\tLoss_D: 3.3761\tLoss_G: 0.8639\tD(x): 0.1792\tD(G(z)): 0.8093 / 0.4215\n",
            "[0/1][835/998]\tLoss_D: 1.9983\tLoss_G: 0.7390\tD(x): 0.6011\tD(G(z)): 0.7745 / 0.4776\n",
            "[0/1][840/998]\tLoss_D: 1.1244\tLoss_G: 1.6977\tD(x): 0.4154\tD(G(z)): 0.2180 / 0.1831\n",
            "[0/1][845/998]\tLoss_D: 1.4322\tLoss_G: 1.9895\tD(x): 0.2860\tD(G(z)): 0.1649 / 0.1368\n",
            "[0/1][850/998]\tLoss_D: 0.8098\tLoss_G: 1.6603\tD(x): 0.8034\tD(G(z)): 0.4461 / 0.1901\n",
            "[0/1][855/998]\tLoss_D: 2.4319\tLoss_G: 0.4973\tD(x): 0.9434\tD(G(z)): 0.9069 / 0.6082\n",
            "[0/1][860/998]\tLoss_D: 0.3523\tLoss_G: 1.9436\tD(x): 0.8392\tD(G(z)): 0.1622 / 0.1432\n",
            "[0/1][865/998]\tLoss_D: 3.4008\tLoss_G: 0.2496\tD(x): 0.4222\tD(G(z)): 0.9210 / 0.7791\n",
            "[0/1][870/998]\tLoss_D: 1.4011\tLoss_G: 0.7816\tD(x): 0.8975\tD(G(z)): 0.7256 / 0.4577\n",
            "[0/1][875/998]\tLoss_D: 1.0595\tLoss_G: 1.5595\tD(x): 0.5242\tD(G(z)): 0.3387 / 0.2102\n",
            "[0/1][880/998]\tLoss_D: 0.1576\tLoss_G: 2.5693\tD(x): 0.9589\tD(G(z)): 0.1092 / 0.0766\n",
            "[0/1][885/998]\tLoss_D: 0.6242\tLoss_G: 1.6135\tD(x): 0.9075\tD(G(z)): 0.4097 / 0.1992\n",
            "[0/1][890/998]\tLoss_D: 0.7735\tLoss_G: 1.6449\tD(x): 0.7635\tD(G(z)): 0.3957 / 0.1930\n",
            "[0/1][895/998]\tLoss_D: 0.9757\tLoss_G: 2.0111\tD(x): 0.5032\tD(G(z)): 0.2509 / 0.1338\n",
            "[0/1][900/998]\tLoss_D: 0.7276\tLoss_G: 2.7317\tD(x): 0.5111\tD(G(z)): 0.0549 / 0.0651\n",
            "[0/1][905/998]\tLoss_D: 0.2115\tLoss_G: 2.7185\tD(x): 0.9556\tD(G(z)): 0.1530 / 0.0660\n",
            "[0/1][910/998]\tLoss_D: 1.0810\tLoss_G: 1.7170\tD(x): 0.8165\tD(G(z)): 0.5845 / 0.1796\n",
            "[0/1][915/998]\tLoss_D: 4.2840\tLoss_G: 0.9062\tD(x): 0.0381\tD(G(z)): 0.6378 / 0.4041\n",
            "[0/1][920/998]\tLoss_D: 2.1015\tLoss_G: 0.9148\tD(x): 0.5922\tD(G(z)): 0.7935 / 0.4006\n",
            "[0/1][925/998]\tLoss_D: 1.8044\tLoss_G: 1.1947\tD(x): 0.3403\tD(G(z)): 0.5163 / 0.3028\n",
            "[0/1][930/998]\tLoss_D: 0.9097\tLoss_G: 1.2165\tD(x): 0.8368\tD(G(z)): 0.5188 / 0.2963\n",
            "[0/1][935/998]\tLoss_D: 2.3225\tLoss_G: 0.8758\tD(x): 0.9341\tD(G(z)): 0.8951 / 0.4165\n",
            "[0/1][940/998]\tLoss_D: 0.7005\tLoss_G: 1.3162\tD(x): 0.9415\tD(G(z)): 0.4728 / 0.2682\n",
            "[0/1][945/998]\tLoss_D: 1.4608\tLoss_G: 0.9902\tD(x): 0.7477\tD(G(z)): 0.6896 / 0.3715\n",
            "[0/1][950/998]\tLoss_D: 2.1363\tLoss_G: 0.7801\tD(x): 0.1611\tD(G(z)): 0.2670 / 0.4583\n",
            "[0/1][955/998]\tLoss_D: 1.2211\tLoss_G: 1.0494\tD(x): 0.6708\tD(G(z)): 0.5603 / 0.3502\n",
            "[0/1][960/998]\tLoss_D: 1.2293\tLoss_G: 0.9334\tD(x): 0.8438\tD(G(z)): 0.6534 / 0.3932\n",
            "[0/1][965/998]\tLoss_D: 1.2669\tLoss_G: 1.5380\tD(x): 0.7571\tD(G(z)): 0.6279 / 0.2148\n",
            "[0/1][970/998]\tLoss_D: 3.2614\tLoss_G: 1.4099\tD(x): 0.0625\tD(G(z)): 0.3869 / 0.2442\n",
            "[0/1][975/998]\tLoss_D: 2.4975\tLoss_G: 1.4428\tD(x): 0.1318\tD(G(z)): 0.3758 / 0.2363\n",
            "[0/1][980/998]\tLoss_D: 2.6288\tLoss_G: 1.4307\tD(x): 0.1805\tD(G(z)): 0.6002 / 0.2391\n",
            "[0/1][985/998]\tLoss_D: 1.0380\tLoss_G: 1.2092\tD(x): 0.6750\tD(G(z)): 0.4753 / 0.2984\n",
            "[0/1][990/998]\tLoss_D: 1.9317\tLoss_G: 1.8257\tD(x): 0.1882\tD(G(z)): 0.2300 / 0.1611\n",
            "[0/1][995/998]\tLoss_D: 2.2030\tLoss_G: 1.2569\tD(x): 0.3445\tD(G(z)): 0.6794 / 0.2845\n"
          ]
        }
      ]
    }
  ]
}
