{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64304ffd607c453e9391fc4d88f3af76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d046d0b998744318f366292b157d312",
              "IPY_MODEL_d437e1da7a3b4fffb6cca7c26d5e3c8e",
              "IPY_MODEL_a7a45fc5be6c4bb399a2947469081f96"
            ],
            "layout": "IPY_MODEL_8f207082f73c4571b04a08bfc402fbb7"
          }
        },
        "0d046d0b998744318f366292b157d312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d31729569a641a4a25bc17690690d80",
            "placeholder": "​",
            "style": "IPY_MODEL_5c6e03f56f3a4c71ae7e44fc1e8d71c7",
            "value": "Map: 100%"
          }
        },
        "d437e1da7a3b4fffb6cca7c26d5e3c8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a32cd6c2911421e8a3980d72ab1622f",
            "max": 81614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0df9d376608c4e0db0e77569d045cc5c",
            "value": 81614
          }
        },
        "a7a45fc5be6c4bb399a2947469081f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3ddb4cc49c34d9a962eaadcd2c31e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_b76ec05be0bb4e86a002babe3d062c7d",
            "value": " 81614/81614 [03:25&lt;00:00, 364.50 examples/s]"
          }
        },
        "8f207082f73c4571b04a08bfc402fbb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8d31729569a641a4a25bc17690690d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c6e03f56f3a4c71ae7e44fc1e8d71c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a32cd6c2911421e8a3980d72ab1622f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df9d376608c4e0db0e77569d045cc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3ddb4cc49c34d9a962eaadcd2c31e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76ec05be0bb4e86a002babe3d062c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b1b14acff614cab96e17a61bd4da016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35964ea48bd14f4f954da31f65fa5abe",
              "IPY_MODEL_d0dc8f1bc23341c0a1104358646c64c1",
              "IPY_MODEL_2d0fc64051d1434586f551a15f24c5a8"
            ],
            "layout": "IPY_MODEL_1194958890924f10a21573e833dcb68a"
          }
        },
        "35964ea48bd14f4f954da31f65fa5abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afd83636afb4d46b25639c24d814c59",
            "placeholder": "​",
            "style": "IPY_MODEL_fdbe7b4c827a4fea9b818ff644fa2325",
            "value": "Map: 100%"
          }
        },
        "d0dc8f1bc23341c0a1104358646c64c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12082a7fa0bc4e8894b820c1c36c4f26",
            "max": 998,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71ed55acea0440eb855c1c6b73753c9d",
            "value": 998
          }
        },
        "2d0fc64051d1434586f551a15f24c5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43baeda15f5547bcbf9d46749fc7ac42",
            "placeholder": "​",
            "style": "IPY_MODEL_a470e001b4a744e99634915cee320490",
            "value": " 998/998 [00:02&lt;00:00, 464.54 examples/s]"
          }
        },
        "1194958890924f10a21573e833dcb68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3afd83636afb4d46b25639c24d814c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbe7b4c827a4fea9b818ff644fa2325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12082a7fa0bc4e8894b820c1c36c4f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ed55acea0440eb855c1c6b73753c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43baeda15f5547bcbf9d46749fc7ac42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a470e001b4a744e99634915cee320490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### GAN Attempt!"
      ],
      "metadata": {
        "id": "l2vionRRzF_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "JADRaL5b276C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Setup\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "ESRs9D8S2gd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd drive/MyDrive/CS\\ 224N/CS\\ 224N\\ Project\n",
        "%ls # verify that you are in the right directory"
      ],
      "metadata": {
        "id": "txGRbtkd4IWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define the generator (use the pre-trained BART implementation)\n",
        "\"\"\"\n",
        "\n",
        "# bart-base checkpoint pre-trained on our dataset\n",
        "# (can also try generically pre-trained bart base)\n",
        "model_dir = 'bart-base-checkpoint-204000'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
        "print(netG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RgiUTBezH2V",
        "outputId": "323710b2-a516-4b5e-cd0e-10b54289e206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartForConditionalGeneration(\n",
            "  (model): BartModel(\n",
            "    (shared): Embedding(50265, 768, padding_idx=1)\n",
            "    (encoder): BartEncoder(\n",
            "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): BartEncoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): GELUActivation()\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): BartDecoder(\n",
            "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
            "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
            "      (layers): ModuleList(\n",
            "        (0): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): BartDecoderLayer(\n",
            "          (self_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (activation_fn): GELUActivation()\n",
            "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): BartAttention(\n",
            "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define convolutional discriminator\n",
        "\"\"\"\n",
        "\n",
        "nc = 1\n",
        "ndf = 64\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            #Reshaping input\n",
        "            nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 64 --> 1, 1, 64, 64\n",
        "            # input is (nc) x 64 x 64 | our input is 1 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        #print(len(input.shape))\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "XBPd1v0Q34Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngpu = 1\n",
        "netD = Discriminator(ngpu).to(device)"
      ],
      "metadata": {
        "id": "F4fElnOc_aAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment = pipeline(model='finiteautomata/bertweet-base-sentiment-analysis')"
      ],
      "metadata": {
        "id": "PFxhD-KlTaB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_tokens(comment):\n",
        "  max_input_length = 128\n",
        "  if len(comment) > 128:\n",
        "    comment = comment[:128]\n",
        "  comment_sentiment = sentiment([comment])[0]\n",
        "  comment_sentiment = comment_sentiment['label'] + ': ' + str(comment_sentiment['score'])\n",
        "  comment_sentiment_tokens = tokenizer(comment_sentiment, max_length=128, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "  return comment_sentiment_tokens['input_ids'].tolist()"
      ],
      "metadata": {
        "id": "Q2df63FbTahX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loss functions and optimizers\n",
        "\"\"\"\n",
        "# Size of generator input\n",
        "nz = 512\n",
        "# Optim params\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "# Initialize BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "mLLWvDY-7M96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA0gynyNom7B"
      },
      "source": [
        "train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n",
        "valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n",
        "test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_txt = Dataset.from_pandas(train_df)\n",
        "validation_data_txt = Dataset.from_pandas(valid_df)\n",
        "test_data_txt = Dataset.from_pandas(test_df)\n",
        "print(train_data_txt)\n",
        "print(validation_data_txt)\n",
        "print(test_data_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf4cgIQL9uCA",
        "outputId": "68157518-9c86-426c-c674-24fb612491c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'comments'],\n",
            "    num_rows: 81614\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'comments'],\n",
            "    num_rows: 998\n",
            "})\n",
            "Dataset({\n",
            "    features: ['text', 'comments'],\n",
            "    num_rows: 998\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Preprocess\n",
        "\"\"\"\n",
        "\n",
        "encoder_max_length = 256  # changed from 256\n",
        "decoder_max_length = 64  # changed from 64\n",
        "\n",
        "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
        "    source, target = batch[\"text\"], batch[\"comments\"]\n",
        "    source_tokenized = tokenizer(\n",
        "        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch\n",
        "\n",
        "\n",
        "train_data = train_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=train_data_txt.column_names,\n",
        ")\n",
        "\n",
        "validation_data = validation_data_txt.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=validation_data_txt.column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "64304ffd607c453e9391fc4d88f3af76",
            "0d046d0b998744318f366292b157d312",
            "d437e1da7a3b4fffb6cca7c26d5e3c8e",
            "a7a45fc5be6c4bb399a2947469081f96",
            "8f207082f73c4571b04a08bfc402fbb7",
            "8d31729569a641a4a25bc17690690d80",
            "5c6e03f56f3a4c71ae7e44fc1e8d71c7",
            "4a32cd6c2911421e8a3980d72ab1622f",
            "0df9d376608c4e0db0e77569d045cc5c",
            "c3ddb4cc49c34d9a962eaadcd2c31e4b",
            "b76ec05be0bb4e86a002babe3d062c7d",
            "3b1b14acff614cab96e17a61bd4da016",
            "35964ea48bd14f4f954da31f65fa5abe",
            "d0dc8f1bc23341c0a1104358646c64c1",
            "2d0fc64051d1434586f551a15f24c5a8",
            "1194958890924f10a21573e833dcb68a",
            "3afd83636afb4d46b25639c24d814c59",
            "fdbe7b4c827a4fea9b818ff644fa2325",
            "12082a7fa0bc4e8894b820c1c36c4f26",
            "71ed55acea0440eb855c1c6b73753c9d",
            "43baeda15f5547bcbf9d46749fc7ac42",
            "a470e001b4a744e99634915cee320490"
          ]
        },
        "id": "wvBpN-KNAJ4x",
        "outputId": "8c6f66c3-213a-447a-f09b-f79ca59aaf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/81614 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64304ffd607c453e9391fc4d88f3af76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/998 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b1b14acff614cab96e17a61bd4da016"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRueMmaYFamD",
        "outputId": "61ba6ca2-1aac-4290-823c-5243a00280bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 81614\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data[0]['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVc3xgHXFdk4",
        "outputId": "3d0b7cd9-4fe4-45f8-85c3-ccd957ddb42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_validation_index = 17\n",
        "fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n",
        "fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "aYSn2PZcA4Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "num_epochs = 1\n",
        "max_input_length = 512\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # todo: batch this/use a dataloader\n",
        "    for i in range(len(validation_data)):\n",
        "        data = validation_data[i]\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        #print(len(data['labels']))\n",
        "        sentiment_tokens = get_sentiment_tokens(str(valid_df.iloc[i]['comments']))\n",
        "        real_cpu = torch.tensor(data['labels'] + sentiment_tokens[0], dtype=torch.float32)\n",
        "        #real_cpu = data['labels']\n",
        "        #print(real_cpu.shape)\n",
        "        # real_cpu = real_cpu.unsqueeze(0)\n",
        "        # real_cpu = real_cpu.unsqueeze(0)\n",
        "        # real_cpu = real_cpu.unsqueeze(0)\n",
        "        real_cpu = real_cpu.view(1, 1, 1, 64 + 128) #these are the comment tokens\n",
        "        #print(real_cpu.shape)\n",
        "        real_cpu = real_cpu.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        #discriminator will train off of true comments in the real batch pass\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1) \n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # print(inputs['input_ids'].shape)\n",
        "        # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n",
        "        # Generate fake image batch with G\n",
        "\n",
        "        inputs = valid_df.iloc[i]['text']\n",
        "        data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "        fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n",
        "        decoded_fake_comment = tokenizer.batch_decode(fake, skip_special_tokens=True)\n",
        "        sentiment_tokens = get_sentiment_tokens(decoded_fake_comment[0])\n",
        "        inp_tensor = torch.tensor(sentiment_tokens[0], dtype=torch.long).unsqueeze(0)\n",
        "        fake = torch.cat((inp_tensor, fake), dim=1)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        #print(fake.shape)\n",
        "        fake = fake.type(torch.float32)\n",
        "        fake = fake.view(1, 1, 1, -1)\n",
        "        fake = fake.detach().to(device)\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 5 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(validation_data),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        if iters == 5: netG.save_pretrained('pear/pear-save-initial')\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters != 0 and iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n",
        "            netG.save_pretrained('pear/pear-save-halfway')\n",
        "            with torch.no_grad():\n",
        "                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n",
        "            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1\n",
        "\n",
        "netG.save_pretrained('pear/pear-save-final')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7CIqDPACJV9",
        "outputId": "33b07215-ad9a-4bef-d46c-f0e6d37a2b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training Loop...\n",
            "[0/1][0/998]\tLoss_D: 1.2201\tLoss_G: 6.7044\tD(x): 0.4763\tD(G(z)): 0.3802 / 0.0012\n",
            "[0/1][5/998]\tLoss_D: 0.0771\tLoss_G: 3.8508\tD(x): 0.9462\tD(G(z)): 0.0216 / 0.0213\n",
            "[0/1][10/998]\tLoss_D: 0.0014\tLoss_G: 8.8193\tD(x): 0.9988\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][15/998]\tLoss_D: 0.0009\tLoss_G: 7.6370\tD(x): 0.9997\tD(G(z)): 0.0006 / 0.0005\n",
            "[0/1][20/998]\tLoss_D: 0.0005\tLoss_G: 7.7316\tD(x): 0.9999\tD(G(z)): 0.0005 / 0.0004\n",
            "[0/1][25/998]\tLoss_D: 0.0039\tLoss_G: 7.1750\tD(x): 0.9969\tD(G(z)): 0.0008 / 0.0008\n",
            "[0/1][30/998]\tLoss_D: 0.0012\tLoss_G: 6.8266\tD(x): 0.9999\tD(G(z)): 0.0011 / 0.0011\n",
            "[0/1][35/998]\tLoss_D: 0.0025\tLoss_G: 8.5001\tD(x): 0.9977\tD(G(z)): 0.0002 / 0.0002\n",
            "[0/1][40/998]\tLoss_D: 0.0064\tLoss_G: 6.9582\tD(x): 0.9947\tD(G(z)): 0.0010 / 0.0010\n",
            "[0/1][45/998]\tLoss_D: 0.0008\tLoss_G: 7.2637\tD(x): 1.0000\tD(G(z)): 0.0007 / 0.0007\n",
            "[0/1][50/998]\tLoss_D: 0.0047\tLoss_G: 6.2717\tD(x): 0.9974\tD(G(z)): 0.0021 / 0.0019\n",
            "[0/1][55/998]\tLoss_D: 0.2576\tLoss_G: 5.2311\tD(x): 0.7737\tD(G(z)): 0.0011 / 0.0053\n",
            "[0/1][60/998]\tLoss_D: 0.0001\tLoss_G: 10.3490\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0000\n",
            "[0/1][65/998]\tLoss_D: 0.0001\tLoss_G: 9.9520\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][70/998]\tLoss_D: 0.0000\tLoss_G: 10.3302\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][75/998]\tLoss_D: 0.0000\tLoss_G: 11.3604\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][80/998]\tLoss_D: 0.0002\tLoss_G: 10.9095\tD(x): 0.9998\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][85/998]\tLoss_D: 0.0001\tLoss_G: 11.6713\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][90/998]\tLoss_D: 0.0003\tLoss_G: 8.2475\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n",
            "[0/1][95/998]\tLoss_D: 0.0009\tLoss_G: 9.8379\tD(x): 0.9992\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][100/998]\tLoss_D: 0.0001\tLoss_G: 9.1027\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][105/998]\tLoss_D: 0.0001\tLoss_G: 11.5717\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][110/998]\tLoss_D: 0.0089\tLoss_G: 6.1352\tD(x): 1.0000\tD(G(z)): 0.0088 / 0.0022\n",
            "[0/1][115/998]\tLoss_D: 0.0003\tLoss_G: 8.1737\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n",
            "[0/1][120/998]\tLoss_D: 0.0013\tLoss_G: 6.9069\tD(x): 0.9999\tD(G(z)): 0.0012 / 0.0010\n",
            "[0/1][125/998]\tLoss_D: 0.0006\tLoss_G: 7.8327\tD(x): 0.9998\tD(G(z)): 0.0004 / 0.0004\n",
            "[0/1][130/998]\tLoss_D: 0.0005\tLoss_G: 10.6413\tD(x): 0.9995\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][135/998]\tLoss_D: 0.0000\tLoss_G: 11.7124\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][140/998]\tLoss_D: 0.0002\tLoss_G: 11.3424\tD(x): 0.9998\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][145/998]\tLoss_D: 0.0000\tLoss_G: 10.1022\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][150/998]\tLoss_D: 0.0000\tLoss_G: 10.8766\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][155/998]\tLoss_D: 0.3892\tLoss_G: 10.5000\tD(x): 1.0000\tD(G(z)): 0.3224 / 0.0000\n",
            "[0/1][160/998]\tLoss_D: 0.0031\tLoss_G: 12.6578\tD(x): 0.9969\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][165/998]\tLoss_D: 0.0068\tLoss_G: 4.7988\tD(x): 1.0000\tD(G(z)): 0.0068 / 0.0082\n",
            "[0/1][170/998]\tLoss_D: 0.0134\tLoss_G: 6.1455\tD(x): 1.0000\tD(G(z)): 0.0133 / 0.0021\n",
            "[0/1][175/998]\tLoss_D: 0.0004\tLoss_G: 8.0348\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n",
            "[0/1][180/998]\tLoss_D: 0.0001\tLoss_G: 9.8887\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][185/998]\tLoss_D: 0.0001\tLoss_G: 8.9445\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][190/998]\tLoss_D: 0.0002\tLoss_G: 8.3694\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n",
            "[0/1][195/998]\tLoss_D: 0.0000\tLoss_G: 10.4361\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][200/998]\tLoss_D: 0.0002\tLoss_G: 8.7956\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n",
            "[0/1][205/998]\tLoss_D: 0.0000\tLoss_G: 11.4688\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][210/998]\tLoss_D: 0.0002\tLoss_G: 8.6893\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n",
            "[0/1][215/998]\tLoss_D: 0.0000\tLoss_G: 10.1515\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][220/998]\tLoss_D: 0.0001\tLoss_G: 9.2419\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][225/998]\tLoss_D: 0.0005\tLoss_G: 7.8191\tD(x): 1.0000\tD(G(z)): 0.0004 / 0.0004\n",
            "[0/1][230/998]\tLoss_D: 0.0000\tLoss_G: 11.1093\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][235/998]\tLoss_D: 0.0000\tLoss_G: 14.2977\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][240/998]\tLoss_D: 0.0000\tLoss_G: 12.6649\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][245/998]\tLoss_D: 0.0000\tLoss_G: 11.7679\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][250/998]\tLoss_D: 0.0001\tLoss_G: 9.5134\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][255/998]\tLoss_D: 0.0001\tLoss_G: 10.2940\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][260/998]\tLoss_D: 0.0003\tLoss_G: 7.4780\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0006\n",
            "[0/1][265/998]\tLoss_D: 0.0000\tLoss_G: 15.7026\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][270/998]\tLoss_D: 0.0000\tLoss_G: 15.4604\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][275/998]\tLoss_D: 0.0000\tLoss_G: 15.5534\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][280/998]\tLoss_D: 0.0000\tLoss_G: 16.4511\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][285/998]\tLoss_D: 0.0001\tLoss_G: 15.3846\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][290/998]\tLoss_D: 0.0000\tLoss_G: 10.3623\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][295/998]\tLoss_D: 0.0000\tLoss_G: 16.1153\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][300/998]\tLoss_D: 0.0000\tLoss_G: 18.5863\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][305/998]\tLoss_D: 0.0001\tLoss_G: 18.2128\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][310/998]\tLoss_D: 0.0000\tLoss_G: 17.4752\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][315/998]\tLoss_D: 0.0000\tLoss_G: 16.4931\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][320/998]\tLoss_D: 0.0000\tLoss_G: 15.6486\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][325/998]\tLoss_D: 0.0000\tLoss_G: 16.5070\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][330/998]\tLoss_D: 0.0000\tLoss_G: 14.0488\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][335/998]\tLoss_D: 0.0024\tLoss_G: 6.0967\tD(x): 1.0000\tD(G(z)): 0.0024 / 0.0023\n",
            "[0/1][340/998]\tLoss_D: 0.0001\tLoss_G: 9.2681\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][345/998]\tLoss_D: 0.0000\tLoss_G: 17.5221\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][350/998]\tLoss_D: 0.0017\tLoss_G: 6.4102\tD(x): 1.0000\tD(G(z)): 0.0017 / 0.0016\n",
            "[0/1][355/998]\tLoss_D: 0.0000\tLoss_G: 16.8984\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][360/998]\tLoss_D: 0.0000\tLoss_G: 19.0696\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][365/998]\tLoss_D: 0.0000\tLoss_G: 11.3747\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][370/998]\tLoss_D: 0.0000\tLoss_G: 17.7066\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][375/998]\tLoss_D: 0.0000\tLoss_G: 17.0562\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][380/998]\tLoss_D: 0.0002\tLoss_G: 8.9150\tD(x): 0.9999\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][385/998]\tLoss_D: 0.0003\tLoss_G: 13.6143\tD(x): 0.9997\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][390/998]\tLoss_D: 0.0000\tLoss_G: 10.1201\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][395/998]\tLoss_D: 0.0000\tLoss_G: 11.1430\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][400/998]\tLoss_D: 0.0000\tLoss_G: 17.1273\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][405/998]\tLoss_D: 0.0000\tLoss_G: 17.0062\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][410/998]\tLoss_D: 0.0003\tLoss_G: 8.0117\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n",
            "[0/1][415/998]\tLoss_D: 0.0000\tLoss_G: 17.5308\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][420/998]\tLoss_D: 0.0006\tLoss_G: 18.1940\tD(x): 0.9994\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][425/998]\tLoss_D: 0.0000\tLoss_G: 18.0629\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][430/998]\tLoss_D: 0.0000\tLoss_G: 11.2385\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][435/998]\tLoss_D: 0.0000\tLoss_G: 16.0659\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][440/998]\tLoss_D: 0.0000\tLoss_G: 16.8114\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][445/998]\tLoss_D: 0.0000\tLoss_G: 17.1536\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][450/998]\tLoss_D: 0.0000\tLoss_G: 16.7790\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][455/998]\tLoss_D: 0.0000\tLoss_G: 17.8679\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][460/998]\tLoss_D: 0.0000\tLoss_G: 13.4675\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][465/998]\tLoss_D: 0.0000\tLoss_G: 14.1877\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][470/998]\tLoss_D: 0.0000\tLoss_G: 16.6839\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][475/998]\tLoss_D: 0.0000\tLoss_G: 15.2230\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][480/998]\tLoss_D: 0.0000\tLoss_G: 18.4518\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][485/998]\tLoss_D: 0.0005\tLoss_G: 7.6610\tD(x): 1.0000\tD(G(z)): 0.0005 / 0.0005\n",
            "[0/1][490/998]\tLoss_D: 0.0000\tLoss_G: 18.3638\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][495/998]\tLoss_D: 0.0000\tLoss_G: 17.4371\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][500/998]\tLoss_D: 0.0000\tLoss_G: 15.6074\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][505/998]\tLoss_D: 0.0000\tLoss_G: 15.3945\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][510/998]\tLoss_D: 0.0001\tLoss_G: 15.3010\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][515/998]\tLoss_D: 0.0000\tLoss_G: 18.0909\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][520/998]\tLoss_D: 0.0000\tLoss_G: 17.3256\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][525/998]\tLoss_D: 0.0000\tLoss_G: 18.7762\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][530/998]\tLoss_D: 0.0000\tLoss_G: 12.7123\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][535/998]\tLoss_D: 0.0000\tLoss_G: 14.5054\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][540/998]\tLoss_D: 0.0000\tLoss_G: 12.6602\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][545/998]\tLoss_D: 0.0000\tLoss_G: 14.2375\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][550/998]\tLoss_D: 0.0000\tLoss_G: 18.5365\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][555/998]\tLoss_D: 0.0000\tLoss_G: 18.7866\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][560/998]\tLoss_D: 0.0000\tLoss_G: 17.1144\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][565/998]\tLoss_D: 0.0003\tLoss_G: 8.0083\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n",
            "[0/1][570/998]\tLoss_D: 0.0000\tLoss_G: 12.8687\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][575/998]\tLoss_D: 0.0000\tLoss_G: 18.9518\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][580/998]\tLoss_D: 0.0000\tLoss_G: 13.7319\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][585/998]\tLoss_D: 0.0000\tLoss_G: 17.5851\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][590/998]\tLoss_D: 0.0000\tLoss_G: 13.0037\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][595/998]\tLoss_D: 0.0000\tLoss_G: 15.4189\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][600/998]\tLoss_D: 0.0000\tLoss_G: 12.2553\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][605/998]\tLoss_D: 0.0000\tLoss_G: 16.3530\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][610/998]\tLoss_D: 0.0000\tLoss_G: 13.0259\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][615/998]\tLoss_D: 0.0000\tLoss_G: 14.7491\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][620/998]\tLoss_D: 0.0000\tLoss_G: 13.0530\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][625/998]\tLoss_D: 0.0000\tLoss_G: 13.5847\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][630/998]\tLoss_D: 0.0000\tLoss_G: 14.4482\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][635/998]\tLoss_D: 0.0000\tLoss_G: 17.4714\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][640/998]\tLoss_D: 0.0000\tLoss_G: 13.2300\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][645/998]\tLoss_D: 0.0000\tLoss_G: 14.9362\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][650/998]\tLoss_D: 0.0000\tLoss_G: 16.7939\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][655/998]\tLoss_D: 0.0000\tLoss_G: 11.7455\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][660/998]\tLoss_D: 0.0004\tLoss_G: 7.8608\tD(x): 1.0000\tD(G(z)): 0.0004 / 0.0004\n",
            "[0/1][665/998]\tLoss_D: 0.0000\tLoss_G: 11.3040\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][670/998]\tLoss_D: 0.0000\tLoss_G: 17.6000\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][675/998]\tLoss_D: 0.0000\tLoss_G: 18.2887\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][680/998]\tLoss_D: 0.0000\tLoss_G: 16.9177\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][685/998]\tLoss_D: 0.0000\tLoss_G: 18.6077\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][690/998]\tLoss_D: 0.0000\tLoss_G: 17.9912\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][695/998]\tLoss_D: 0.0001\tLoss_G: 16.8207\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][700/998]\tLoss_D: 0.0002\tLoss_G: 17.5649\tD(x): 0.9998\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][705/998]\tLoss_D: 0.0000\tLoss_G: 10.6861\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][710/998]\tLoss_D: 0.0000\tLoss_G: 16.7324\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][715/998]\tLoss_D: 0.0000\tLoss_G: 11.3878\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][720/998]\tLoss_D: 0.0000\tLoss_G: 18.2495\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][725/998]\tLoss_D: 0.0162\tLoss_G: 18.6731\tD(x): 0.9840\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][730/998]\tLoss_D: 0.0000\tLoss_G: 13.9123\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][735/998]\tLoss_D: 0.0000\tLoss_G: 18.3408\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][740/998]\tLoss_D: 0.0000\tLoss_G: 14.6046\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][745/998]\tLoss_D: 0.0001\tLoss_G: 9.5998\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][750/998]\tLoss_D: 0.0000\tLoss_G: 15.4036\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][755/998]\tLoss_D: 0.0000\tLoss_G: 18.3623\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][760/998]\tLoss_D: 0.0000\tLoss_G: 18.9883\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][765/998]\tLoss_D: 0.0000\tLoss_G: 15.7248\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][770/998]\tLoss_D: 0.0000\tLoss_G: 17.3106\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][775/998]\tLoss_D: 0.0000\tLoss_G: 16.3185\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][780/998]\tLoss_D: 0.0009\tLoss_G: 7.0344\tD(x): 1.0000\tD(G(z)): 0.0009 / 0.0009\n",
            "[0/1][785/998]\tLoss_D: 0.0000\tLoss_G: 17.3682\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][790/998]\tLoss_D: 0.0000\tLoss_G: 17.3868\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][795/998]\tLoss_D: 0.0000\tLoss_G: 15.4472\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][800/998]\tLoss_D: 0.0001\tLoss_G: 16.6102\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][805/998]\tLoss_D: 0.0000\tLoss_G: 17.0321\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][810/998]\tLoss_D: 0.0006\tLoss_G: 7.4909\tD(x): 1.0000\tD(G(z)): 0.0006 / 0.0006\n",
            "[0/1][815/998]\tLoss_D: 0.0000\tLoss_G: 14.4520\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][820/998]\tLoss_D: 0.0000\tLoss_G: 17.5596\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][825/998]\tLoss_D: 0.0000\tLoss_G: 10.8432\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][830/998]\tLoss_D: 0.0001\tLoss_G: 9.0806\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][835/998]\tLoss_D: 0.0000\tLoss_G: 10.1539\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][840/998]\tLoss_D: 0.0000\tLoss_G: 11.5764\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][845/998]\tLoss_D: 0.0005\tLoss_G: 7.5930\tD(x): 1.0000\tD(G(z)): 0.0005 / 0.0005\n",
            "[0/1][850/998]\tLoss_D: 0.0000\tLoss_G: 13.3246\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][855/998]\tLoss_D: 0.0003\tLoss_G: 8.2596\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n",
            "[0/1][860/998]\tLoss_D: 0.0000\tLoss_G: 17.3466\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][865/998]\tLoss_D: 0.0005\tLoss_G: 7.5777\tD(x): 1.0000\tD(G(z)): 0.0005 / 0.0005\n",
            "[0/1][870/998]\tLoss_D: 0.0000\tLoss_G: 10.3525\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][875/998]\tLoss_D: 0.0000\tLoss_G: 11.7693\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][880/998]\tLoss_D: 0.0007\tLoss_G: 7.2430\tD(x): 1.0000\tD(G(z)): 0.0007 / 0.0007\n",
            "[0/1][885/998]\tLoss_D: 0.0000\tLoss_G: 11.7187\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][890/998]\tLoss_D: 0.0000\tLoss_G: 17.3352\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][895/998]\tLoss_D: 0.0000\tLoss_G: 18.0856\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][900/998]\tLoss_D: 0.0000\tLoss_G: 16.0429\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][905/998]\tLoss_D: 0.0000\tLoss_G: 16.7276\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][910/998]\tLoss_D: 0.0000\tLoss_G: 15.8627\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][915/998]\tLoss_D: 0.0001\tLoss_G: 8.9003\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][920/998]\tLoss_D: 0.0000\tLoss_G: 19.1690\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][925/998]\tLoss_D: 0.0000\tLoss_G: 15.4561\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][930/998]\tLoss_D: 0.0006\tLoss_G: 7.3907\tD(x): 1.0000\tD(G(z)): 0.0006 / 0.0006\n",
            "[0/1][935/998]\tLoss_D: 0.0000\tLoss_G: 18.8136\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][940/998]\tLoss_D: 0.0000\tLoss_G: 17.3265\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][945/998]\tLoss_D: 0.0000\tLoss_G: 11.4197\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][950/998]\tLoss_D: 0.0001\tLoss_G: 9.1731\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][955/998]\tLoss_D: 0.0000\tLoss_G: 15.1983\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][960/998]\tLoss_D: 0.0002\tLoss_G: 8.6984\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n",
            "[0/1][965/998]\tLoss_D: 0.0000\tLoss_G: 10.3417\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][970/998]\tLoss_D: 0.0000\tLoss_G: 17.0625\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][975/998]\tLoss_D: 0.0001\tLoss_G: 9.3770\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
            "[0/1][980/998]\tLoss_D: 0.0002\tLoss_G: 8.4969\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n",
            "[0/1][985/998]\tLoss_D: 0.0000\tLoss_G: 17.1204\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][990/998]\tLoss_D: 0.0000\tLoss_G: 12.7806\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n",
            "[0/1][995/998]\tLoss_D: 0.0000\tLoss_G: 17.4593\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n"
          ]
        }
      ]
    }
  ]
}
