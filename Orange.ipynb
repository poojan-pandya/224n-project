{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Cd2zRw0vmYrxM4m0NKORJ3Bmlii4COaY","timestamp":1679188040804},{"file_id":"1RZzlzBJW5PHbrD96lZfq-lb4aMVIJ3pB","timestamp":1679127966258}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02d7de766c5e4fb3883103a2d39ade7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b00ea26c933642c095bb455ac411abd7","IPY_MODEL_8bcb56ea7b7b4fea9049cfe127794449","IPY_MODEL_d8b2206beb1e4743bfb4fe6c66720525"],"layout":"IPY_MODEL_aa1ab84a36034f9abffcaaf3a7375709"}},"b00ea26c933642c095bb455ac411abd7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a13289645b4c0ab51a9f59557c32d4","placeholder":"​","style":"IPY_MODEL_1916547783564f0e85ee1eca221257e8","value":"Downloading pytorch_model.bin: 100%"}},"8bcb56ea7b7b4fea9049cfe127794449":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a969116d3e241ee880684a1d57dc562","max":539679413,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3bfae8c075e4f1e9d8e2f2f239c09a1","value":539679413}},"d8b2206beb1e4743bfb4fe6c66720525":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0c05c42a2594559bb9c4765e1ed34e2","placeholder":"​","style":"IPY_MODEL_2eecc9992ca841ba89fcb8389463eb15","value":" 540M/540M [00:10&lt;00:00, 56.3MB/s]"}},"aa1ab84a36034f9abffcaaf3a7375709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6a13289645b4c0ab51a9f59557c32d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1916547783564f0e85ee1eca221257e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a969116d3e241ee880684a1d57dc562":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3bfae8c075e4f1e9d8e2f2f239c09a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0c05c42a2594559bb9c4765e1ed34e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eecc9992ca841ba89fcb8389463eb15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d45de190b265473c9869c28793255cd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1914261ed8a443d2b20ba9d178d2d7cf","IPY_MODEL_37e8b72afbdf453eb7150320da2b5cee","IPY_MODEL_034ec43f9c1b45de853ed620a285f7da"],"layout":"IPY_MODEL_7ea513146f154426948fe891cd44f5ee"}},"1914261ed8a443d2b20ba9d178d2d7cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c757b9d0e3845cda6337afa2053ce04","placeholder":"​","style":"IPY_MODEL_db917a798d1141808db62fda8cf9838a","value":"Downloading (…)okenizer_config.json: 100%"}},"37e8b72afbdf453eb7150320da2b5cee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10b04c3491a54973ab4bee095e8aee25","max":338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5dd7c20b8fa40ec899e4ce7ed38032c","value":338}},"034ec43f9c1b45de853ed620a285f7da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_311c5d80db7843e78c19ae1d1042271d","placeholder":"​","style":"IPY_MODEL_235fae26c4b6494c8b26568a6f01d371","value":" 338/338 [00:00&lt;00:00, 16.3kB/s]"}},"7ea513146f154426948fe891cd44f5ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c757b9d0e3845cda6337afa2053ce04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db917a798d1141808db62fda8cf9838a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10b04c3491a54973ab4bee095e8aee25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5dd7c20b8fa40ec899e4ce7ed38032c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"311c5d80db7843e78c19ae1d1042271d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"235fae26c4b6494c8b26568a6f01d371":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e99ad772acd34a48807d1d278f732569":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbfd67cbe51b4357a38251337f3e865d","IPY_MODEL_56e764f8a93246f399e71bca171090c8","IPY_MODEL_3f7aa8ec9a2346b29f01cd5d05d106e3"],"layout":"IPY_MODEL_af416d485ba541d79d6adb2843d47b37"}},"fbfd67cbe51b4357a38251337f3e865d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4673ea1e32da4ea1a85c14c353157963","placeholder":"​","style":"IPY_MODEL_525f7da857884bd0b7b801d8a5ebf820","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"56e764f8a93246f399e71bca171090c8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a37dd763bd754cf4b0380207ec418727","max":843438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f2bf3afc6a24364a3cf82b8ff0e952c","value":843438}},"3f7aa8ec9a2346b29f01cd5d05d106e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf10b420571a429198f25ae3232c237e","placeholder":"​","style":"IPY_MODEL_754335f5c9f74aba95f97339ac3b959b","value":" 843k/843k [00:00&lt;00:00, 5.77MB/s]"}},"af416d485ba541d79d6adb2843d47b37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4673ea1e32da4ea1a85c14c353157963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"525f7da857884bd0b7b801d8a5ebf820":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a37dd763bd754cf4b0380207ec418727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f2bf3afc6a24364a3cf82b8ff0e952c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf10b420571a429198f25ae3232c237e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"754335f5c9f74aba95f97339ac3b959b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c20cb5652d174439afdfa3a449c56c2c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98b704ebbdbb43b2a75e25514372af4e","IPY_MODEL_876856942f57467d8544c255952045e5","IPY_MODEL_309a571af043410494d5835bac9e29f1"],"layout":"IPY_MODEL_c9905ba79cc44b038ea2ded92afa5ae0"}},"98b704ebbdbb43b2a75e25514372af4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1542591d4a6a43fda8d7fcd78f7423fc","placeholder":"​","style":"IPY_MODEL_7699530e28dc4541a33dbcfdc9089b91","value":"Downloading (…)solve/main/bpe.codes: 100%"}},"876856942f57467d8544c255952045e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55303dd742f8405daef149f9bc2ac136","max":1078931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f07c046c2b884523bbc02a7d26ec930d","value":1078931}},"309a571af043410494d5835bac9e29f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fc0d4c60d3d44fcb02c66e12be7ad8a","placeholder":"​","style":"IPY_MODEL_65f4b97324c845e5a00f08d5e4a86d98","value":" 1.08M/1.08M [00:00&lt;00:00, 6.43MB/s]"}},"c9905ba79cc44b038ea2ded92afa5ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1542591d4a6a43fda8d7fcd78f7423fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7699530e28dc4541a33dbcfdc9089b91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55303dd742f8405daef149f9bc2ac136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f07c046c2b884523bbc02a7d26ec930d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4fc0d4c60d3d44fcb02c66e12be7ad8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65f4b97324c845e5a00f08d5e4a86d98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"778ce8c8cfcc4910aa3701af28499f90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e840e652a46d48e9b62fbd5052d2508d","IPY_MODEL_c0593e59dde243318480d387b61c7baa","IPY_MODEL_7623306a78d74a49a52ffbc2f8f3fa35"],"layout":"IPY_MODEL_7b131417a9924d63a653eb269820802e"}},"e840e652a46d48e9b62fbd5052d2508d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1fdc8a3cd8443585e31a768ac4d132","placeholder":"​","style":"IPY_MODEL_9bc803bb18b34fa68128e55c277724b4","value":"Downloading (…)in/added_tokens.json: 100%"}},"c0593e59dde243318480d387b61c7baa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13e6db770859438a916b74519750760d","max":22,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fae6f0c475994ed282a436a59447d09d","value":22}},"7623306a78d74a49a52ffbc2f8f3fa35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dd7502695ec43fa965bdb10aea1e89c","placeholder":"​","style":"IPY_MODEL_b2c40897bff54044b5e06aa58f27981d","value":" 22.0/22.0 [00:00&lt;00:00, 934B/s]"}},"7b131417a9924d63a653eb269820802e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1fdc8a3cd8443585e31a768ac4d132":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc803bb18b34fa68128e55c277724b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13e6db770859438a916b74519750760d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae6f0c475994ed282a436a59447d09d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dd7502695ec43fa965bdb10aea1e89c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2c40897bff54044b5e06aa58f27981d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40d85e7e641444fa9cff7f3059ec77a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_297193371acb467eb70f64763fa5b503","IPY_MODEL_45ddfd018c8e4681ba881743be5bb3af","IPY_MODEL_a683ec3cfa974ff1a95d1c20029a5148"],"layout":"IPY_MODEL_652a98d0cadd47fdbe63c6ad8f747034"}},"297193371acb467eb70f64763fa5b503":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_797952794a9243e2abe940cdeba6ef68","placeholder":"​","style":"IPY_MODEL_2b6893ba6ab347efb6461137b6a98475","value":"Downloading (…)cial_tokens_map.json: 100%"}},"45ddfd018c8e4681ba881743be5bb3af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78e374e901964f85822ccec256083797","max":167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1dba09f031845f58713ea0c5ac7857a","value":167}},"a683ec3cfa974ff1a95d1c20029a5148":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87eb8a5810d94daab89a4c7ebf9d7fdf","placeholder":"​","style":"IPY_MODEL_8d05460775a94aaf8a614e5140f248f3","value":" 167/167 [00:00&lt;00:00, 8.39kB/s]"}},"652a98d0cadd47fdbe63c6ad8f747034":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"797952794a9243e2abe940cdeba6ef68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b6893ba6ab347efb6461137b6a98475":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78e374e901964f85822ccec256083797":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1dba09f031845f58713ea0c5ac7857a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87eb8a5810d94daab89a4c7ebf9d7fdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d05460775a94aaf8a614e5140f248f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddd89fbd501a4477ac5dbe764013ff96":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba744dc9256a4669acebd5be6aac8d20","IPY_MODEL_ab15fef153744566a84beb3787b2fa99","IPY_MODEL_00716c6c208846edb865b61df059bdf7"],"layout":"IPY_MODEL_2ac23b36668c4583bee90b286b1ba2d5"}},"ba744dc9256a4669acebd5be6aac8d20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8e26d39109c4225bf8b9ea37cec66c6","placeholder":"​","style":"IPY_MODEL_b446411335a74aa099a9410922618178","value":"Map: 100%"}},"ab15fef153744566a84beb3787b2fa99":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_53e8434f5c504f369307e541c1928adc","max":81614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16984811c698464ca7c26ca6b8c16cc6","value":81614}},"00716c6c208846edb865b61df059bdf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_137110c943ea41489701eee13728e454","placeholder":"​","style":"IPY_MODEL_474d934c443343578b21a6b3f220b530","value":" 81614/81614 [03:38&lt;00:00, 390.80 examples/s]"}},"2ac23b36668c4583bee90b286b1ba2d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"e8e26d39109c4225bf8b9ea37cec66c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b446411335a74aa099a9410922618178":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53e8434f5c504f369307e541c1928adc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16984811c698464ca7c26ca6b8c16cc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"137110c943ea41489701eee13728e454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"474d934c443343578b21a6b3f220b530":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f789fb365894c9cb2792e127854b51d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbf84b12ea8f458d9558479031303313","IPY_MODEL_8d77504898e348109ba5731104c1908f","IPY_MODEL_fd25419898d8427a9260e4a7a88d2874"],"layout":"IPY_MODEL_56c87483ccc64c4cb9d45641a7e44c8f"}},"bbf84b12ea8f458d9558479031303313":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a388c60c8945938c360cff6507b648","placeholder":"​","style":"IPY_MODEL_a744f1ca925947ce9e19d77feab0e1cc","value":"Map: 100%"}},"8d77504898e348109ba5731104c1908f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b16c6acf0cc4e8eab7671eaeb66e914","max":998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_648e22cd8a3f4d3ebed4d58af701cf1f","value":998}},"fd25419898d8427a9260e4a7a88d2874":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_039c4d98857c4251bd85c9551233b64d","placeholder":"​","style":"IPY_MODEL_ee22bae4570d48b7a6c4cd5f70faa63f","value":" 998/998 [00:02&lt;00:00, 440.96 examples/s]"}},"56c87483ccc64c4cb9d45641a7e44c8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"04a388c60c8945938c360cff6507b648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a744f1ca925947ce9e19d77feab0e1cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b16c6acf0cc4e8eab7671eaeb66e914":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"648e22cd8a3f4d3ebed4d58af701cf1f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"039c4d98857c4251bd85c9551233b64d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee22bae4570d48b7a6c4cd5f70faa63f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### GAN Attempt!"],"metadata":{"id":"l2vionRRzF_O"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JADRaL5b276C","executionInfo":{"status":"ok","timestamp":1679264394660,"user_tz":300,"elapsed":32375,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"87fabb2a-d81a-496d-b9bb-164c397b67af"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Setup\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n","    AutoModel,\n",")\n","import pandas as pd\n","from datasets import Dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ESRs9D8S2gd3","executionInfo":{"status":"ok","timestamp":1679264401170,"user_tz":300,"elapsed":6515,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","%cd drive/MyDrive/CS\\ 224N/CS\\ 224N\\ Project\n","%ls # verify that you are in the right directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txGRbtkd4IWq","executionInfo":{"status":"ok","timestamp":1679264433214,"user_tz":300,"elapsed":3341,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"4fa6ac19-5417-4f4b-d94c-e8706b265f73"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1x7bmzM_qtbj3CPKzenuwvwocK9KiZzWU/CS 224N Project\n","'224N Experiments (GAN on 998 Samples).gsheet'\n","'224N Project Brainstorm.gdoc'\n","\u001b[0m\u001b[01;36m'224N Project Helpful Tutorials.gdoc'\u001b[0m@\n","'224N Project Milestone Notes.gdoc'\n"," Adversarial-T5_Structure_1.ipynb\n"," aita_clean.csv\n"," aita_comments.csv\n"," aita_test_set.csv\n"," aita_test_set.gsheet\n"," aita_train_set.csv\n"," aita_valid_set.csv\n"," \u001b[01;34mbanana\u001b[0m/\n"," banana.ipynb\n"," \u001b[01;34mbart-base-checkpoint-204000\u001b[0m/\n"," bart-baseline-attempt2.ipynb\n"," \u001b[01;34mbart-checkpoint-5000\u001b[0m/\n"," bert-baseline.ipynb\n"," \u001b[01;34mblueberry\u001b[0m/\n"," blueberry.ipynb\n"," checkpoint.txt\n"," config.json\n"," \u001b[01;34mcsvs\u001b[0m/\n"," dataset_agg.ipynb\n"," \u001b[01;34mdrive\u001b[0m/\n"," Evaluate.ipynb\n","'experimenting with gumbel.ipynb'\n"," \u001b[01;34mfinetune-gpt2\u001b[0m/\n","\u001b[01;34m'first proposal OLD'\u001b[0m/\n"," gan-gen-trial\n"," gan-halfway-gen-transformer-d\n"," gpt-2-attempt2.ipynb\n"," gpt2-attempt3.ipynb\n"," gpt2-baseline.ipynb\n"," \u001b[01;34mgpt2-small-rationale-generation\u001b[0m/\n"," gpt2-wt-5.ipynb\n"," \u001b[01;34mgrape\u001b[0m/\n"," grape-exploration.ipynb\n"," grape.ipynb\n"," \u001b[01;34mhoneydew\u001b[0m/\n"," honeydew.ipynb\n"," \u001b[01;34mlogs\u001b[0m/\n"," Mango.ipynb\n"," \u001b[01;34mmango-old\u001b[0m/\n"," orange-halfway\n"," Orange.ipynb\n"," orange-trial\n","'Pear (1).ipynb'\n"," Pear.ipynb\n"," \u001b[01;34mpineapple\u001b[0m/\n"," Pineapple.ipynb\n"," \u001b[01;34mpineapple-old\u001b[0m/\n"," \u001b[01;34mprocessed-set-gpt2\u001b[0m/\n","'Reddit Scraper.ipynb'\n"," \u001b[01;34mresults\u001b[0m/\n"," rouge_scores_baseline.txt\n"," rouge_scores.txt\n","\u001b[01;34m'screenshots bart'\u001b[0m/\n","\u001b[01;34m'screenshots t5'\u001b[0m/\n"," T5_Attempt_2.ipynb\n"," t5_attempt3.ipynb\n"," T5-baseline.ipynb\n"," \u001b[01;34mwandb\u001b[0m/\n"," wmd_scores_baseline.txt\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define the generator (use the pre-trained BART implementation)\n","\"\"\"\n","\n","# bart-base checkpoint pre-trained on our dataset\n","# (can also try generically pre-trained bart base)\n","model_dir = 'bart-base-checkpoint-204000'\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","print(netG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RgiUTBezH2V","executionInfo":{"status":"ok","timestamp":1679264444016,"user_tz":300,"elapsed":10804,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"40e72e3a-7b56-4c74-a2f3-cb8f4fdff90b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","sentiment = pipeline(model='finiteautomata/bertweet-base-sentiment-analysis')\n","#sentiment = AutoModel.from_pretrained('finiteautomata/bertweet-base-sentiment-analysis')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":227,"referenced_widgets":["02d7de766c5e4fb3883103a2d39ade7a","b00ea26c933642c095bb455ac411abd7","8bcb56ea7b7b4fea9049cfe127794449","d8b2206beb1e4743bfb4fe6c66720525","aa1ab84a36034f9abffcaaf3a7375709","f6a13289645b4c0ab51a9f59557c32d4","1916547783564f0e85ee1eca221257e8","4a969116d3e241ee880684a1d57dc562","b3bfae8c075e4f1e9d8e2f2f239c09a1","c0c05c42a2594559bb9c4765e1ed34e2","2eecc9992ca841ba89fcb8389463eb15","d45de190b265473c9869c28793255cd7","1914261ed8a443d2b20ba9d178d2d7cf","37e8b72afbdf453eb7150320da2b5cee","034ec43f9c1b45de853ed620a285f7da","7ea513146f154426948fe891cd44f5ee","0c757b9d0e3845cda6337afa2053ce04","db917a798d1141808db62fda8cf9838a","10b04c3491a54973ab4bee095e8aee25","c5dd7c20b8fa40ec899e4ce7ed38032c","311c5d80db7843e78c19ae1d1042271d","235fae26c4b6494c8b26568a6f01d371","e99ad772acd34a48807d1d278f732569","fbfd67cbe51b4357a38251337f3e865d","56e764f8a93246f399e71bca171090c8","3f7aa8ec9a2346b29f01cd5d05d106e3","af416d485ba541d79d6adb2843d47b37","4673ea1e32da4ea1a85c14c353157963","525f7da857884bd0b7b801d8a5ebf820","a37dd763bd754cf4b0380207ec418727","1f2bf3afc6a24364a3cf82b8ff0e952c","bf10b420571a429198f25ae3232c237e","754335f5c9f74aba95f97339ac3b959b","c20cb5652d174439afdfa3a449c56c2c","98b704ebbdbb43b2a75e25514372af4e","876856942f57467d8544c255952045e5","309a571af043410494d5835bac9e29f1","c9905ba79cc44b038ea2ded92afa5ae0","1542591d4a6a43fda8d7fcd78f7423fc","7699530e28dc4541a33dbcfdc9089b91","55303dd742f8405daef149f9bc2ac136","f07c046c2b884523bbc02a7d26ec930d","4fc0d4c60d3d44fcb02c66e12be7ad8a","65f4b97324c845e5a00f08d5e4a86d98","778ce8c8cfcc4910aa3701af28499f90","e840e652a46d48e9b62fbd5052d2508d","c0593e59dde243318480d387b61c7baa","7623306a78d74a49a52ffbc2f8f3fa35","7b131417a9924d63a653eb269820802e","4e1fdc8a3cd8443585e31a768ac4d132","9bc803bb18b34fa68128e55c277724b4","13e6db770859438a916b74519750760d","fae6f0c475994ed282a436a59447d09d","7dd7502695ec43fa965bdb10aea1e89c","b2c40897bff54044b5e06aa58f27981d","40d85e7e641444fa9cff7f3059ec77a9","297193371acb467eb70f64763fa5b503","45ddfd018c8e4681ba881743be5bb3af","a683ec3cfa974ff1a95d1c20029a5148","652a98d0cadd47fdbe63c6ad8f747034","797952794a9243e2abe940cdeba6ef68","2b6893ba6ab347efb6461137b6a98475","78e374e901964f85822ccec256083797","f1dba09f031845f58713ea0c5ac7857a","87eb8a5810d94daab89a4c7ebf9d7fdf","8d05460775a94aaf8a614e5140f248f3"]},"id":"pjnWlqrx5JgS","executionInfo":{"status":"ok","timestamp":1679264511434,"user_tz":300,"elapsed":15204,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"4a7ff62a-943d-46bc-fa36-5bedccf2c55b"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02d7de766c5e4fb3883103a2d39ade7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d45de190b265473c9869c28793255cd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e99ad772acd34a48807d1d278f732569"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c20cb5652d174439afdfa3a449c56c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778ce8c8cfcc4910aa3701af28499f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d85e7e641444fa9cff7f3059ec77a9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define transformer discriminator\n","\"\"\"\n","\n","nc = 1\n","ndf = 64\n","\n","# class Discriminator(nn.Module):\n","#     def __init__(self, ngpu):\n","#         super(Discriminator, self).__init__()\n","#         self.ngpu = ngpu\n","#         self.main = nn.Sequential(\n","#             #Reshaping input\n","#             nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 64 --> 1, 1, 64, 64\n","#             # input is (nc) x 64 x 64 | our input is 1 x 64\n","#             nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf) x 32 x 32\n","#             nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","#             nn.BatchNorm2d(ndf * 2),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf*2) x 16 x 16\n","#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","#             nn.BatchNorm2d(ndf * 4),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf*4) x 8 x 8\n","#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","#             nn.BatchNorm2d(ndf * 8),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf*8) x 4 x 4\n","#             nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","#             nn.Sigmoid()\n","#         )\n","\n","#     def forward(self, input):\n","#         #print(len(input.shape))\n","#         return self.main(input)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        \n","        # Transformer Encoder\n","        self.upsample = nn.Upsample(size=(64))\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(64, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        #input shape: (batch_size, seq_len, d_model)\n","        upsampled_input = self.upsample(input)\n","        transformer_output = self.transformer_encoder(upsampled_input) \n","        discriminator_output = self.classifier(transformer_output.mean(dim=1)) #(batch_size, 1)\n","        \n","        return discriminator_output\n"],"metadata":{"id":"XBPd1v0Q34Jn","executionInfo":{"status":"ok","timestamp":1679264514022,"user_tz":300,"elapsed":96,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ngpu = 1\n","netD = Discriminator(ngpu).to(device)\n","\n","# d_model_dir = \"siebert/sentiment-roberta-large-english\"\n","# netD = AutoModelForSequenceClassification.from_pretrained(model_dir)\n","\n","#netD =   #AutoModel.from_pretrained(\"vinai/bertweet-base\")"],"metadata":{"id":"F4fElnOc_aAR","executionInfo":{"status":"ok","timestamp":1679264522174,"user_tz":300,"elapsed":7431,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Loss functions and optimizers\n","\"\"\"\n","# Size of generator input\n","nz = 512\n","# Optim params\n","lr = 0.0002\n","beta1 = 0.5\n","\n","# Initialize BCELoss function\n","criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"mLLWvDY-7M96","executionInfo":{"status":"ok","timestamp":1679264522174,"user_tz":300,"elapsed":3,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA0gynyNom7B","executionInfo":{"status":"ok","timestamp":1679264527383,"user_tz":300,"elapsed":5211,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"source":["train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n","valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n","test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["valid_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"sjEVc6pTBJpI","executionInfo":{"status":"ok","timestamp":1679264527384,"user_tz":300,"elapsed":5,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"1b53d277-59a5-4018-814d-2c8bfdfdef95"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  text  \\\n","0    AITA for insisting on a refund?. I'm genuinely...   \n","1    AITA for telling her that her boyfriend creeps...   \n","2    AITA for making my son do an exercise routine ...   \n","3    AITA for disagreeing with a friend that making...   \n","4    WIBTA if I message an employer about why I did...   \n","..                                                 ...   \n","993  WIBTA if I expose antivaxxers?. Back story: my...   \n","994  WIBTA if I took my mini-fridge from my roommat...   \n","995  WIBTA if i \"snitch\" on my half sister to my pa...   \n","996  AITA for not wanting to live with my roommate ...   \n","997  AITA for refusing to taste my wife’s food beca...   \n","\n","                                              comments  \n","0    YTA. Why all this needless drama and attention...  \n","1    YTA. You tried to kiss her, she wasn't interes...  \n","2    Why don't you do things with him? Instead of i...  \n","3    It wasn't really an \"announcement,\" everybody ...  \n","4    YTA \\n\\nDO NOT DO THIS. Do not cross the strea...  \n","..                                                 ...  \n","993  NTA - I would say you're an asshole if you did...  \n","994  NTA, but this is largely your fault too. Who c...  \n","995  NTA whatever her motivation for crying to her ...  \n","996  NTA. The lease was up; it wasn’t as if you wer...  \n","997  NTA - one of the most basic parts of food safe...  \n","\n","[998 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-1baa27fb-6a47-4ed4-ae43-b4746b6926dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>comments</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AITA for insisting on a refund?. I'm genuinely...</td>\n","      <td>YTA. Why all this needless drama and attention...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AITA for telling her that her boyfriend creeps...</td>\n","      <td>YTA. You tried to kiss her, she wasn't interes...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AITA for making my son do an exercise routine ...</td>\n","      <td>Why don't you do things with him? Instead of i...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AITA for disagreeing with a friend that making...</td>\n","      <td>It wasn't really an \"announcement,\" everybody ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>WIBTA if I message an employer about why I did...</td>\n","      <td>YTA \\n\\nDO NOT DO THIS. Do not cross the strea...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>993</th>\n","      <td>WIBTA if I expose antivaxxers?. Back story: my...</td>\n","      <td>NTA - I would say you're an asshole if you did...</td>\n","    </tr>\n","    <tr>\n","      <th>994</th>\n","      <td>WIBTA if I took my mini-fridge from my roommat...</td>\n","      <td>NTA, but this is largely your fault too. Who c...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>WIBTA if i \"snitch\" on my half sister to my pa...</td>\n","      <td>NTA whatever her motivation for crying to her ...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>AITA for not wanting to live with my roommate ...</td>\n","      <td>NTA. The lease was up; it wasn’t as if you wer...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>AITA for refusing to taste my wife’s food beca...</td>\n","      <td>NTA - one of the most basic parts of food safe...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>998 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1baa27fb-6a47-4ed4-ae43-b4746b6926dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1baa27fb-6a47-4ed4-ae43-b4746b6926dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1baa27fb-6a47-4ed4-ae43-b4746b6926dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["train_data_txt = Dataset.from_pandas(train_df)\n","validation_data_txt = Dataset.from_pandas(valid_df)\n","test_data_txt = Dataset.from_pandas(test_df)\n","print(train_data_txt)\n","print(validation_data_txt)\n","print(test_data_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf4cgIQL9uCA","executionInfo":{"status":"ok","timestamp":1679264527870,"user_tz":300,"elapsed":490,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"fbf24669-38b7-4408-e81c-ae88d423d917"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 81614\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Preprocess\n","\"\"\"\n","\n","encoder_max_length = 256  # changed from 256\n","decoder_max_length = 64  # changed from 64\n","\n","def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"comments\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["ddd89fbd501a4477ac5dbe764013ff96","ba744dc9256a4669acebd5be6aac8d20","ab15fef153744566a84beb3787b2fa99","00716c6c208846edb865b61df059bdf7","2ac23b36668c4583bee90b286b1ba2d5","e8e26d39109c4225bf8b9ea37cec66c6","b446411335a74aa099a9410922618178","53e8434f5c504f369307e541c1928adc","16984811c698464ca7c26ca6b8c16cc6","137110c943ea41489701eee13728e454","474d934c443343578b21a6b3f220b530","8f789fb365894c9cb2792e127854b51d","bbf84b12ea8f458d9558479031303313","8d77504898e348109ba5731104c1908f","fd25419898d8427a9260e4a7a88d2874","56c87483ccc64c4cb9d45641a7e44c8f","04a388c60c8945938c360cff6507b648","a744f1ca925947ce9e19d77feab0e1cc","0b16c6acf0cc4e8eab7671eaeb66e914","648e22cd8a3f4d3ebed4d58af701cf1f","039c4d98857c4251bd85c9551233b64d","ee22bae4570d48b7a6c4cd5f70faa63f"]},"id":"wvBpN-KNAJ4x","executionInfo":{"status":"ok","timestamp":1679264749048,"user_tz":300,"elapsed":221181,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"f228ffb2-17ac-4760-b5e5-3542ee9d699b"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/81614 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd89fbd501a4477ac5dbe764013ff96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/998 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f789fb365894c9cb2792e127854b51d"}},"metadata":{}}]},{"cell_type":"code","source":["print(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRueMmaYFamD","executionInfo":{"status":"ok","timestamp":1679264749048,"user_tz":300,"elapsed":8,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"125920b5-5ea6-4d5c-d5a9-785ed1060520"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 81614\n","})\n"]}]},{"cell_type":"code","source":["print(train_data[0]['input_ids'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N1k0GllyERDa","executionInfo":{"status":"ok","timestamp":1679264749048,"user_tz":300,"elapsed":7,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"9043c515-316a-4e49-d7b2-d1a246e5bf9f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 250, 2068, 250, 13, 45, 2405, 964, 19, 5, 1816, 54, 12961, 162, 116, 4, 28106, 4384, 6, 142, 127, 1441, 333, 70, 216, 127, 44014, 1316, 36, 9226, 40, 146, 1472, 423, 322, 1437, 50118, 50118, 100, 348, 57, 4927, 10, 1816, 38, 348, 57, 964, 19, 187, 127, 3812, 76, 9, 239, 334, 4, 166, 348, 4925, 5, 276, 333, 9, 7628, 964, 187, 172, 36, 1694, 32, 70, 7195, 11, 1564, 122, 322, 166, 214, 70, 1256, 3229, 29716, 4, 50118, 50118, 10462, 6, 79, 12961, 162, 682, 4319, 69, 2188, 25, 145, 274, 3765, 673, 36, 506, 4352, 9, 1716, 66, 43, 77, 24, 606, 7, 5, 4927, 1310, 6, 941, 187, 52, 32, 70, 98, 664, 4, 1437, 50118, 50118, 100, 399, 75, 269, 7684, 69, 13, 24, 6, 142, 14, 18, 10, 8134, 1219, 8, 38, 399, 75, 206, 1169, 9, 201, 58, 27744, 10, 1473, 499, 561, 6, 23, 513, 45, 648, 4, 125, 38, 21, 6, 8, 202, 524, 6, 5278, 15418, 13, 42, 1816, 8, 38, 802, 24, 74, 28, 275, 114, 52, 2442, 45, 964, 4, 1437, 50118, 50118, 1779, 38, 174, 69, 42, 6, 79, 300, 10, 410, 828, 2465, 4, 767, 7, 69, 6, 38, 21, 145, 31338, 8, 22, 20391, 6234, 69, 113, 13, 6923, 7, 33, 92, 3734, 4, 38, 23215, 14, 9, 768, 38, 938, 75, 608, 14, 6, 38, 1622, 1705, 75, 3679, 10, 25063, 9330, 576, 141, 38, 1299, 13, 69, 4, 50118, 50118, 2409, 172, 79, 2]\n"]}]},{"cell_type":"code","source":["print(len(train_data[0]['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVc3xgHXFdk4","executionInfo":{"status":"ok","timestamp":1679264749049,"user_tz":300,"elapsed":6,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"outputId":"bbae9975-cdd8-46d7-9218-023f501abb9c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["256\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lZSaCnDjBk-x","executionInfo":{"status":"aborted","timestamp":1679264453045,"user_tz":300,"elapsed":8,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sentiment_tokens(comment):\n","  max_input_length = 128\n","  if len(comment) > 128:\n","    comment = comment[:128]\n","  comment_sentiment = sentiment([comment])[0]\n","  comment_sentiment = comment_sentiment['label'] + ': ' + str(comment_sentiment['score'])\n","  comment_sentiment_tokens = tokenizer(comment_sentiment, max_length=128, padding='max_length', truncation=True, return_tensors=\"pt\")\n","  return comment_sentiment_tokens['input_ids'].tolist()"],"metadata":{"id":"61IkvNKB9QaT","executionInfo":{"status":"ok","timestamp":1679264749049,"user_tz":300,"elapsed":4,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["fixed_validation_index = 17\n","fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n","fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"aYSn2PZcA4Pa","executionInfo":{"status":"ok","timestamp":1679264749146,"user_tz":300,"elapsed":101,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["batch_size=4\n","dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","                                         shuffle=True)\n","for i, data in enumerate(dataloader, 0):\n","  print(torch.stack(data['attention_mask']).shape)\n","  break\n"],"metadata":{"id":"OTM_7TRDEuwr","executionInfo":{"status":"ok","timestamp":1679264749146,"user_tz":300,"elapsed":4,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba21188a-1f90-4985-fea8-b451f01b2d81"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 4])\n"]}]},{"cell_type":"code","source":["# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# # num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i, data in enumerate(dataloader, 0):\n","#         #data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         #print(data)\n","#         print(data['labels'])\n","#         real_cpu = torch.stack(data['labels'])\n","#         #real_cpu = torch.unsqueeze(real_cpu, dim=0)\n","#         #real_cpu = torch.cat(real_cpu, dim=0)\n","#         #real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.type(torch.FloatTensor).view(-1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         #inputs = train_df.iloc[i]['text']\n","#         #data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         data = {k : torch.stack(v) for k, v in data.items()}\n","#         fake = netG(**data)\n","\n","#         # fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"kpQNOHLX7dL_","executionInfo":{"status":"ok","timestamp":1679264749147,"user_tz":300,"elapsed":3,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["################ Changing the working data to validation ####################\n","\n","# Training Loop\n","\n","# Lists to keep track of progress\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","num_epochs = 1\n","max_input_length = 512\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # todo: batch this/use a dataloader\n","    for i in range(len(validation_data)):\n","        data = validation_data[i]\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        netD.zero_grad()\n","        # Format batch\n","        #print(len(data['labels']))\n","\n","        sentiment_tokens = get_sentiment_tokens(str(valid_df.iloc[i]['comments']))\n","        #print(data['labels'])\n","        #print(sentiment_tokens[0])\n","        real_cpu = torch.tensor(data['labels'] + sentiment_tokens[0], dtype=torch.float32)\n","        #real_cpu = data['labels']\n","        #print(real_cpu.shape)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        #print(real_cpu.shape)\n","        real_cpu = real_cpu.view(1, 1, 64 + 128) #these are the comment tokens\n","        #print(real_cpu.shape)\n","        #print(real_cpu.shape)\n","        real_cpu = real_cpu.to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","        #discriminator will train off of true comments in the real batch pass\n","        # Forward pass real batch through D\n","        output = netD(real_cpu).view(-1) \n","        # Calculate loss on all-real batch\n","        errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        # print(inputs['input_ids'].shape)\n","        # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","        # Generate fake image batch with G\n","\n","        inputs = valid_df.iloc[i]['text']\n","        data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","        decoded_fake_comment = tokenizer.batch_decode(fake, skip_special_tokens=True)\n","        sentiment_tokens = get_sentiment_tokens(decoded_fake_comment[0])\n","        #print(decoded_fake_comment[0])\n","        #print(type(decoded_fake_comment[0]))\n","        #print(type(sentiment(decoded_fake_comment[0])[0]))\n","        #print(sentiment_tokens[0])\n","        inp_tensor = torch.tensor(sentiment_tokens[0], dtype=torch.long).unsqueeze(0)\n","        fake = torch.cat((inp_tensor, fake), dim=1)\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        #print(fake.shape)\n","        fake = fake.type(torch.float32)\n","        fake = fake.view(1, 1, -1)\n","        #print(fake.shape)\n","        #fake = correct_to_64(fake)\n","        #print(fake.shape)\n","        fake = fake.detach().to(device)\n","        output = netD(fake).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        if i % 5 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(validation_data),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        if iters == 5: netG.save_pretrained('orange/orange-trial')\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","            netG.save_pretrained('orange/orange-halfway')\n","            with torch.no_grad():\n","                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1\n","\n","netG.save_pretrained('orange/orange-full')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7CIqDPACJV9","outputId":"a0a61828-aae5-4aa3-9870-cc42ea1b31e8","executionInfo":{"status":"ok","timestamp":1679271683101,"user_tz":300,"elapsed":6933956,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training Loop...\n","[0/1][0/998]\tLoss_D: 1.1869\tLoss_G: 0.8342\tD(x): 0.8622\tD(G(z)): 0.6461 / 0.4342\n","[0/1][5/998]\tLoss_D: 1.8239\tLoss_G: 1.5843\tD(x): 0.2806\tD(G(z)): 0.4248 / 0.2051\n","[0/1][10/998]\tLoss_D: 0.6056\tLoss_G: 1.3363\tD(x): 0.8479\tD(G(z)): 0.3563 / 0.2628\n","[0/1][15/998]\tLoss_D: 0.1448\tLoss_G: 2.5036\tD(x): 0.9524\tD(G(z)): 0.0916 / 0.0818\n","[0/1][20/998]\tLoss_D: 0.1120\tLoss_G: 2.8985\tD(x): 0.9676\tD(G(z)): 0.0761 / 0.0551\n","[0/1][25/998]\tLoss_D: 0.1253\tLoss_G: 2.6990\tD(x): 0.9618\tD(G(z)): 0.0827 / 0.0673\n","[0/1][30/998]\tLoss_D: 0.1049\tLoss_G: 3.0962\tD(x): 0.9649\tD(G(z)): 0.0668 / 0.0452\n","[0/1][35/998]\tLoss_D: 3.2399\tLoss_G: 2.5500\tD(x): 0.0406\tD(G(z)): 0.0343 / 0.0781\n","[0/1][40/998]\tLoss_D: 0.1362\tLoss_G: 3.1790\tD(x): 0.9144\tD(G(z)): 0.0457 / 0.0416\n","[0/1][45/998]\tLoss_D: 0.0602\tLoss_G: 3.2891\tD(x): 0.9763\tD(G(z)): 0.0356 / 0.0373\n","[0/1][50/998]\tLoss_D: 0.2191\tLoss_G: 1.0043\tD(x): 0.9749\tD(G(z)): 0.1761 / 0.3663\n","[0/1][55/998]\tLoss_D: 2.6487\tLoss_G: 2.1784\tD(x): 0.0755\tD(G(z)): 0.0636 / 0.1132\n","[0/1][60/998]\tLoss_D: 0.1524\tLoss_G: 2.5106\tD(x): 0.9552\tD(G(z)): 0.1011 / 0.0812\n","[0/1][65/998]\tLoss_D: 0.0715\tLoss_G: 3.2150\tD(x): 0.9789\tD(G(z)): 0.0489 / 0.0402\n","[0/1][70/998]\tLoss_D: 0.0532\tLoss_G: 3.5512\tD(x): 0.9783\tD(G(z)): 0.0308 / 0.0287\n","[0/1][75/998]\tLoss_D: 0.0498\tLoss_G: 3.4988\tD(x): 0.9831\tD(G(z)): 0.0323 / 0.0302\n","[0/1][80/998]\tLoss_D: 0.4567\tLoss_G: 3.3818\tD(x): 0.9845\tD(G(z)): 0.3566 / 0.0340\n","[0/1][85/998]\tLoss_D: 2.5022\tLoss_G: 2.0528\tD(x): 0.0846\tD(G(z)): 0.0315 / 0.1284\n","[0/1][90/998]\tLoss_D: 0.2865\tLoss_G: 2.7101\tD(x): 0.9255\tD(G(z)): 0.1887 / 0.0665\n","[0/1][95/998]\tLoss_D: 0.1405\tLoss_G: 3.4912\tD(x): 0.9069\tD(G(z)): 0.0419 / 0.0305\n","[0/1][100/998]\tLoss_D: 0.0673\tLoss_G: 3.3293\tD(x): 0.9700\tD(G(z)): 0.0362 / 0.0358\n","[0/1][105/998]\tLoss_D: 0.0544\tLoss_G: 3.4011\tD(x): 0.9756\tD(G(z)): 0.0292 / 0.0333\n","[0/1][110/998]\tLoss_D: 2.7832\tLoss_G: 3.5032\tD(x): 0.0637\tD(G(z)): 0.0287 / 0.0301\n","[0/1][115/998]\tLoss_D: 0.1052\tLoss_G: 3.1963\tD(x): 0.9494\tD(G(z)): 0.0518 / 0.0409\n","[0/1][120/998]\tLoss_D: 2.7111\tLoss_G: 2.7924\tD(x): 0.0695\tD(G(z)): 0.0430 / 0.0613\n","[0/1][125/998]\tLoss_D: 2.6866\tLoss_G: 3.1598\tD(x): 0.9822\tD(G(z)): 0.9307 / 0.0424\n","[0/1][130/998]\tLoss_D: 0.1320\tLoss_G: 3.4048\tD(x): 0.9102\tD(G(z)): 0.0373 / 0.0332\n","[0/1][135/998]\tLoss_D: 0.0589\tLoss_G: 3.6333\tD(x): 0.9776\tD(G(z)): 0.0357 / 0.0264\n","[0/1][140/998]\tLoss_D: 0.0540\tLoss_G: 3.3647\tD(x): 0.9767\tD(G(z)): 0.0299 / 0.0346\n","[0/1][145/998]\tLoss_D: 0.0472\tLoss_G: 3.7863\tD(x): 0.9804\tD(G(z)): 0.0270 / 0.0227\n","[0/1][150/998]\tLoss_D: 0.0422\tLoss_G: 3.8995\tD(x): 0.9790\tD(G(z)): 0.0208 / 0.0203\n","[0/1][155/998]\tLoss_D: 0.0400\tLoss_G: 3.7505\tD(x): 0.9826\tD(G(z)): 0.0222 / 0.0235\n","[0/1][160/998]\tLoss_D: 0.0799\tLoss_G: 2.3096\tD(x): 0.9805\tD(G(z)): 0.0584 / 0.0993\n","[0/1][165/998]\tLoss_D: 0.0366\tLoss_G: 3.9484\tD(x): 0.9841\tD(G(z)): 0.0204 / 0.0193\n","[0/1][170/998]\tLoss_D: 0.0350\tLoss_G: 3.9554\tD(x): 0.9845\tD(G(z)): 0.0192 / 0.0192\n","[0/1][175/998]\tLoss_D: 0.0386\tLoss_G: 3.6212\tD(x): 0.9839\tD(G(z)): 0.0221 / 0.0268\n","[0/1][180/998]\tLoss_D: 0.0355\tLoss_G: 3.8021\tD(x): 0.9835\tD(G(z)): 0.0186 / 0.0223\n","[0/1][185/998]\tLoss_D: 0.0363\tLoss_G: 4.0385\tD(x): 0.9830\tD(G(z)): 0.0189 / 0.0176\n","[0/1][190/998]\tLoss_D: 0.0329\tLoss_G: 4.0328\tD(x): 0.9857\tD(G(z)): 0.0183 / 0.0177\n","[0/1][195/998]\tLoss_D: 0.0368\tLoss_G: 3.9918\tD(x): 0.9814\tD(G(z)): 0.0178 / 0.0185\n","[0/1][200/998]\tLoss_D: 0.2928\tLoss_G: 4.0191\tD(x): 0.7603\tD(G(z)): 0.0186 / 0.0180\n","[0/1][205/998]\tLoss_D: 0.0345\tLoss_G: 3.9461\tD(x): 0.9866\tD(G(z)): 0.0207 / 0.0193\n","[0/1][210/998]\tLoss_D: 2.9685\tLoss_G: 3.9498\tD(x): 0.0522\tD(G(z)): 0.0154 / 0.0193\n","[0/1][215/998]\tLoss_D: 0.0498\tLoss_G: 3.5467\tD(x): 0.9850\tD(G(z)): 0.0342 / 0.0288\n","[0/1][220/998]\tLoss_D: 0.0367\tLoss_G: 3.6104\tD(x): 0.9870\tD(G(z)): 0.0234 / 0.0270\n","[0/1][225/998]\tLoss_D: 0.0363\tLoss_G: 4.0071\tD(x): 0.9819\tD(G(z)): 0.0179 / 0.0182\n","[0/1][230/998]\tLoss_D: 0.0337\tLoss_G: 3.5574\tD(x): 0.9844\tD(G(z)): 0.0178 / 0.0285\n","[0/1][235/998]\tLoss_D: 0.0305\tLoss_G: 4.1058\tD(x): 0.9859\tD(G(z)): 0.0162 / 0.0165\n","[0/1][240/998]\tLoss_D: 0.0417\tLoss_G: 4.0279\tD(x): 0.9762\tD(G(z)): 0.0175 / 0.0178\n","[0/1][245/998]\tLoss_D: 0.0598\tLoss_G: 3.6013\tD(x): 0.9699\tD(G(z)): 0.0288 / 0.0273\n","[0/1][250/998]\tLoss_D: 0.0451\tLoss_G: 3.6623\tD(x): 0.9767\tD(G(z)): 0.0213 / 0.0257\n","[0/1][255/998]\tLoss_D: 0.0365\tLoss_G: 3.9658\tD(x): 0.9843\tD(G(z)): 0.0205 / 0.0190\n","[0/1][260/998]\tLoss_D: 0.0605\tLoss_G: 3.2526\tD(x): 0.9840\tD(G(z)): 0.0434 / 0.0387\n","[0/1][265/998]\tLoss_D: 0.0529\tLoss_G: 3.5246\tD(x): 0.9810\tD(G(z)): 0.0332 / 0.0295\n","[0/1][270/998]\tLoss_D: 0.0452\tLoss_G: 3.3685\tD(x): 0.9824\tD(G(z)): 0.0271 / 0.0344\n","[0/1][275/998]\tLoss_D: 0.0468\tLoss_G: 3.3815\tD(x): 0.9858\tD(G(z)): 0.0320 / 0.0340\n","[0/1][280/998]\tLoss_D: 0.0857\tLoss_G: 2.9945\tD(x): 0.9853\tD(G(z)): 0.0684 / 0.0501\n","[0/1][285/998]\tLoss_D: 0.0927\tLoss_G: 3.1441\tD(x): 0.9864\tD(G(z)): 0.0760 / 0.0431\n","[0/1][290/998]\tLoss_D: 0.0389\tLoss_G: 3.6878\tD(x): 0.9841\tD(G(z)): 0.0226 / 0.0250\n","[0/1][295/998]\tLoss_D: 0.0906\tLoss_G: 2.7632\tD(x): 0.9811\tD(G(z)): 0.0690 / 0.0631\n","[0/1][300/998]\tLoss_D: 0.0511\tLoss_G: 3.1563\tD(x): 0.9856\tD(G(z)): 0.0359 / 0.0426\n","[0/1][305/998]\tLoss_D: 0.0406\tLoss_G: 3.9172\tD(x): 0.9823\tD(G(z)): 0.0226 / 0.0199\n","[0/1][310/998]\tLoss_D: 0.0395\tLoss_G: 3.8719\tD(x): 0.9860\tD(G(z)): 0.0251 / 0.0208\n","[0/1][315/998]\tLoss_D: 0.0399\tLoss_G: 3.8686\tD(x): 0.9838\tD(G(z)): 0.0233 / 0.0209\n","[0/1][320/998]\tLoss_D: 0.0340\tLoss_G: 3.8964\tD(x): 0.9868\tD(G(z)): 0.0205 / 0.0203\n","[0/1][325/998]\tLoss_D: 0.0302\tLoss_G: 4.0182\tD(x): 0.9868\tD(G(z)): 0.0168 / 0.0180\n","[0/1][330/998]\tLoss_D: 0.1125\tLoss_G: 3.9958\tD(x): 0.9873\tD(G(z)): 0.0949 / 0.0184\n","[0/1][335/998]\tLoss_D: 0.0315\tLoss_G: 3.8975\tD(x): 0.9872\tD(G(z)): 0.0185 / 0.0203\n","[0/1][340/998]\tLoss_D: 0.0301\tLoss_G: 4.1712\tD(x): 0.9873\tD(G(z)): 0.0172 / 0.0154\n","[0/1][345/998]\tLoss_D: 0.0303\tLoss_G: 4.1314\tD(x): 0.9859\tD(G(z)): 0.0160 / 0.0161\n","[0/1][350/998]\tLoss_D: 0.0286\tLoss_G: 4.1554\tD(x): 0.9876\tD(G(z)): 0.0160 / 0.0157\n","[0/1][355/998]\tLoss_D: 0.0410\tLoss_G: 1.5734\tD(x): 0.9873\tD(G(z)): 0.0278 / 0.2073\n","[0/1][360/998]\tLoss_D: 0.0459\tLoss_G: 3.9110\tD(x): 0.9817\tD(G(z)): 0.0271 / 0.0200\n","[0/1][365/998]\tLoss_D: 0.0412\tLoss_G: 3.9723\tD(x): 0.9842\tD(G(z)): 0.0250 / 0.0188\n","[0/1][370/998]\tLoss_D: 0.0332\tLoss_G: 3.7401\tD(x): 0.9863\tD(G(z)): 0.0192 / 0.0238\n","[0/1][375/998]\tLoss_D: 0.0351\tLoss_G: 3.9751\tD(x): 0.9856\tD(G(z)): 0.0204 / 0.0188\n","[0/1][380/998]\tLoss_D: 0.0368\tLoss_G: 4.1383\tD(x): 0.9865\tD(G(z)): 0.0229 / 0.0159\n","[0/1][385/998]\tLoss_D: 4.0131\tLoss_G: 3.9045\tD(x): 0.0184\tD(G(z)): 0.0168 / 0.0202\n","[0/1][390/998]\tLoss_D: 0.0398\tLoss_G: 3.7253\tD(x): 0.9859\tD(G(z)): 0.0252 / 0.0241\n","[0/1][395/998]\tLoss_D: 0.0392\tLoss_G: 3.8202\tD(x): 0.9854\tD(G(z)): 0.0243 / 0.0219\n","[0/1][400/998]\tLoss_D: 0.0418\tLoss_G: 4.0444\tD(x): 0.9824\tD(G(z)): 0.0237 / 0.0175\n","[0/1][405/998]\tLoss_D: 0.0314\tLoss_G: 3.9853\tD(x): 0.9880\tD(G(z)): 0.0192 / 0.0186\n","[0/1][410/998]\tLoss_D: 0.0295\tLoss_G: 4.1581\tD(x): 0.9881\tD(G(z)): 0.0174 / 0.0156\n","[0/1][415/998]\tLoss_D: 0.0299\tLoss_G: 4.1278\tD(x): 0.9879\tD(G(z)): 0.0175 / 0.0161\n","[0/1][420/998]\tLoss_D: 0.0311\tLoss_G: 4.1383\tD(x): 0.9858\tD(G(z)): 0.0167 / 0.0160\n","[0/1][425/998]\tLoss_D: 0.0289\tLoss_G: 4.0081\tD(x): 0.9882\tD(G(z)): 0.0169 / 0.0182\n","[0/1][430/998]\tLoss_D: 0.0289\tLoss_G: 4.0997\tD(x): 0.9872\tD(G(z)): 0.0159 / 0.0166\n","[0/1][435/998]\tLoss_D: 0.0299\tLoss_G: 4.0999\tD(x): 0.9872\tD(G(z)): 0.0169 / 0.0166\n","[0/1][440/998]\tLoss_D: 0.0809\tLoss_G: 2.8587\tD(x): 0.9865\tD(G(z)): 0.0651 / 0.0573\n","[0/1][445/998]\tLoss_D: 0.0578\tLoss_G: 3.5557\tD(x): 0.9878\tD(G(z)): 0.0445 / 0.0286\n","[0/1][450/998]\tLoss_D: 3.4020\tLoss_G: 2.3073\tD(x): 0.0343\tD(G(z)): 0.0281 / 0.0995\n","[0/1][455/998]\tLoss_D: 0.1689\tLoss_G: 1.8062\tD(x): 0.9757\tD(G(z)): 0.1343 / 0.1643\n","[0/1][460/998]\tLoss_D: 0.0716\tLoss_G: 3.1848\tD(x): 0.9732\tD(G(z)): 0.0434 / 0.0414\n","[0/1][465/998]\tLoss_D: 0.0675\tLoss_G: 3.2994\tD(x): 0.9740\tD(G(z)): 0.0403 / 0.0369\n","[0/1][470/998]\tLoss_D: 0.1378\tLoss_G: 1.9113\tD(x): 0.9802\tD(G(z)): 0.1112 / 0.1479\n","[0/1][475/998]\tLoss_D: 0.1050\tLoss_G: 2.4875\tD(x): 0.9833\tD(G(z)): 0.0844 / 0.0831\n","[0/1][480/998]\tLoss_D: 0.0690\tLoss_G: 2.5479\tD(x): 0.9849\tD(G(z)): 0.0523 / 0.0782\n","[0/1][485/998]\tLoss_D: 0.0567\tLoss_G: 3.1467\tD(x): 0.9847\tD(G(z)): 0.0404 / 0.0430\n","[0/1][490/998]\tLoss_D: 0.0891\tLoss_G: 2.8571\tD(x): 0.9852\tD(G(z)): 0.0715 / 0.0574\n","[0/1][495/998]\tLoss_D: 0.0597\tLoss_G: 3.2955\tD(x): 0.9837\tD(G(z)): 0.0423 / 0.0371\n","[0/1][500/998]\tLoss_D: 0.0801\tLoss_G: 3.3714\tD(x): 0.9749\tD(G(z)): 0.0532 / 0.0343\n","[0/1][505/998]\tLoss_D: 0.0466\tLoss_G: 3.4475\tD(x): 0.9839\tD(G(z)): 0.0299 / 0.0318\n","[0/1][510/998]\tLoss_D: 0.0324\tLoss_G: 3.9216\tD(x): 0.9868\tD(G(z)): 0.0190 / 0.0198\n","[0/1][515/998]\tLoss_D: 0.0385\tLoss_G: 3.9473\tD(x): 0.9867\tD(G(z)): 0.0248 / 0.0193\n","[0/1][520/998]\tLoss_D: 0.0406\tLoss_G: 3.8686\tD(x): 0.9803\tD(G(z)): 0.0205 / 0.0209\n","[0/1][525/998]\tLoss_D: 3.6107\tLoss_G: 3.1505\tD(x): 0.0275\tD(G(z)): 0.0176 / 0.0428\n","[0/1][530/998]\tLoss_D: 0.0799\tLoss_G: 3.2071\tD(x): 0.9786\tD(G(z)): 0.0566 / 0.0405\n","[0/1][535/998]\tLoss_D: 0.0436\tLoss_G: 3.6247\tD(x): 0.9840\tD(G(z)): 0.0271 / 0.0267\n","[0/1][540/998]\tLoss_D: 0.0484\tLoss_G: 3.3660\tD(x): 0.9807\tD(G(z)): 0.0284 / 0.0345\n","[0/1][545/998]\tLoss_D: 0.0374\tLoss_G: 3.7415\tD(x): 0.9863\tD(G(z)): 0.0233 / 0.0237\n","[0/1][550/998]\tLoss_D: 0.0362\tLoss_G: 4.0431\tD(x): 0.9851\tD(G(z)): 0.0210 / 0.0175\n","[0/1][555/998]\tLoss_D: 0.0371\tLoss_G: 3.9832\tD(x): 0.9836\tD(G(z)): 0.0203 / 0.0186\n","[0/1][560/998]\tLoss_D: 0.0607\tLoss_G: 3.9006\tD(x): 0.9575\tD(G(z)): 0.0171 / 0.0202\n","[0/1][565/998]\tLoss_D: 0.0341\tLoss_G: 4.0044\tD(x): 0.9850\tD(G(z)): 0.0189 / 0.0182\n","[0/1][570/998]\tLoss_D: 0.0331\tLoss_G: 4.0714\tD(x): 0.9872\tD(G(z)): 0.0200 / 0.0171\n","[0/1][575/998]\tLoss_D: 0.0691\tLoss_G: 2.9737\tD(x): 0.9857\tD(G(z)): 0.0532 / 0.0511\n","[0/1][580/998]\tLoss_D: 0.0318\tLoss_G: 3.9454\tD(x): 0.9862\tD(G(z)): 0.0178 / 0.0193\n","[0/1][585/998]\tLoss_D: 0.0287\tLoss_G: 4.1239\tD(x): 0.9874\tD(G(z)): 0.0159 / 0.0162\n","[0/1][590/998]\tLoss_D: 0.0294\tLoss_G: 3.9027\tD(x): 0.9875\tD(G(z)): 0.0167 / 0.0202\n","[0/1][595/998]\tLoss_D: 0.0298\tLoss_G: 4.0178\tD(x): 0.9879\tD(G(z)): 0.0175 / 0.0180\n","[0/1][600/998]\tLoss_D: 0.0280\tLoss_G: 4.1521\tD(x): 0.9869\tD(G(z)): 0.0147 / 0.0157\n","[0/1][605/998]\tLoss_D: 0.0281\tLoss_G: 4.1186\tD(x): 0.9876\tD(G(z)): 0.0156 / 0.0163\n","[0/1][610/998]\tLoss_D: 0.0276\tLoss_G: 4.0792\tD(x): 0.9877\tD(G(z)): 0.0151 / 0.0169\n","[0/1][615/998]\tLoss_D: 0.0283\tLoss_G: 3.9305\tD(x): 0.9877\tD(G(z)): 0.0158 / 0.0196\n","[0/1][620/998]\tLoss_D: 0.0277\tLoss_G: 4.1408\tD(x): 0.9887\tD(G(z)): 0.0162 / 0.0159\n","[0/1][625/998]\tLoss_D: 0.0256\tLoss_G: 4.1752\tD(x): 0.9884\tD(G(z)): 0.0138 / 0.0154\n","[0/1][630/998]\tLoss_D: 0.0263\tLoss_G: 4.1639\tD(x): 0.9882\tD(G(z)): 0.0143 / 0.0155\n","[0/1][635/998]\tLoss_D: 0.0264\tLoss_G: 4.2591\tD(x): 0.9872\tD(G(z)): 0.0134 / 0.0141\n","[0/1][640/998]\tLoss_D: 0.0387\tLoss_G: 4.2552\tD(x): 0.9759\tD(G(z)): 0.0142 / 0.0142\n","[0/1][645/998]\tLoss_D: 0.0368\tLoss_G: 4.2296\tD(x): 0.9790\tD(G(z)): 0.0155 / 0.0146\n","[0/1][650/998]\tLoss_D: 0.0320\tLoss_G: 4.2168\tD(x): 0.9839\tD(G(z)): 0.0157 / 0.0147\n","[0/1][655/998]\tLoss_D: 0.0320\tLoss_G: 4.1652\tD(x): 0.9840\tD(G(z)): 0.0157 / 0.0155\n","[0/1][660/998]\tLoss_D: 0.0296\tLoss_G: 4.2589\tD(x): 0.9854\tD(G(z)): 0.0148 / 0.0141\n","[0/1][665/998]\tLoss_D: 0.0714\tLoss_G: 4.1905\tD(x): 0.9455\tD(G(z)): 0.0152 / 0.0151\n","[0/1][670/998]\tLoss_D: 0.0520\tLoss_G: 4.1829\tD(x): 0.9625\tD(G(z)): 0.0137 / 0.0153\n","[0/1][675/998]\tLoss_D: 0.0347\tLoss_G: 4.2185\tD(x): 0.9811\tD(G(z)): 0.0155 / 0.0147\n","[0/1][680/998]\tLoss_D: 0.0302\tLoss_G: 4.2675\tD(x): 0.9837\tD(G(z)): 0.0138 / 0.0140\n","[0/1][685/998]\tLoss_D: 0.0290\tLoss_G: 4.1781\tD(x): 0.9854\tD(G(z)): 0.0142 / 0.0153\n","[0/1][690/998]\tLoss_D: 0.0333\tLoss_G: 4.2978\tD(x): 0.9807\tD(G(z)): 0.0138 / 0.0136\n","[0/1][695/998]\tLoss_D: 0.0567\tLoss_G: 4.2809\tD(x): 0.9576\tD(G(z)): 0.0133 / 0.0138\n","[0/1][700/998]\tLoss_D: 0.0246\tLoss_G: 4.3498\tD(x): 0.9885\tD(G(z)): 0.0130 / 0.0129\n","[0/1][705/998]\tLoss_D: 0.0284\tLoss_G: 4.2057\tD(x): 0.9873\tD(G(z)): 0.0154 / 0.0149\n","[0/1][710/998]\tLoss_D: 0.0247\tLoss_G: 4.1508\tD(x): 0.9888\tD(G(z)): 0.0134 / 0.0158\n","[0/1][715/998]\tLoss_D: 0.0258\tLoss_G: 4.0992\tD(x): 0.9889\tD(G(z)): 0.0145 / 0.0166\n","[0/1][720/998]\tLoss_D: 0.0251\tLoss_G: 4.2015\tD(x): 0.9885\tD(G(z)): 0.0134 / 0.0150\n","[0/1][725/998]\tLoss_D: 0.0248\tLoss_G: 4.3105\tD(x): 0.9887\tD(G(z)): 0.0134 / 0.0134\n","[0/1][730/998]\tLoss_D: 0.0242\tLoss_G: 4.2903\tD(x): 0.9890\tD(G(z)): 0.0130 / 0.0137\n","[0/1][735/998]\tLoss_D: 0.0410\tLoss_G: 4.2662\tD(x): 0.9730\tD(G(z)): 0.0136 / 0.0140\n","[0/1][740/998]\tLoss_D: 0.0245\tLoss_G: 4.3797\tD(x): 0.9902\tD(G(z)): 0.0146 / 0.0125\n","[0/1][745/998]\tLoss_D: 0.0234\tLoss_G: 4.3525\tD(x): 0.9899\tD(G(z)): 0.0132 / 0.0129\n","[0/1][750/998]\tLoss_D: 0.0232\tLoss_G: 4.4029\tD(x): 0.9895\tD(G(z)): 0.0126 / 0.0122\n","[0/1][755/998]\tLoss_D: 0.0247\tLoss_G: 4.3295\tD(x): 0.9883\tD(G(z)): 0.0129 / 0.0132\n","[0/1][760/998]\tLoss_D: 3.5017\tLoss_G: 4.1762\tD(x): 0.0305\tD(G(z)): 0.0129 / 0.0154\n","[0/1][765/998]\tLoss_D: 0.0289\tLoss_G: 4.2530\tD(x): 0.9882\tD(G(z)): 0.0169 / 0.0142\n","[0/1][770/998]\tLoss_D: 0.1196\tLoss_G: 4.2773\tD(x): 0.9011\tD(G(z)): 0.0153 / 0.0139\n","[0/1][775/998]\tLoss_D: 0.0419\tLoss_G: 4.1946\tD(x): 0.9744\tD(G(z)): 0.0159 / 0.0151\n","[0/1][780/998]\tLoss_D: 0.0310\tLoss_G: 3.9476\tD(x): 0.9855\tD(G(z)): 0.0163 / 0.0193\n","[0/1][785/998]\tLoss_D: 0.0368\tLoss_G: 4.0071\tD(x): 0.9816\tD(G(z)): 0.0181 / 0.0182\n","[0/1][790/998]\tLoss_D: 0.0365\tLoss_G: 4.1232\tD(x): 0.9842\tD(G(z)): 0.0204 / 0.0162\n","[0/1][795/998]\tLoss_D: 0.0286\tLoss_G: 4.1055\tD(x): 0.9850\tD(G(z)): 0.0134 / 0.0165\n","[0/1][800/998]\tLoss_D: 0.0310\tLoss_G: 4.2189\tD(x): 0.9826\tD(G(z)): 0.0133 / 0.0147\n","[0/1][805/998]\tLoss_D: 0.0274\tLoss_G: 4.0904\tD(x): 0.9879\tD(G(z)): 0.0151 / 0.0167\n","[0/1][810/998]\tLoss_D: 0.0280\tLoss_G: 4.1438\tD(x): 0.9876\tD(G(z)): 0.0154 / 0.0159\n","[0/1][815/998]\tLoss_D: 0.0321\tLoss_G: 3.8044\tD(x): 0.9860\tD(G(z)): 0.0178 / 0.0223\n","[0/1][820/998]\tLoss_D: 0.0341\tLoss_G: 3.9964\tD(x): 0.9890\tD(G(z)): 0.0227 / 0.0184\n","[0/1][825/998]\tLoss_D: 0.0301\tLoss_G: 3.9277\tD(x): 0.9876\tD(G(z)): 0.0175 / 0.0197\n","[0/1][830/998]\tLoss_D: 0.0261\tLoss_G: 4.2645\tD(x): 0.9889\tD(G(z)): 0.0149 / 0.0141\n","[0/1][835/998]\tLoss_D: 0.0273\tLoss_G: 4.1215\tD(x): 0.9895\tD(G(z)): 0.0166 / 0.0162\n","[0/1][840/998]\tLoss_D: 0.0250\tLoss_G: 4.2010\tD(x): 0.9895\tD(G(z)): 0.0143 / 0.0150\n","[0/1][845/998]\tLoss_D: 0.0252\tLoss_G: 4.3254\tD(x): 0.9896\tD(G(z)): 0.0146 / 0.0132\n","[0/1][850/998]\tLoss_D: 0.0248\tLoss_G: 4.3807\tD(x): 0.9896\tD(G(z)): 0.0142 / 0.0125\n","[0/1][855/998]\tLoss_D: 0.0254\tLoss_G: 4.4121\tD(x): 0.9883\tD(G(z)): 0.0136 / 0.0121\n","[0/1][860/998]\tLoss_D: 0.0231\tLoss_G: 4.2963\tD(x): 0.9896\tD(G(z)): 0.0126 / 0.0136\n","[0/1][865/998]\tLoss_D: 0.0225\tLoss_G: 4.3135\tD(x): 0.9899\tD(G(z)): 0.0123 / 0.0134\n","[0/1][870/998]\tLoss_D: 0.0228\tLoss_G: 4.3232\tD(x): 0.9897\tD(G(z)): 0.0124 / 0.0133\n","[0/1][875/998]\tLoss_D: 0.0227\tLoss_G: 4.2118\tD(x): 0.9903\tD(G(z)): 0.0128 / 0.0148\n","[0/1][880/998]\tLoss_D: 0.0245\tLoss_G: 4.4100\tD(x): 0.9883\tD(G(z)): 0.0127 / 0.0122\n","[0/1][885/998]\tLoss_D: 0.0229\tLoss_G: 4.3870\tD(x): 0.9897\tD(G(z)): 0.0125 / 0.0124\n","[0/1][890/998]\tLoss_D: 0.0203\tLoss_G: 4.4269\tD(x): 0.9909\tD(G(z)): 0.0111 / 0.0120\n","[0/1][895/998]\tLoss_D: 0.0216\tLoss_G: 4.4042\tD(x): 0.9902\tD(G(z)): 0.0117 / 0.0122\n","[0/1][900/998]\tLoss_D: 0.0253\tLoss_G: 4.3840\tD(x): 0.9885\tD(G(z)): 0.0137 / 0.0125\n","[0/1][905/998]\tLoss_D: 0.0202\tLoss_G: 4.4862\tD(x): 0.9907\tD(G(z)): 0.0108 / 0.0113\n","[0/1][910/998]\tLoss_D: 0.0212\tLoss_G: 4.4734\tD(x): 0.9897\tD(G(z)): 0.0108 / 0.0114\n","[0/1][915/998]\tLoss_D: 0.0308\tLoss_G: 4.4499\tD(x): 0.9813\tD(G(z)): 0.0119 / 0.0117\n","[0/1][920/998]\tLoss_D: 0.0245\tLoss_G: 4.4596\tD(x): 0.9887\tD(G(z)): 0.0130 / 0.0116\n","[0/1][925/998]\tLoss_D: 0.0264\tLoss_G: 4.3619\tD(x): 0.9887\tD(G(z)): 0.0149 / 0.0128\n","[0/1][930/998]\tLoss_D: 0.0223\tLoss_G: 4.2820\tD(x): 0.9899\tD(G(z)): 0.0121 / 0.0138\n","[0/1][935/998]\tLoss_D: 0.0214\tLoss_G: 4.4258\tD(x): 0.9896\tD(G(z)): 0.0109 / 0.0120\n","[0/1][940/998]\tLoss_D: 0.0251\tLoss_G: 4.5747\tD(x): 0.9875\tD(G(z)): 0.0124 / 0.0103\n","[0/1][945/998]\tLoss_D: 0.0215\tLoss_G: 4.5753\tD(x): 0.9906\tD(G(z)): 0.0120 / 0.0103\n","[0/1][950/998]\tLoss_D: 0.0224\tLoss_G: 4.5309\tD(x): 0.9894\tD(G(z)): 0.0117 / 0.0108\n","[0/1][955/998]\tLoss_D: 0.0216\tLoss_G: 4.4946\tD(x): 0.9896\tD(G(z)): 0.0111 / 0.0112\n","[0/1][960/998]\tLoss_D: 0.0213\tLoss_G: 4.4548\tD(x): 0.9903\tD(G(z)): 0.0115 / 0.0116\n","[0/1][965/998]\tLoss_D: 0.0226\tLoss_G: 4.1517\tD(x): 0.9898\tD(G(z)): 0.0122 / 0.0157\n","[0/1][970/998]\tLoss_D: 0.0555\tLoss_G: 2.8259\tD(x): 0.9881\tD(G(z)): 0.0426 / 0.0593\n","[0/1][975/998]\tLoss_D: 0.0368\tLoss_G: 3.5901\tD(x): 0.9905\tD(G(z)): 0.0269 / 0.0276\n","[0/1][980/998]\tLoss_D: 0.0233\tLoss_G: 4.1791\tD(x): 0.9903\tD(G(z)): 0.0135 / 0.0153\n","[0/1][985/998]\tLoss_D: 0.0296\tLoss_G: 4.0714\tD(x): 0.9895\tD(G(z)): 0.0188 / 0.0171\n","[0/1][990/998]\tLoss_D: 0.0259\tLoss_G: 4.3411\tD(x): 0.9885\tD(G(z)): 0.0142 / 0.0130\n","[0/1][995/998]\tLoss_D: 0.0237\tLoss_G: 4.2160\tD(x): 0.9890\tD(G(z)): 0.0126 / 0.0148\n"]}]},{"cell_type":"code","source":["# ################ WORKING DO NOT TOUCH ####################\n","\n","# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i in range(len(train_data)):\n","#         data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.view(1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         inputs = train_df.iloc[i]['text']\n","#         data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"bZkK8xM0FBpM","executionInfo":{"status":"aborted","timestamp":1679264453047,"user_tz":300,"elapsed":17498,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QxIWu1TqEse1","executionInfo":{"status":"aborted","timestamp":1679264453047,"user_tz":300,"elapsed":17496,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","\n","# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# print(input.shape)\n","# m = nn.Upsample(size=(64, 64))\n","# output = m(input)\n","# output = output.reshape((1, 64, 64))\n","# print(output.shape)\n","\n","# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"id":"0zmQecWWiUWa","executionInfo":{"status":"aborted","timestamp":1679264453047,"user_tz":300,"elapsed":17494,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"id":"0ZdysfkciVDS","executionInfo":{"status":"aborted","timestamp":1679264453047,"user_tz":300,"elapsed":17492,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# m = nn.Upsample(size=(64, 64))\n","# intermediate = m(input)\n","# x = nn.Flatten(0, 1)\n","# output = x(intermediate)\n","# print(input.shape)\n","# print(intermediate.shape)\n","# print(output.shape)"],"metadata":{"id":"0P87XbnOkEOm","executionInfo":{"status":"aborted","timestamp":1679264453048,"user_tz":300,"elapsed":17491,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8BIW0Ev3m4b0","executionInfo":{"status":"aborted","timestamp":1679264453206,"user_tz":300,"elapsed":1,"user":{"displayName":"Kavin Anand","userId":"10451993716058838623"}}},"execution_count":null,"outputs":[]}]}