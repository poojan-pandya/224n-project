{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"272086ae15ff4b0cab206292230ccedd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33aa2efb2421493b866f7966540b85f9","IPY_MODEL_c64e2f368cda41eb82729442a378ccf3","IPY_MODEL_93ea608ff9084b5ea78e5c674785cc41"],"layout":"IPY_MODEL_69970c6ddb01434f8dfab0861c3fb8dc"}},"33aa2efb2421493b866f7966540b85f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59840fc3ca594eb0a5dc52249acd3537","placeholder":"​","style":"IPY_MODEL_9eddc2b7cd7e4dd5b77da607afe53b19","value":"Downloading (…)lve/main/config.json: 100%"}},"c64e2f368cda41eb82729442a378ccf3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a211aa2c7742539406370031998681","max":949,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b85744990df46bb8c579c87df04cbcd","value":949}},"93ea608ff9084b5ea78e5c674785cc41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_535d35b9b4c44e54b558bc341ce17580","placeholder":"​","style":"IPY_MODEL_c1ce623b4fd14067958514f1416adedb","value":" 949/949 [00:00&lt;00:00, 33.8kB/s]"}},"69970c6ddb01434f8dfab0861c3fb8dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59840fc3ca594eb0a5dc52249acd3537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eddc2b7cd7e4dd5b77da607afe53b19":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97a211aa2c7742539406370031998681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b85744990df46bb8c579c87df04cbcd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"535d35b9b4c44e54b558bc341ce17580":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1ce623b4fd14067958514f1416adedb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90915f294dcb4dd182b838b5b5d5e04b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_af705dd101194c7a8d86013985bf1e69","IPY_MODEL_d5c43ba609ad4e3dbeab523fe30dcdd8","IPY_MODEL_2cd88d54174d4c42b0a8753f20ad41ce"],"layout":"IPY_MODEL_4264703247a6498ab2f150bf62ba5043"}},"af705dd101194c7a8d86013985bf1e69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b61f4ecaa7634ac0a8baba137a72d179","placeholder":"​","style":"IPY_MODEL_411f87ba14764edb8d5324573f0d3c04","value":"Downloading pytorch_model.bin: 100%"}},"d5c43ba609ad4e3dbeab523fe30dcdd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_268699da2a7f41fbb3606ae35f7e3d5d","max":539679413,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa2a48cf00eb46a4aa73efef9cad5853","value":539679413}},"2cd88d54174d4c42b0a8753f20ad41ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aa4840a88bc4ba383fc9f47a6fd1392","placeholder":"​","style":"IPY_MODEL_a68e60fcca5f496aa2ef707bde149cd6","value":" 540M/540M [00:05&lt;00:00, 105MB/s]"}},"4264703247a6498ab2f150bf62ba5043":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b61f4ecaa7634ac0a8baba137a72d179":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"411f87ba14764edb8d5324573f0d3c04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"268699da2a7f41fbb3606ae35f7e3d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa2a48cf00eb46a4aa73efef9cad5853":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8aa4840a88bc4ba383fc9f47a6fd1392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a68e60fcca5f496aa2ef707bde149cd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"938f97b9979f46bbb6990b153034fbb1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73732b7100904c77a5dd67f25fc69d98","IPY_MODEL_8a001433fd264b219b94452ba2a9326c","IPY_MODEL_0cce93aa443a4b118cb341e766e2a8a0"],"layout":"IPY_MODEL_bf9e39a8aa0d4a7e915ea5a8b182140a"}},"73732b7100904c77a5dd67f25fc69d98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e7642a95f17451f8c51f8f684b9cf02","placeholder":"​","style":"IPY_MODEL_75a0523217494dd9b29716a184cf6431","value":"Downloading (…)okenizer_config.json: 100%"}},"8a001433fd264b219b94452ba2a9326c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70614376a3ab4c3b9f5d362e29f6ff09","max":338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49490571ccb24a2b9310123d6c095806","value":338}},"0cce93aa443a4b118cb341e766e2a8a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d473c5ad480c49c6aa63f3bc92cafa58","placeholder":"​","style":"IPY_MODEL_9ff59c25e650459e98e386382f27aa85","value":" 338/338 [00:00&lt;00:00, 15.6kB/s]"}},"bf9e39a8aa0d4a7e915ea5a8b182140a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e7642a95f17451f8c51f8f684b9cf02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75a0523217494dd9b29716a184cf6431":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70614376a3ab4c3b9f5d362e29f6ff09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49490571ccb24a2b9310123d6c095806":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d473c5ad480c49c6aa63f3bc92cafa58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ff59c25e650459e98e386382f27aa85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f1ff5719021410087db9e312097c67a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fab0b7cbbfa49d890a3df565949f679","IPY_MODEL_7ba24c28d6854eda8d76a66891b755ba","IPY_MODEL_0ddfd82c68ef49219db7c1dbefe8270d"],"layout":"IPY_MODEL_12762a272146496cac9d25abab837b6a"}},"0fab0b7cbbfa49d890a3df565949f679":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a579a30170d436bbc74e49d164af709","placeholder":"​","style":"IPY_MODEL_ceeb82e1510240cda0192c47046670fb","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"7ba24c28d6854eda8d76a66891b755ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65d3b8f6d6da4c4ca9b5af700d84c663","max":843438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ebc98bd7dd7e48548fe3c6b44ddfbc2f","value":843438}},"0ddfd82c68ef49219db7c1dbefe8270d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85fcb2ddbd834af08d09273c0f251c62","placeholder":"​","style":"IPY_MODEL_9d42de1ebfd94643a813650f697deacc","value":" 843k/843k [00:01&lt;00:00, 761kB/s]"}},"12762a272146496cac9d25abab837b6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a579a30170d436bbc74e49d164af709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceeb82e1510240cda0192c47046670fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65d3b8f6d6da4c4ca9b5af700d84c663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebc98bd7dd7e48548fe3c6b44ddfbc2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"85fcb2ddbd834af08d09273c0f251c62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d42de1ebfd94643a813650f697deacc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c179652cb794af58eac476ee24419a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_482417d43ad44a52b7bf712811dd48a0","IPY_MODEL_159aa7b00f474ca59e5ee2f548b9738a","IPY_MODEL_7caaaceea43149769c720bce1e733e54"],"layout":"IPY_MODEL_08cec4b43ad045b7959ff980a9abcc65"}},"482417d43ad44a52b7bf712811dd48a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfe395ef99bf49b3ad3fec7c5ec60ae2","placeholder":"​","style":"IPY_MODEL_95bbe0ae93a24ab4921a0c75981c8ef0","value":"Downloading (…)solve/main/bpe.codes: 100%"}},"159aa7b00f474ca59e5ee2f548b9738a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59e7a261593449539ca6ab228175321c","max":1078931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_775c7047bb764509adb5b613489af758","value":1078931}},"7caaaceea43149769c720bce1e733e54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_434535d4b047448284a9762d5f8d4d89","placeholder":"​","style":"IPY_MODEL_3949a5b7cb0543d49e85db76e0fcedd8","value":" 1.08M/1.08M [00:01&lt;00:00, 812kB/s]"}},"08cec4b43ad045b7959ff980a9abcc65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfe395ef99bf49b3ad3fec7c5ec60ae2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95bbe0ae93a24ab4921a0c75981c8ef0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59e7a261593449539ca6ab228175321c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"775c7047bb764509adb5b613489af758":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"434535d4b047448284a9762d5f8d4d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3949a5b7cb0543d49e85db76e0fcedd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a52a4defb92c4beeb24b2f62a769d1f4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4dabab2b010f40b5abe853b5cffd6b63","IPY_MODEL_fe9148f0c1564e5a9121e17af3b3d864","IPY_MODEL_2271f653471040d286258512be1d1efc"],"layout":"IPY_MODEL_237364e6d21b407aa9a3df2d5e91440b"}},"4dabab2b010f40b5abe853b5cffd6b63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7aacb03b00f143ac8c30ae7360e128a4","placeholder":"​","style":"IPY_MODEL_0ebe57f0b7d443a0bfef893e87d62d56","value":"Downloading (…)in/added_tokens.json: 100%"}},"fe9148f0c1564e5a9121e17af3b3d864":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0287995e28cd46d7ab85118f7d815c86","max":22,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bcc281c325ef4e47b14e6d02fdb5f52e","value":22}},"2271f653471040d286258512be1d1efc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ebcc86fbf2c4e179bbc2cc5da49b018","placeholder":"​","style":"IPY_MODEL_7c54eada7b834dd580cce697df0f3da9","value":" 22.0/22.0 [00:00&lt;00:00, 1.23kB/s]"}},"237364e6d21b407aa9a3df2d5e91440b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aacb03b00f143ac8c30ae7360e128a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ebe57f0b7d443a0bfef893e87d62d56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0287995e28cd46d7ab85118f7d815c86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc281c325ef4e47b14e6d02fdb5f52e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ebcc86fbf2c4e179bbc2cc5da49b018":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c54eada7b834dd580cce697df0f3da9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"100d0fa9beac4b70ae9d898a19467dba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92ddef9f7f064125af7bef7b56b428a0","IPY_MODEL_94bbf9c41a67473999abffccc93d7201","IPY_MODEL_77acb47e1a5945898b72f4703db6ab0e"],"layout":"IPY_MODEL_447244478b5e4e24aca164ccf75f4130"}},"92ddef9f7f064125af7bef7b56b428a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd25f5daac204f1aa6c133b0e52f5ed7","placeholder":"​","style":"IPY_MODEL_aafaea17861a4410ab4bce2097899aa7","value":"Downloading (…)cial_tokens_map.json: 100%"}},"94bbf9c41a67473999abffccc93d7201":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ab3764519ae4a3999f312d404202cbc","max":167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_515bba8daf984bbbb92dd5c6643fbab1","value":167}},"77acb47e1a5945898b72f4703db6ab0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_815e29caf16c402d91509bba0d439652","placeholder":"​","style":"IPY_MODEL_c6bacbf3f41741d8914e878886609142","value":" 167/167 [00:00&lt;00:00, 2.74kB/s]"}},"447244478b5e4e24aca164ccf75f4130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd25f5daac204f1aa6c133b0e52f5ed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aafaea17861a4410ab4bce2097899aa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ab3764519ae4a3999f312d404202cbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"515bba8daf984bbbb92dd5c6643fbab1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"815e29caf16c402d91509bba0d439652":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6bacbf3f41741d8914e878886609142":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64304ffd607c453e9391fc4d88f3af76":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d046d0b998744318f366292b157d312","IPY_MODEL_d437e1da7a3b4fffb6cca7c26d5e3c8e","IPY_MODEL_a7a45fc5be6c4bb399a2947469081f96"],"layout":"IPY_MODEL_8f207082f73c4571b04a08bfc402fbb7"}},"0d046d0b998744318f366292b157d312":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d31729569a641a4a25bc17690690d80","placeholder":"​","style":"IPY_MODEL_5c6e03f56f3a4c71ae7e44fc1e8d71c7","value":"Map: 100%"}},"d437e1da7a3b4fffb6cca7c26d5e3c8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a32cd6c2911421e8a3980d72ab1622f","max":81614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0df9d376608c4e0db0e77569d045cc5c","value":81614}},"a7a45fc5be6c4bb399a2947469081f96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3ddb4cc49c34d9a962eaadcd2c31e4b","placeholder":"​","style":"IPY_MODEL_b76ec05be0bb4e86a002babe3d062c7d","value":" 81614/81614 [03:25&lt;00:00, 364.50 examples/s]"}},"8f207082f73c4571b04a08bfc402fbb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"8d31729569a641a4a25bc17690690d80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6e03f56f3a4c71ae7e44fc1e8d71c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a32cd6c2911421e8a3980d72ab1622f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0df9d376608c4e0db0e77569d045cc5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c3ddb4cc49c34d9a962eaadcd2c31e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b76ec05be0bb4e86a002babe3d062c7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b1b14acff614cab96e17a61bd4da016":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35964ea48bd14f4f954da31f65fa5abe","IPY_MODEL_d0dc8f1bc23341c0a1104358646c64c1","IPY_MODEL_2d0fc64051d1434586f551a15f24c5a8"],"layout":"IPY_MODEL_1194958890924f10a21573e833dcb68a"}},"35964ea48bd14f4f954da31f65fa5abe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3afd83636afb4d46b25639c24d814c59","placeholder":"​","style":"IPY_MODEL_fdbe7b4c827a4fea9b818ff644fa2325","value":"Map: 100%"}},"d0dc8f1bc23341c0a1104358646c64c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_12082a7fa0bc4e8894b820c1c36c4f26","max":998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71ed55acea0440eb855c1c6b73753c9d","value":998}},"2d0fc64051d1434586f551a15f24c5a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43baeda15f5547bcbf9d46749fc7ac42","placeholder":"​","style":"IPY_MODEL_a470e001b4a744e99634915cee320490","value":" 998/998 [00:02&lt;00:00, 464.54 examples/s]"}},"1194958890924f10a21573e833dcb68a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"3afd83636afb4d46b25639c24d814c59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdbe7b4c827a4fea9b818ff644fa2325":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12082a7fa0bc4e8894b820c1c36c4f26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71ed55acea0440eb855c1c6b73753c9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43baeda15f5547bcbf9d46749fc7ac42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a470e001b4a744e99634915cee320490":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### GAN Attempt!"],"metadata":{"id":"l2vionRRzF_O"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JADRaL5b276C","executionInfo":{"status":"ok","timestamp":1679264769980,"user_tz":300,"elapsed":38801,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"b77fce67-edcc-481b-907b-24d6322f3147"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Setup\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n",")\n","import pandas as pd\n","from datasets import Dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ESRs9D8S2gd3","executionInfo":{"status":"ok","timestamp":1679264773481,"user_tz":300,"elapsed":3506,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/CS\\ 224N/CS\\ 224N\\ Project\n","%ls # verify that you are in the right directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txGRbtkd4IWq","executionInfo":{"status":"ok","timestamp":1679264811410,"user_tz":300,"elapsed":37937,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"fa2d0b2d-b454-42e5-b992-f3add3eb4007"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1x7bmzM_qtbj3CPKzenuwvwocK9KiZzWU/CS 224N Project\n","'224N Experiments (GAN on 998 Samples).gsheet'\n","'224N Project Brainstorm.gdoc'\n","\u001b[0m\u001b[01;36m'224N Project Helpful Tutorials.gdoc'\u001b[0m@\n","'224N Project Milestone Notes.gdoc'\n"," Adversarial-T5_Structure_1.ipynb\n"," aita_clean.csv\n"," aita_comments.csv\n"," aita_test_set.csv\n"," aita_test_set.gsheet\n"," aita_train_set.csv\n"," aita_valid_set.csv\n"," \u001b[01;34mbanana\u001b[0m/\n"," banana.ipynb\n"," \u001b[01;34mbart-base-checkpoint-204000\u001b[0m/\n"," bart-baseline-attempt2.ipynb\n"," \u001b[01;34mbart-checkpoint-5000\u001b[0m/\n"," bert-baseline.ipynb\n"," \u001b[01;34mblueberry\u001b[0m/\n"," blueberry.ipynb\n"," checkpoint.txt\n"," config.json\n"," \u001b[01;34mcsvs\u001b[0m/\n"," dataset_agg.ipynb\n"," \u001b[01;34mdrive\u001b[0m/\n"," Evaluate.ipynb\n","'experimenting with gumbel.ipynb'\n"," \u001b[01;34mfinetune-gpt2\u001b[0m/\n","\u001b[01;34m'first proposal OLD'\u001b[0m/\n"," gan-gen-trial\n"," gan-halfway-gen-transformer-d\n"," gpt-2-attempt2.ipynb\n"," gpt2-attempt3.ipynb\n"," gpt2-baseline.ipynb\n"," \u001b[01;34mgpt2-small-rationale-generation\u001b[0m/\n"," gpt2-wt-5.ipynb\n"," \u001b[01;34mgrape\u001b[0m/\n"," grape-exploration.ipynb\n"," grape.ipynb\n"," \u001b[01;34mhoneydew\u001b[0m/\n"," honeydew.ipynb\n"," \u001b[01;34mlogs\u001b[0m/\n"," Mango.ipynb\n"," \u001b[01;34mmango-old\u001b[0m/\n"," \u001b[01;34morange\u001b[0m/\n"," orange-halfway\n"," Orange.ipynb\n"," orange-trial\n"," Pear.ipynb\n"," Pear_RUN.ipynb\n"," \u001b[01;34mpineapple\u001b[0m/\n"," Pineapple.ipynb\n"," \u001b[01;34mpineapple-old\u001b[0m/\n"," \u001b[01;34mprocessed-set-gpt2\u001b[0m/\n","'Reddit Scraper.ipynb'\n"," \u001b[01;34mresults\u001b[0m/\n"," rouge_scores_baseline.txt\n"," rouge_scores.txt\n","\u001b[01;34m'screenshots bart'\u001b[0m/\n","\u001b[01;34m'screenshots t5'\u001b[0m/\n"," T5_Attempt_2.ipynb\n"," t5_attempt3.ipynb\n"," T5-baseline.ipynb\n"," \u001b[01;34mwandb\u001b[0m/\n"," wmd_scores_baseline.txt\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define the generator (use the pre-trained BART implementation)\n","\"\"\"\n","\n","# bart-base checkpoint pre-trained on our dataset\n","# (can also try generically pre-trained bart base)\n","model_dir = 'bart-base-checkpoint-204000'\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","print(netG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RgiUTBezH2V","executionInfo":{"status":"ok","timestamp":1679264828567,"user_tz":300,"elapsed":17159,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"323710b2-a516-4b5e-cd0e-10b54289e206"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define convolutional discriminator\n","\"\"\"\n","\n","nc = 1\n","ndf = 64\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            #Reshaping input\n","            nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 64 --> 1, 1, 64, 64\n","            # input is (nc) x 64 x 64 | our input is 1 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        #print(len(input.shape))\n","        return self.main(input)"],"metadata":{"id":"XBPd1v0Q34Jn","executionInfo":{"status":"ok","timestamp":1679264828567,"user_tz":300,"elapsed":14,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["ngpu = 1\n","netD = Discriminator(ngpu).to(device)"],"metadata":{"id":"F4fElnOc_aAR","executionInfo":{"status":"ok","timestamp":1679264832700,"user_tz":300,"elapsed":4146,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline\n","sentiment = pipeline(model='finiteautomata/bertweet-base-sentiment-analysis')\n","#sentiment = AutoModel.from_pretrained('finiteautomata/bertweet-base-sentiment-analysis')"],"metadata":{"id":"PFxhD-KlTaB3","colab":{"base_uri":"https://localhost:8080/","height":259,"referenced_widgets":["272086ae15ff4b0cab206292230ccedd","33aa2efb2421493b866f7966540b85f9","c64e2f368cda41eb82729442a378ccf3","93ea608ff9084b5ea78e5c674785cc41","69970c6ddb01434f8dfab0861c3fb8dc","59840fc3ca594eb0a5dc52249acd3537","9eddc2b7cd7e4dd5b77da607afe53b19","97a211aa2c7742539406370031998681","3b85744990df46bb8c579c87df04cbcd","535d35b9b4c44e54b558bc341ce17580","c1ce623b4fd14067958514f1416adedb","90915f294dcb4dd182b838b5b5d5e04b","af705dd101194c7a8d86013985bf1e69","d5c43ba609ad4e3dbeab523fe30dcdd8","2cd88d54174d4c42b0a8753f20ad41ce","4264703247a6498ab2f150bf62ba5043","b61f4ecaa7634ac0a8baba137a72d179","411f87ba14764edb8d5324573f0d3c04","268699da2a7f41fbb3606ae35f7e3d5d","aa2a48cf00eb46a4aa73efef9cad5853","8aa4840a88bc4ba383fc9f47a6fd1392","a68e60fcca5f496aa2ef707bde149cd6","938f97b9979f46bbb6990b153034fbb1","73732b7100904c77a5dd67f25fc69d98","8a001433fd264b219b94452ba2a9326c","0cce93aa443a4b118cb341e766e2a8a0","bf9e39a8aa0d4a7e915ea5a8b182140a","6e7642a95f17451f8c51f8f684b9cf02","75a0523217494dd9b29716a184cf6431","70614376a3ab4c3b9f5d362e29f6ff09","49490571ccb24a2b9310123d6c095806","d473c5ad480c49c6aa63f3bc92cafa58","9ff59c25e650459e98e386382f27aa85","7f1ff5719021410087db9e312097c67a","0fab0b7cbbfa49d890a3df565949f679","7ba24c28d6854eda8d76a66891b755ba","0ddfd82c68ef49219db7c1dbefe8270d","12762a272146496cac9d25abab837b6a","2a579a30170d436bbc74e49d164af709","ceeb82e1510240cda0192c47046670fb","65d3b8f6d6da4c4ca9b5af700d84c663","ebc98bd7dd7e48548fe3c6b44ddfbc2f","85fcb2ddbd834af08d09273c0f251c62","9d42de1ebfd94643a813650f697deacc","3c179652cb794af58eac476ee24419a8","482417d43ad44a52b7bf712811dd48a0","159aa7b00f474ca59e5ee2f548b9738a","7caaaceea43149769c720bce1e733e54","08cec4b43ad045b7959ff980a9abcc65","dfe395ef99bf49b3ad3fec7c5ec60ae2","95bbe0ae93a24ab4921a0c75981c8ef0","59e7a261593449539ca6ab228175321c","775c7047bb764509adb5b613489af758","434535d4b047448284a9762d5f8d4d89","3949a5b7cb0543d49e85db76e0fcedd8","a52a4defb92c4beeb24b2f62a769d1f4","4dabab2b010f40b5abe853b5cffd6b63","fe9148f0c1564e5a9121e17af3b3d864","2271f653471040d286258512be1d1efc","237364e6d21b407aa9a3df2d5e91440b","7aacb03b00f143ac8c30ae7360e128a4","0ebe57f0b7d443a0bfef893e87d62d56","0287995e28cd46d7ab85118f7d815c86","bcc281c325ef4e47b14e6d02fdb5f52e","6ebcc86fbf2c4e179bbc2cc5da49b018","7c54eada7b834dd580cce697df0f3da9","100d0fa9beac4b70ae9d898a19467dba","92ddef9f7f064125af7bef7b56b428a0","94bbf9c41a67473999abffccc93d7201","77acb47e1a5945898b72f4703db6ab0e","447244478b5e4e24aca164ccf75f4130","cd25f5daac204f1aa6c133b0e52f5ed7","aafaea17861a4410ab4bce2097899aa7","4ab3764519ae4a3999f312d404202cbc","515bba8daf984bbbb92dd5c6643fbab1","815e29caf16c402d91509bba0d439652","c6bacbf3f41741d8914e878886609142"]},"executionInfo":{"status":"ok","timestamp":1679264861417,"user_tz":300,"elapsed":28719,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"3729b183-221c-4940-fbec-98de7d0d4b6a"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/949 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272086ae15ff4b0cab206292230ccedd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90915f294dcb4dd182b838b5b5d5e04b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"938f97b9979f46bbb6990b153034fbb1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f1ff5719021410087db9e312097c67a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c179652cb794af58eac476ee24419a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a52a4defb92c4beeb24b2f62a769d1f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"100d0fa9beac4b70ae9d898a19467dba"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"]}]},{"cell_type":"code","source":["def get_sentiment_tokens(comment):\n","  max_input_length = 128\n","  if len(comment) > 128:\n","    comment = comment[:128]\n","  comment_sentiment = sentiment([comment])[0]\n","  comment_sentiment = comment_sentiment['label'] + ': ' + str(comment_sentiment['score'])\n","  comment_sentiment_tokens = tokenizer(comment_sentiment, max_length=128, padding='max_length', truncation=True, return_tensors=\"pt\")\n","  return comment_sentiment_tokens['input_ids'].tolist()"],"metadata":{"id":"Q2df63FbTahX","executionInfo":{"status":"ok","timestamp":1679264861417,"user_tz":300,"elapsed":16,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Loss functions and optimizers\n","\"\"\"\n","# Size of generator input\n","nz = 512\n","# Optim params\n","lr = 0.0002\n","beta1 = 0.5\n","\n","# Initialize BCELoss function\n","criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"mLLWvDY-7M96","executionInfo":{"status":"ok","timestamp":1679264864112,"user_tz":300,"elapsed":2710,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA0gynyNom7B","executionInfo":{"status":"ok","timestamp":1679264870791,"user_tz":300,"elapsed":6690,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"source":["train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n","valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n","test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"],"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_data_txt = Dataset.from_pandas(train_df)\n","validation_data_txt = Dataset.from_pandas(valid_df)\n","test_data_txt = Dataset.from_pandas(test_df)\n","print(train_data_txt)\n","print(validation_data_txt)\n","print(test_data_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf4cgIQL9uCA","executionInfo":{"status":"ok","timestamp":1679264871198,"user_tz":300,"elapsed":423,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"68157518-9c86-426c-c674-24fb612491c4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 81614\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Preprocess\n","\"\"\"\n","\n","encoder_max_length = 256  # changed from 256\n","decoder_max_length = 64  # changed from 64\n","\n","def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"comments\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["64304ffd607c453e9391fc4d88f3af76","0d046d0b998744318f366292b157d312","d437e1da7a3b4fffb6cca7c26d5e3c8e","a7a45fc5be6c4bb399a2947469081f96","8f207082f73c4571b04a08bfc402fbb7","8d31729569a641a4a25bc17690690d80","5c6e03f56f3a4c71ae7e44fc1e8d71c7","4a32cd6c2911421e8a3980d72ab1622f","0df9d376608c4e0db0e77569d045cc5c","c3ddb4cc49c34d9a962eaadcd2c31e4b","b76ec05be0bb4e86a002babe3d062c7d","3b1b14acff614cab96e17a61bd4da016","35964ea48bd14f4f954da31f65fa5abe","d0dc8f1bc23341c0a1104358646c64c1","2d0fc64051d1434586f551a15f24c5a8","1194958890924f10a21573e833dcb68a","3afd83636afb4d46b25639c24d814c59","fdbe7b4c827a4fea9b818ff644fa2325","12082a7fa0bc4e8894b820c1c36c4f26","71ed55acea0440eb855c1c6b73753c9d","43baeda15f5547bcbf9d46749fc7ac42","a470e001b4a744e99634915cee320490"]},"id":"wvBpN-KNAJ4x","executionInfo":{"status":"ok","timestamp":1679265078910,"user_tz":300,"elapsed":207716,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"8c6f66c3-213a-447a-f09b-f79ca59aaf66"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/81614 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64304ffd607c453e9391fc4d88f3af76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/998 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b1b14acff614cab96e17a61bd4da016"}},"metadata":{}}]},{"cell_type":"code","source":["print(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRueMmaYFamD","executionInfo":{"status":"ok","timestamp":1679265078910,"user_tz":300,"elapsed":9,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"61ba6ca2-1aac-4290-823c-5243a00280bd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 81614\n","})\n"]}]},{"cell_type":"code","source":["print(len(train_data[0]['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVc3xgHXFdk4","executionInfo":{"status":"ok","timestamp":1679265078910,"user_tz":300,"elapsed":6,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}},"outputId":"3d0b7cd9-4fe4-45f8-85c3-ccd957ddb42a"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["256\n"]}]},{"cell_type":"code","source":["fixed_validation_index = 17\n","fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n","fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"aYSn2PZcA4Pa","executionInfo":{"status":"ok","timestamp":1679265078911,"user_tz":300,"elapsed":5,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# batch_size=4\n","# dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","#                                          shuffle=True)\n","# for i, data in enumerate(dataloader, 0):\n","#   print(torch.stack(data['attention_mask']).shape)\n","#   break"],"metadata":{"id":"OTM_7TRDEuwr","executionInfo":{"status":"ok","timestamp":1679265078911,"user_tz":300,"elapsed":4,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["################ Changing the working data to validation ####################\n","\n","# Training Loop\n","\n","# Lists to keep track of progress\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","num_epochs = 1\n","max_input_length = 512\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # todo: batch this/use a dataloader\n","    for i in range(len(validation_data)):\n","        data = validation_data[i]\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        netD.zero_grad()\n","        # Format batch\n","        #print(len(data['labels']))\n","        sentiment_tokens = get_sentiment_tokens(str(valid_df.iloc[i]['comments']))\n","        real_cpu = torch.tensor(data['labels'] + sentiment_tokens[0], dtype=torch.float32)\n","        #real_cpu = data['labels']\n","        #print(real_cpu.shape)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        real_cpu = real_cpu.view(1, 1, 1, 64 + 128) #these are the comment tokens\n","        #print(real_cpu.shape)\n","        real_cpu = real_cpu.to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","        #discriminator will train off of true comments in the real batch pass\n","        # Forward pass real batch through D\n","        output = netD(real_cpu).view(-1) \n","        # Calculate loss on all-real batch\n","        errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        # print(inputs['input_ids'].shape)\n","        # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","        # Generate fake image batch with G\n","\n","        inputs = valid_df.iloc[i]['text']\n","        data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","        decoded_fake_comment = tokenizer.batch_decode(fake, skip_special_tokens=True)\n","        sentiment_tokens = get_sentiment_tokens(decoded_fake_comment[0])\n","        inp_tensor = torch.tensor(sentiment_tokens[0], dtype=torch.long).unsqueeze(0)\n","        fake = torch.cat((inp_tensor, fake), dim=1)\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        #print(fake.shape)\n","        fake = fake.type(torch.float32)\n","        fake = fake.view(1, 1, 1, -1)\n","        fake = fake.detach().to(device)\n","        output = netD(fake).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        if i % 5 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(validation_data),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        if iters == 5: netG.save_pretrained('pear/pear-save-initial')\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        if (iters != 0 and iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","            netG.save_pretrained('pear/pear-save-halfway')\n","            with torch.no_grad():\n","                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1\n","\n","netG.save_pretrained('pear/pear-save-final')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7CIqDPACJV9","outputId":"33b07215-ad9a-4bef-d46c-f0e6d37a2b35","executionInfo":{"status":"ok","timestamp":1679272172674,"user_tz":300,"elapsed":7093767,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training Loop...\n","[0/1][0/998]\tLoss_D: 1.2201\tLoss_G: 6.7044\tD(x): 0.4763\tD(G(z)): 0.3802 / 0.0012\n","[0/1][5/998]\tLoss_D: 0.0771\tLoss_G: 3.8508\tD(x): 0.9462\tD(G(z)): 0.0216 / 0.0213\n","[0/1][10/998]\tLoss_D: 0.0014\tLoss_G: 8.8193\tD(x): 0.9988\tD(G(z)): 0.0001 / 0.0001\n","[0/1][15/998]\tLoss_D: 0.0009\tLoss_G: 7.6370\tD(x): 0.9997\tD(G(z)): 0.0006 / 0.0005\n","[0/1][20/998]\tLoss_D: 0.0005\tLoss_G: 7.7316\tD(x): 0.9999\tD(G(z)): 0.0005 / 0.0004\n","[0/1][25/998]\tLoss_D: 0.0039\tLoss_G: 7.1750\tD(x): 0.9969\tD(G(z)): 0.0008 / 0.0008\n","[0/1][30/998]\tLoss_D: 0.0012\tLoss_G: 6.8266\tD(x): 0.9999\tD(G(z)): 0.0011 / 0.0011\n","[0/1][35/998]\tLoss_D: 0.0025\tLoss_G: 8.5001\tD(x): 0.9977\tD(G(z)): 0.0002 / 0.0002\n","[0/1][40/998]\tLoss_D: 0.0064\tLoss_G: 6.9582\tD(x): 0.9947\tD(G(z)): 0.0010 / 0.0010\n","[0/1][45/998]\tLoss_D: 0.0008\tLoss_G: 7.2637\tD(x): 1.0000\tD(G(z)): 0.0007 / 0.0007\n","[0/1][50/998]\tLoss_D: 0.0047\tLoss_G: 6.2717\tD(x): 0.9974\tD(G(z)): 0.0021 / 0.0019\n","[0/1][55/998]\tLoss_D: 0.2576\tLoss_G: 5.2311\tD(x): 0.7737\tD(G(z)): 0.0011 / 0.0053\n","[0/1][60/998]\tLoss_D: 0.0001\tLoss_G: 10.3490\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0000\n","[0/1][65/998]\tLoss_D: 0.0001\tLoss_G: 9.9520\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][70/998]\tLoss_D: 0.0000\tLoss_G: 10.3302\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][75/998]\tLoss_D: 0.0000\tLoss_G: 11.3604\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][80/998]\tLoss_D: 0.0002\tLoss_G: 10.9095\tD(x): 0.9998\tD(G(z)): 0.0000 / 0.0000\n","[0/1][85/998]\tLoss_D: 0.0001\tLoss_G: 11.6713\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][90/998]\tLoss_D: 0.0003\tLoss_G: 8.2475\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n","[0/1][95/998]\tLoss_D: 0.0009\tLoss_G: 9.8379\tD(x): 0.9992\tD(G(z)): 0.0001 / 0.0001\n","[0/1][100/998]\tLoss_D: 0.0001\tLoss_G: 9.1027\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][105/998]\tLoss_D: 0.0001\tLoss_G: 11.5717\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][110/998]\tLoss_D: 0.0089\tLoss_G: 6.1352\tD(x): 1.0000\tD(G(z)): 0.0088 / 0.0022\n","[0/1][115/998]\tLoss_D: 0.0003\tLoss_G: 8.1737\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n","[0/1][120/998]\tLoss_D: 0.0013\tLoss_G: 6.9069\tD(x): 0.9999\tD(G(z)): 0.0012 / 0.0010\n","[0/1][125/998]\tLoss_D: 0.0006\tLoss_G: 7.8327\tD(x): 0.9998\tD(G(z)): 0.0004 / 0.0004\n","[0/1][130/998]\tLoss_D: 0.0005\tLoss_G: 10.6413\tD(x): 0.9995\tD(G(z)): 0.0000 / 0.0000\n","[0/1][135/998]\tLoss_D: 0.0000\tLoss_G: 11.7124\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][140/998]\tLoss_D: 0.0002\tLoss_G: 11.3424\tD(x): 0.9998\tD(G(z)): 0.0000 / 0.0000\n","[0/1][145/998]\tLoss_D: 0.0000\tLoss_G: 10.1022\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][150/998]\tLoss_D: 0.0000\tLoss_G: 10.8766\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][155/998]\tLoss_D: 0.3892\tLoss_G: 10.5000\tD(x): 1.0000\tD(G(z)): 0.3224 / 0.0000\n","[0/1][160/998]\tLoss_D: 0.0031\tLoss_G: 12.6578\tD(x): 0.9969\tD(G(z)): 0.0000 / 0.0000\n","[0/1][165/998]\tLoss_D: 0.0068\tLoss_G: 4.7988\tD(x): 1.0000\tD(G(z)): 0.0068 / 0.0082\n","[0/1][170/998]\tLoss_D: 0.0134\tLoss_G: 6.1455\tD(x): 1.0000\tD(G(z)): 0.0133 / 0.0021\n","[0/1][175/998]\tLoss_D: 0.0004\tLoss_G: 8.0348\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n","[0/1][180/998]\tLoss_D: 0.0001\tLoss_G: 9.8887\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][185/998]\tLoss_D: 0.0001\tLoss_G: 8.9445\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][190/998]\tLoss_D: 0.0002\tLoss_G: 8.3694\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n","[0/1][195/998]\tLoss_D: 0.0000\tLoss_G: 10.4361\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][200/998]\tLoss_D: 0.0002\tLoss_G: 8.7956\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n","[0/1][205/998]\tLoss_D: 0.0000\tLoss_G: 11.4688\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][210/998]\tLoss_D: 0.0002\tLoss_G: 8.6893\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n","[0/1][215/998]\tLoss_D: 0.0000\tLoss_G: 10.1515\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][220/998]\tLoss_D: 0.0001\tLoss_G: 9.2419\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][225/998]\tLoss_D: 0.0005\tLoss_G: 7.8191\tD(x): 1.0000\tD(G(z)): 0.0004 / 0.0004\n","[0/1][230/998]\tLoss_D: 0.0000\tLoss_G: 11.1093\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][235/998]\tLoss_D: 0.0000\tLoss_G: 14.2977\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][240/998]\tLoss_D: 0.0000\tLoss_G: 12.6649\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][245/998]\tLoss_D: 0.0000\tLoss_G: 11.7679\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][250/998]\tLoss_D: 0.0001\tLoss_G: 9.5134\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][255/998]\tLoss_D: 0.0001\tLoss_G: 10.2940\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][260/998]\tLoss_D: 0.0003\tLoss_G: 7.4780\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0006\n","[0/1][265/998]\tLoss_D: 0.0000\tLoss_G: 15.7026\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][270/998]\tLoss_D: 0.0000\tLoss_G: 15.4604\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][275/998]\tLoss_D: 0.0000\tLoss_G: 15.5534\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][280/998]\tLoss_D: 0.0000\tLoss_G: 16.4511\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][285/998]\tLoss_D: 0.0001\tLoss_G: 15.3846\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][290/998]\tLoss_D: 0.0000\tLoss_G: 10.3623\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][295/998]\tLoss_D: 0.0000\tLoss_G: 16.1153\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][300/998]\tLoss_D: 0.0000\tLoss_G: 18.5863\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][305/998]\tLoss_D: 0.0001\tLoss_G: 18.2128\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][310/998]\tLoss_D: 0.0000\tLoss_G: 17.4752\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][315/998]\tLoss_D: 0.0000\tLoss_G: 16.4931\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][320/998]\tLoss_D: 0.0000\tLoss_G: 15.6486\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][325/998]\tLoss_D: 0.0000\tLoss_G: 16.5070\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][330/998]\tLoss_D: 0.0000\tLoss_G: 14.0488\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][335/998]\tLoss_D: 0.0024\tLoss_G: 6.0967\tD(x): 1.0000\tD(G(z)): 0.0024 / 0.0023\n","[0/1][340/998]\tLoss_D: 0.0001\tLoss_G: 9.2681\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][345/998]\tLoss_D: 0.0000\tLoss_G: 17.5221\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][350/998]\tLoss_D: 0.0017\tLoss_G: 6.4102\tD(x): 1.0000\tD(G(z)): 0.0017 / 0.0016\n","[0/1][355/998]\tLoss_D: 0.0000\tLoss_G: 16.8984\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][360/998]\tLoss_D: 0.0000\tLoss_G: 19.0696\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][365/998]\tLoss_D: 0.0000\tLoss_G: 11.3747\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][370/998]\tLoss_D: 0.0000\tLoss_G: 17.7066\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][375/998]\tLoss_D: 0.0000\tLoss_G: 17.0562\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][380/998]\tLoss_D: 0.0002\tLoss_G: 8.9150\tD(x): 0.9999\tD(G(z)): 0.0001 / 0.0001\n","[0/1][385/998]\tLoss_D: 0.0003\tLoss_G: 13.6143\tD(x): 0.9997\tD(G(z)): 0.0000 / 0.0000\n","[0/1][390/998]\tLoss_D: 0.0000\tLoss_G: 10.1201\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][395/998]\tLoss_D: 0.0000\tLoss_G: 11.1430\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][400/998]\tLoss_D: 0.0000\tLoss_G: 17.1273\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][405/998]\tLoss_D: 0.0000\tLoss_G: 17.0062\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][410/998]\tLoss_D: 0.0003\tLoss_G: 8.0117\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n","[0/1][415/998]\tLoss_D: 0.0000\tLoss_G: 17.5308\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][420/998]\tLoss_D: 0.0006\tLoss_G: 18.1940\tD(x): 0.9994\tD(G(z)): 0.0000 / 0.0000\n","[0/1][425/998]\tLoss_D: 0.0000\tLoss_G: 18.0629\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][430/998]\tLoss_D: 0.0000\tLoss_G: 11.2385\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][435/998]\tLoss_D: 0.0000\tLoss_G: 16.0659\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][440/998]\tLoss_D: 0.0000\tLoss_G: 16.8114\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][445/998]\tLoss_D: 0.0000\tLoss_G: 17.1536\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][450/998]\tLoss_D: 0.0000\tLoss_G: 16.7790\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][455/998]\tLoss_D: 0.0000\tLoss_G: 17.8679\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][460/998]\tLoss_D: 0.0000\tLoss_G: 13.4675\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][465/998]\tLoss_D: 0.0000\tLoss_G: 14.1877\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][470/998]\tLoss_D: 0.0000\tLoss_G: 16.6839\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][475/998]\tLoss_D: 0.0000\tLoss_G: 15.2230\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][480/998]\tLoss_D: 0.0000\tLoss_G: 18.4518\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][485/998]\tLoss_D: 0.0005\tLoss_G: 7.6610\tD(x): 1.0000\tD(G(z)): 0.0005 / 0.0005\n","[0/1][490/998]\tLoss_D: 0.0000\tLoss_G: 18.3638\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][495/998]\tLoss_D: 0.0000\tLoss_G: 17.4371\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][500/998]\tLoss_D: 0.0000\tLoss_G: 15.6074\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][505/998]\tLoss_D: 0.0000\tLoss_G: 15.3945\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][510/998]\tLoss_D: 0.0001\tLoss_G: 15.3010\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][515/998]\tLoss_D: 0.0000\tLoss_G: 18.0909\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][520/998]\tLoss_D: 0.0000\tLoss_G: 17.3256\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][525/998]\tLoss_D: 0.0000\tLoss_G: 18.7762\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][530/998]\tLoss_D: 0.0000\tLoss_G: 12.7123\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][535/998]\tLoss_D: 0.0000\tLoss_G: 14.5054\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][540/998]\tLoss_D: 0.0000\tLoss_G: 12.6602\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][545/998]\tLoss_D: 0.0000\tLoss_G: 14.2375\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][550/998]\tLoss_D: 0.0000\tLoss_G: 18.5365\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][555/998]\tLoss_D: 0.0000\tLoss_G: 18.7866\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][560/998]\tLoss_D: 0.0000\tLoss_G: 17.1144\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][565/998]\tLoss_D: 0.0003\tLoss_G: 8.0083\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n","[0/1][570/998]\tLoss_D: 0.0000\tLoss_G: 12.8687\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][575/998]\tLoss_D: 0.0000\tLoss_G: 18.9518\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][580/998]\tLoss_D: 0.0000\tLoss_G: 13.7319\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][585/998]\tLoss_D: 0.0000\tLoss_G: 17.5851\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][590/998]\tLoss_D: 0.0000\tLoss_G: 13.0037\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][595/998]\tLoss_D: 0.0000\tLoss_G: 15.4189\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][600/998]\tLoss_D: 0.0000\tLoss_G: 12.2553\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][605/998]\tLoss_D: 0.0000\tLoss_G: 16.3530\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][610/998]\tLoss_D: 0.0000\tLoss_G: 13.0259\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][615/998]\tLoss_D: 0.0000\tLoss_G: 14.7491\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][620/998]\tLoss_D: 0.0000\tLoss_G: 13.0530\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][625/998]\tLoss_D: 0.0000\tLoss_G: 13.5847\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][630/998]\tLoss_D: 0.0000\tLoss_G: 14.4482\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][635/998]\tLoss_D: 0.0000\tLoss_G: 17.4714\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][640/998]\tLoss_D: 0.0000\tLoss_G: 13.2300\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][645/998]\tLoss_D: 0.0000\tLoss_G: 14.9362\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][650/998]\tLoss_D: 0.0000\tLoss_G: 16.7939\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][655/998]\tLoss_D: 0.0000\tLoss_G: 11.7455\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][660/998]\tLoss_D: 0.0004\tLoss_G: 7.8608\tD(x): 1.0000\tD(G(z)): 0.0004 / 0.0004\n","[0/1][665/998]\tLoss_D: 0.0000\tLoss_G: 11.3040\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][670/998]\tLoss_D: 0.0000\tLoss_G: 17.6000\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][675/998]\tLoss_D: 0.0000\tLoss_G: 18.2887\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][680/998]\tLoss_D: 0.0000\tLoss_G: 16.9177\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][685/998]\tLoss_D: 0.0000\tLoss_G: 18.6077\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][690/998]\tLoss_D: 0.0000\tLoss_G: 17.9912\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][695/998]\tLoss_D: 0.0001\tLoss_G: 16.8207\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][700/998]\tLoss_D: 0.0002\tLoss_G: 17.5649\tD(x): 0.9998\tD(G(z)): 0.0000 / 0.0000\n","[0/1][705/998]\tLoss_D: 0.0000\tLoss_G: 10.6861\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][710/998]\tLoss_D: 0.0000\tLoss_G: 16.7324\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][715/998]\tLoss_D: 0.0000\tLoss_G: 11.3878\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][720/998]\tLoss_D: 0.0000\tLoss_G: 18.2495\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][725/998]\tLoss_D: 0.0162\tLoss_G: 18.6731\tD(x): 0.9840\tD(G(z)): 0.0000 / 0.0000\n","[0/1][730/998]\tLoss_D: 0.0000\tLoss_G: 13.9123\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][735/998]\tLoss_D: 0.0000\tLoss_G: 18.3408\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][740/998]\tLoss_D: 0.0000\tLoss_G: 14.6046\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][745/998]\tLoss_D: 0.0001\tLoss_G: 9.5998\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][750/998]\tLoss_D: 0.0000\tLoss_G: 15.4036\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][755/998]\tLoss_D: 0.0000\tLoss_G: 18.3623\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][760/998]\tLoss_D: 0.0000\tLoss_G: 18.9883\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][765/998]\tLoss_D: 0.0000\tLoss_G: 15.7248\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][770/998]\tLoss_D: 0.0000\tLoss_G: 17.3106\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][775/998]\tLoss_D: 0.0000\tLoss_G: 16.3185\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][780/998]\tLoss_D: 0.0009\tLoss_G: 7.0344\tD(x): 1.0000\tD(G(z)): 0.0009 / 0.0009\n","[0/1][785/998]\tLoss_D: 0.0000\tLoss_G: 17.3682\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][790/998]\tLoss_D: 0.0000\tLoss_G: 17.3868\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][795/998]\tLoss_D: 0.0000\tLoss_G: 15.4472\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][800/998]\tLoss_D: 0.0001\tLoss_G: 16.6102\tD(x): 0.9999\tD(G(z)): 0.0000 / 0.0000\n","[0/1][805/998]\tLoss_D: 0.0000\tLoss_G: 17.0321\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][810/998]\tLoss_D: 0.0006\tLoss_G: 7.4909\tD(x): 1.0000\tD(G(z)): 0.0006 / 0.0006\n","[0/1][815/998]\tLoss_D: 0.0000\tLoss_G: 14.4520\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][820/998]\tLoss_D: 0.0000\tLoss_G: 17.5596\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][825/998]\tLoss_D: 0.0000\tLoss_G: 10.8432\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][830/998]\tLoss_D: 0.0001\tLoss_G: 9.0806\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][835/998]\tLoss_D: 0.0000\tLoss_G: 10.1539\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][840/998]\tLoss_D: 0.0000\tLoss_G: 11.5764\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][845/998]\tLoss_D: 0.0005\tLoss_G: 7.5930\tD(x): 1.0000\tD(G(z)): 0.0005 / 0.0005\n","[0/1][850/998]\tLoss_D: 0.0000\tLoss_G: 13.3246\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][855/998]\tLoss_D: 0.0003\tLoss_G: 8.2596\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0003\n","[0/1][860/998]\tLoss_D: 0.0000\tLoss_G: 17.3466\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][865/998]\tLoss_D: 0.0005\tLoss_G: 7.5777\tD(x): 1.0000\tD(G(z)): 0.0005 / 0.0005\n","[0/1][870/998]\tLoss_D: 0.0000\tLoss_G: 10.3525\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][875/998]\tLoss_D: 0.0000\tLoss_G: 11.7693\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][880/998]\tLoss_D: 0.0007\tLoss_G: 7.2430\tD(x): 1.0000\tD(G(z)): 0.0007 / 0.0007\n","[0/1][885/998]\tLoss_D: 0.0000\tLoss_G: 11.7187\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][890/998]\tLoss_D: 0.0000\tLoss_G: 17.3352\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][895/998]\tLoss_D: 0.0000\tLoss_G: 18.0856\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][900/998]\tLoss_D: 0.0000\tLoss_G: 16.0429\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][905/998]\tLoss_D: 0.0000\tLoss_G: 16.7276\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][910/998]\tLoss_D: 0.0000\tLoss_G: 15.8627\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][915/998]\tLoss_D: 0.0001\tLoss_G: 8.9003\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][920/998]\tLoss_D: 0.0000\tLoss_G: 19.1690\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][925/998]\tLoss_D: 0.0000\tLoss_G: 15.4561\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][930/998]\tLoss_D: 0.0006\tLoss_G: 7.3907\tD(x): 1.0000\tD(G(z)): 0.0006 / 0.0006\n","[0/1][935/998]\tLoss_D: 0.0000\tLoss_G: 18.8136\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][940/998]\tLoss_D: 0.0000\tLoss_G: 17.3265\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][945/998]\tLoss_D: 0.0000\tLoss_G: 11.4197\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][950/998]\tLoss_D: 0.0001\tLoss_G: 9.1731\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][955/998]\tLoss_D: 0.0000\tLoss_G: 15.1983\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][960/998]\tLoss_D: 0.0002\tLoss_G: 8.6984\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n","[0/1][965/998]\tLoss_D: 0.0000\tLoss_G: 10.3417\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][970/998]\tLoss_D: 0.0000\tLoss_G: 17.0625\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][975/998]\tLoss_D: 0.0001\tLoss_G: 9.3770\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n","[0/1][980/998]\tLoss_D: 0.0002\tLoss_G: 8.4969\tD(x): 1.0000\tD(G(z)): 0.0002 / 0.0002\n","[0/1][985/998]\tLoss_D: 0.0000\tLoss_G: 17.1204\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][990/998]\tLoss_D: 0.0000\tLoss_G: 12.7806\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n","[0/1][995/998]\tLoss_D: 0.0000\tLoss_G: 17.4593\tD(x): 1.0000\tD(G(z)): 0.0000 / 0.0000\n"]}]},{"cell_type":"code","source":["# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i, data in enumerate(dataloader, 0):\n","#         #data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         #print(data)\n","#         print(data['labels'])\n","#         real_cpu = torch.stack(data['labels'])\n","#         #real_cpu = torch.unsqueeze(real_cpu, dim=0)\n","#         #real_cpu = torch.cat(real_cpu, dim=0)\n","#         #real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.type(torch.FloatTensor).view(-1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         #inputs = train_df.iloc[i]['text']\n","#         #data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         data = {k : torch.stack(v) for k, v in data.items()}\n","#         fake = netG(**data)\n","\n","#         # fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"kpQNOHLX7dL_","executionInfo":{"status":"ok","timestamp":1679272172675,"user_tz":300,"elapsed":10,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ################ WORKING DO NOT TOUCH ####################\n","\n","# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i in range(len(train_data)):\n","#         data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.view(1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         inputs = train_df.iloc[i]['text']\n","#         data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"bZkK8xM0FBpM","executionInfo":{"status":"ok","timestamp":1679272172675,"user_tz":300,"elapsed":10,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QxIWu1TqEse1","executionInfo":{"status":"ok","timestamp":1679272172675,"user_tz":300,"elapsed":9,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","\n","# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# print(input.shape)\n","# m = nn.Upsample(size=(64, 64))\n","# output = m(input)\n","# output = output.reshape((1, 64, 64))\n","# print(output.shape)\n","\n","# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"id":"0zmQecWWiUWa","executionInfo":{"status":"ok","timestamp":1679272172676,"user_tz":300,"elapsed":10,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"id":"0ZdysfkciVDS","executionInfo":{"status":"ok","timestamp":1679272172676,"user_tz":300,"elapsed":9,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# m = nn.Upsample(size=(64, 64))\n","# intermediate = m(input)\n","# x = nn.Flatten(0, 1)\n","# output = x(intermediate)\n","# print(input.shape)\n","# print(intermediate.shape)\n","# print(output.shape)"],"metadata":{"id":"0P87XbnOkEOm","executionInfo":{"status":"ok","timestamp":1679272172676,"user_tz":300,"elapsed":9,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8BIW0Ev3m4b0","executionInfo":{"status":"ok","timestamp":1679272172677,"user_tz":300,"elapsed":9,"user":{"displayName":"Anonymous Tiger","userId":"11625266279754307721"}}},"execution_count":22,"outputs":[]}]}