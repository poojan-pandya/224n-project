{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1RZzlzBJW5PHbrD96lZfq-lb4aMVIJ3pB","timestamp":1679127966258}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"832e979199e64da2ad43505840581bf0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b4d40ba86c64649a2f1ebdbb9b38bc8","IPY_MODEL_cf037d23de764f8aa038c5024131ee6d","IPY_MODEL_3f310662108f4e0b99e106aa96804e4c"],"layout":"IPY_MODEL_aa3304881d934ccea6b43431f7e401c7"}},"2b4d40ba86c64649a2f1ebdbb9b38bc8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1c52413fbc54a1eb67267cd180d920e","placeholder":"​","style":"IPY_MODEL_b5bbc62e4dc84d0fb7e0fb47ad53fa93","value":"Map: 100%"}},"cf037d23de764f8aa038c5024131ee6d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d909d86536594ef999e08c562e0acf7f","max":81614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25c31b9d7646474a8d6d670b48c4b119","value":81614}},"3f310662108f4e0b99e106aa96804e4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b52e7bb118b4ae3b161eb08a5d0d54d","placeholder":"​","style":"IPY_MODEL_7e61fec85c1e47919e86235a7d18310d","value":" 81614/81614 [03:23&lt;00:00, 376.36 examples/s]"}},"aa3304881d934ccea6b43431f7e401c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"a1c52413fbc54a1eb67267cd180d920e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5bbc62e4dc84d0fb7e0fb47ad53fa93":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d909d86536594ef999e08c562e0acf7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25c31b9d7646474a8d6d670b48c4b119":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b52e7bb118b4ae3b161eb08a5d0d54d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e61fec85c1e47919e86235a7d18310d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a68a375cae24744aa22d2ade8890eac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32f61f448b2f4cf196b784bdca0ba471","IPY_MODEL_94eb0111aaf547848d70bbbaacf70e82","IPY_MODEL_6e464ceabd2a40ffa5aeae38557b8bea"],"layout":"IPY_MODEL_df935ff70d8c471eb38d7e7a20406e99"}},"32f61f448b2f4cf196b784bdca0ba471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0758634f6c78434ab16012f64ce21dce","placeholder":"​","style":"IPY_MODEL_f81f6a280bf94122a7a6e6141ef1c307","value":"Map: 100%"}},"94eb0111aaf547848d70bbbaacf70e82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_edb0cb9376274dff823ecfb7a86128c3","max":998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f276e93264d24b91a13828079cf87890","value":998}},"6e464ceabd2a40ffa5aeae38557b8bea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ac28ed4875464ebf387b3ed9c5ce6f","placeholder":"​","style":"IPY_MODEL_72f132e0f7244b2e9e5d7d82200bf6d6","value":" 998/998 [00:02&lt;00:00, 469.02 examples/s]"}},"df935ff70d8c471eb38d7e7a20406e99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"0758634f6c78434ab16012f64ce21dce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f81f6a280bf94122a7a6e6141ef1c307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edb0cb9376274dff823ecfb7a86128c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f276e93264d24b91a13828079cf87890":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0ac28ed4875464ebf387b3ed9c5ce6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72f132e0f7244b2e9e5d7d82200bf6d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### GAN Attempt!"],"metadata":{"id":"l2vionRRzF_O"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JADRaL5b276C","executionInfo":{"status":"ok","timestamp":1679271504076,"user_tz":420,"elapsed":21221,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"b4205a15-a030-4c12-e21a-6fa72e11703b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m305.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Setup\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n",")\n","import pandas as pd\n","from datasets import Dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ESRs9D8S2gd3","executionInfo":{"status":"ok","timestamp":1679271535844,"user_tz":420,"elapsed":1768,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/CS\\ 224N\\ Project\n","%ls # verify that you are in the right directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txGRbtkd4IWq","executionInfo":{"status":"ok","timestamp":1679271626153,"user_tz":420,"elapsed":2070,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"9df26fcc-a18e-419e-dfdd-6bfa1b646988"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1x7bmzM_qtbj3CPKzenuwvwocK9KiZzWU/CS 224N Project\n","'224N Experiments (GAN on 998 Samples).gsheet'\n","'224N Project Brainstorm.gdoc'\n","'224N Project Helpful Tutorials.gdoc'\n","'224N Project Milestone Notes.gdoc'\n"," Adversarial-T5_Structure_1.ipynb\n"," aita_clean.csv\n"," aita_comments.csv\n"," aita_test_set.csv\n"," aita_test_set.gsheet\n"," aita_train_set.csv\n"," aita_valid_set.csv\n"," \u001b[0m\u001b[01;34mbanana\u001b[0m/\n"," banana.ipynb\n"," \u001b[01;34mbart-base-checkpoint-204000\u001b[0m/\n"," bart-baseline-attempt2.ipynb\n"," \u001b[01;34mbart-checkpoint-5000\u001b[0m/\n"," bert-baseline.ipynb\n"," \u001b[01;34mblueberry\u001b[0m/\n"," blueberry.ipynb\n"," checkpoint.txt\n"," config.json\n"," \u001b[01;34mcsvs\u001b[0m/\n"," dataset_agg.ipynb\n"," \u001b[01;34mdrive\u001b[0m/\n"," Evaluate.ipynb\n","'experimenting with gumbel.ipynb'\n"," \u001b[01;34mfinetune-gpt2\u001b[0m/\n","\u001b[01;34m'first proposal OLD'\u001b[0m/\n"," gan-gen-trial\n"," gan-halfway-gen-transformer-d\n"," gpt-2-attempt2.ipynb\n"," gpt2-attempt3.ipynb\n"," gpt2-baseline.ipynb\n"," \u001b[01;34mgpt2-small-rationale-generation\u001b[0m/\n"," gpt2-wt-5.ipynb\n"," \u001b[01;34mgrape\u001b[0m/\n"," grape-exploration.ipynb\n"," grape.ipynb\n"," \u001b[01;34mhoneydew\u001b[0m/\n"," honeydew.ipynb\n"," \u001b[01;34mlogs\u001b[0m/\n"," Mango.ipynb\n"," \u001b[01;34mmango-old\u001b[0m/\n"," \u001b[01;34morange\u001b[0m/\n"," orange-halfway\n"," Orange.ipynb\n"," orange-trial\n"," \u001b[01;34mpear\u001b[0m/\n"," Pear.ipynb\n"," Pear_RUN.ipynb\n"," \u001b[01;34mpineapple\u001b[0m/\n"," Pineapple.ipynb\n"," \u001b[01;34mpineapple-old\u001b[0m/\n"," \u001b[01;34mprocessed-set-gpt2\u001b[0m/\n","'Reddit Scraper.ipynb'\n"," \u001b[01;34mresults\u001b[0m/\n"," rouge_scores_baseline.txt\n"," rouge_scores.txt\n","\u001b[01;34m'screenshots bart'\u001b[0m/\n","\u001b[01;34m'screenshots t5'\u001b[0m/\n"," T5_Attempt_2.ipynb\n"," t5_attempt3.ipynb\n"," T5-baseline.ipynb\n"," \u001b[01;34mwandb\u001b[0m/\n"," wmd_scores_baseline.txt\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define the generator (use the pre-trained BART implementation)\n","\"\"\"\n","\n","# bart-base checkpoint pre-trained on our dataset\n","# (can also try generically pre-trained bart base)\n","model_dir = 'bart-base-checkpoint-204000'\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","print(netG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RgiUTBezH2V","executionInfo":{"status":"ok","timestamp":1679271668291,"user_tz":420,"elapsed":38795,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"21fa056e-7153-4cc2-b177-a6ab985a2b4c"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define transformer discriminator\n","\"\"\"\n","\n","nc = 1\n","ndf = 64\n","\n","# class Discriminator(nn.Module):\n","#     def __init__(self, ngpu):\n","#         super(Discriminator, self).__init__()\n","#         self.ngpu = ngpu\n","#         self.main = nn.Sequential(\n","#             #Reshaping input\n","#             nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 64 --> 1, 1, 64, 64\n","#             # input is (nc) x 64 x 64 | our input is 1 x 64\n","#             nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf) x 32 x 32\n","#             nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","#             nn.BatchNorm2d(ndf * 2),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf*2) x 16 x 16\n","#             nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","#             nn.BatchNorm2d(ndf * 4),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf*4) x 8 x 8\n","#             nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","#             nn.BatchNorm2d(ndf * 8),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             # state size. (ndf*8) x 4 x 4\n","#             nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","#             nn.Sigmoid()\n","#         )\n","\n","#     def forward(self, input):\n","#         #print(len(input.shape))\n","#         return self.main(input)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        \n","        # Transformer Encoder\n","        self.upsample = nn.Upsample(size=(64))\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n","        \n","        self.classifier = nn.Sequential(\n","            nn.Linear(64, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        #input shape: (batch_size, seq_len, d_model)\n","        upsampled_input = self.upsample(input)\n","        transformer_output = self.transformer_encoder(upsampled_input) \n","        discriminator_output = self.classifier(transformer_output.mean(dim=1)) #(batch_size, 1)\n","        \n","        return discriminator_output\n"],"metadata":{"id":"XBPd1v0Q34Jn","executionInfo":{"status":"ok","timestamp":1679271842570,"user_tz":420,"elapsed":4,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ngpu = 1\n","netD = Discriminator(ngpu).to(device)"],"metadata":{"id":"F4fElnOc_aAR","executionInfo":{"status":"ok","timestamp":1679271850805,"user_tz":420,"elapsed":6137,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Loss functions and optimizers\n","\"\"\"\n","# Size of generator input\n","nz = 512\n","# Optim params\n","lr = 0.0002\n","beta1 = 0.5\n","\n","# Initialize BCELoss function\n","criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"mLLWvDY-7M96","executionInfo":{"status":"ok","timestamp":1679271850806,"user_tz":420,"elapsed":5,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA0gynyNom7B","executionInfo":{"status":"ok","timestamp":1679271857093,"user_tz":420,"elapsed":6291,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"source":["train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n","valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n","test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"],"execution_count":12,"outputs":[]},{"cell_type":"code","source":["train_data_txt = Dataset.from_pandas(train_df)\n","validation_data_txt = Dataset.from_pandas(valid_df)\n","test_data_txt = Dataset.from_pandas(test_df)\n","print(train_data_txt)\n","print(validation_data_txt)\n","print(test_data_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf4cgIQL9uCA","executionInfo":{"status":"ok","timestamp":1679271857354,"user_tz":420,"elapsed":262,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"7603ca30-d9de-4f0e-c655-815123bce941"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 81614\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Preprocess\n","\"\"\"\n","\n","encoder_max_length = 256  # changed from 256\n","decoder_max_length = 64  # changed from 64\n","\n","def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"comments\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["832e979199e64da2ad43505840581bf0","2b4d40ba86c64649a2f1ebdbb9b38bc8","cf037d23de764f8aa038c5024131ee6d","3f310662108f4e0b99e106aa96804e4c","aa3304881d934ccea6b43431f7e401c7","a1c52413fbc54a1eb67267cd180d920e","b5bbc62e4dc84d0fb7e0fb47ad53fa93","d909d86536594ef999e08c562e0acf7f","25c31b9d7646474a8d6d670b48c4b119","6b52e7bb118b4ae3b161eb08a5d0d54d","7e61fec85c1e47919e86235a7d18310d","3a68a375cae24744aa22d2ade8890eac","32f61f448b2f4cf196b784bdca0ba471","94eb0111aaf547848d70bbbaacf70e82","6e464ceabd2a40ffa5aeae38557b8bea","df935ff70d8c471eb38d7e7a20406e99","0758634f6c78434ab16012f64ce21dce","f81f6a280bf94122a7a6e6141ef1c307","edb0cb9376274dff823ecfb7a86128c3","f276e93264d24b91a13828079cf87890","b0ac28ed4875464ebf387b3ed9c5ce6f","72f132e0f7244b2e9e5d7d82200bf6d6"]},"id":"wvBpN-KNAJ4x","executionInfo":{"status":"ok","timestamp":1679272063269,"user_tz":420,"elapsed":205923,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"1a5ecf26-e7f0-436b-d696-955e57b02b0b"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/81614 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"832e979199e64da2ad43505840581bf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/998 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a68a375cae24744aa22d2ade8890eac"}},"metadata":{}}]},{"cell_type":"code","source":["\n","print(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRueMmaYFamD","executionInfo":{"status":"ok","timestamp":1679272063269,"user_tz":420,"elapsed":13,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"acf66230-4c92-417d-e769-a196a8f4994b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 81614\n","})\n"]}]},{"cell_type":"code","source":["print(len(train_data[0]['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVc3xgHXFdk4","executionInfo":{"status":"ok","timestamp":1679272063270,"user_tz":420,"elapsed":9,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"5637ae0f-8609-4511-c662-e4b236c17e18"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["256\n"]}]},{"cell_type":"code","source":["fixed_validation_index = 17\n","fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n","fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"aYSn2PZcA4Pa","executionInfo":{"status":"ok","timestamp":1679272063270,"user_tz":420,"elapsed":7,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["batch_size=4\n","dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","                                         shuffle=True)\n","for i, data in enumerate(dataloader, 0):\n","  print(torch.stack(data['attention_mask']).shape)\n","  break\n"],"metadata":{"id":"OTM_7TRDEuwr","executionInfo":{"status":"ok","timestamp":1679272104092,"user_tz":420,"elapsed":135,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5d6d8d6-8077-40b9-c317-620e15e53c9d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([256, 4])\n"]}]},{"cell_type":"code","source":["# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i, data in enumerate(dataloader, 0):\n","#         #data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         #print(data)\n","#         print(data['labels'])\n","#         real_cpu = torch.stack(data['labels'])\n","#         #real_cpu = torch.unsqueeze(real_cpu, dim=0)\n","#         #real_cpu = torch.cat(real_cpu, dim=0)\n","#         #real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.type(torch.FloatTensor).view(-1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         #inputs = train_df.iloc[i]['text']\n","#         #data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         data = {k : torch.stack(v) for k, v in data.items()}\n","#         fake = netG(**data)\n","\n","#         # fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"kpQNOHLX7dL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################ Changing the working data to validation ####################\n","\n","# Training Loop\n","\n","# Lists to keep track of progress\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","num_epochs = 1\n","max_input_length = 512\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # todo: batch this/use a dataloader\n","    for i in range(len(validation_data)):\n","        data = validation_data[i]\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        netD.zero_grad()\n","        # Format batch\n","        #print(len(data['labels']))\n","        real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","        #real_cpu = data['labels']\n","        #print(real_cpu.shape)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        #print(real_cpu.shape)\n","        real_cpu = real_cpu.view(1, 1, 64) #these are the comment tokens\n","        #print(real_cpu.shape)\n","        #print(real_cpu.shape)\n","        real_cpu = real_cpu.to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","        #discriminator will train off of true comments in the real batch pass\n","        # Forward pass real batch through D\n","        output = netD(real_cpu).view(-1) \n","        # Calculate loss on all-real batch\n","        errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        # print(inputs['input_ids'].shape)\n","        # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","        # Generate fake image batch with G\n","\n","        inputs = valid_df.iloc[i]['text']\n","        data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        #print(fake.shape)\n","        fake = fake.type(torch.float32)\n","        fake = fake.view(1, 1, -1)\n","        #print(fake.shape)\n","        #fake = correct_to_64(fake)\n","        #print(fake.shape)\n","        fake = fake.detach().to(device)\n","        output = netD(fake).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        if i % 5 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(validation_data),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        if iters == 5: netG.save_pretrained('pineapple/pineapple-initial-save')\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        if (iters != 0 and iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","            netG.save_pretrained('pineapple/pineapple-halfway')\n","            with torch.no_grad():\n","                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1\n","\n","netG.save_pretrained('pineapple/pineapple-full')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7CIqDPACJV9","outputId":"a11adaa9-e2d0-40c8-d6b9-b4d40551c088","executionInfo":{"status":"ok","timestamp":1679278637458,"user_tz":420,"elapsed":6524757,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training Loop...\n","[0/1][0/998]\tLoss_D: 1.3979\tLoss_G: 1.0473\tD(x): 0.5657\tD(G(z)): 0.5632 / 0.3509\n","[0/1][5/998]\tLoss_D: 2.1694\tLoss_G: 0.7613\tD(x): 0.4147\tD(G(z)): 0.7245 / 0.4671\n","[0/1][10/998]\tLoss_D: 1.7153\tLoss_G: 0.7108\tD(x): 0.4136\tD(G(z)): 0.5650 / 0.4912\n","[0/1][15/998]\tLoss_D: 1.2648\tLoss_G: 1.2467\tD(x): 0.3801\tD(G(z)): 0.2572 / 0.2874\n","[0/1][20/998]\tLoss_D: 1.9756\tLoss_G: 1.2152\tD(x): 0.3145\tD(G(z)): 0.5590 / 0.2967\n","[0/1][25/998]\tLoss_D: 1.6681\tLoss_G: 0.5402\tD(x): 0.6364\tD(G(z)): 0.7036 / 0.5827\n","[0/1][30/998]\tLoss_D: 1.7606\tLoss_G: 0.4695\tD(x): 0.5831\tD(G(z)): 0.7051 / 0.6253\n","[0/1][35/998]\tLoss_D: 0.8031\tLoss_G: 1.8999\tD(x): 0.6768\tD(G(z)): 0.3382 / 0.1496\n","[0/1][40/998]\tLoss_D: 0.5026\tLoss_G: 2.7055\tD(x): 0.6407\tD(G(z)): 0.0558 / 0.0668\n","[0/1][45/998]\tLoss_D: 1.6420\tLoss_G: 0.7098\tD(x): 0.5200\tD(G(z)): 0.6278 / 0.4918\n","[0/1][50/998]\tLoss_D: 1.5490\tLoss_G: 2.0841\tD(x): 0.3529\tD(G(z)): 0.3979 / 0.1244\n","[0/1][55/998]\tLoss_D: 2.6368\tLoss_G: 0.8763\tD(x): 0.0801\tD(G(z)): 0.1057 / 0.4163\n","[0/1][60/998]\tLoss_D: 1.2476\tLoss_G: 0.9771\tD(x): 0.6563\tD(G(z)): 0.5624 / 0.3764\n","[0/1][65/998]\tLoss_D: 1.1878\tLoss_G: 0.6964\tD(x): 0.6037\tD(G(z)): 0.4950 / 0.4984\n","[0/1][70/998]\tLoss_D: 1.1209\tLoss_G: 0.8369\tD(x): 0.6671\tD(G(z)): 0.5113 / 0.4330\n","[0/1][75/998]\tLoss_D: 1.3768\tLoss_G: 0.6783\tD(x): 0.6408\tD(G(z)): 0.6062 / 0.5075\n","[0/1][80/998]\tLoss_D: 1.1787\tLoss_G: 1.3019\tD(x): 0.5288\tD(G(z)): 0.4181 / 0.2720\n","[0/1][85/998]\tLoss_D: 0.7736\tLoss_G: 1.4156\tD(x): 0.5693\tD(G(z)): 0.1896 / 0.2428\n","[0/1][90/998]\tLoss_D: 0.7571\tLoss_G: 1.8411\tD(x): 0.6852\tD(G(z)): 0.3155 / 0.1586\n","[0/1][95/998]\tLoss_D: 0.4334\tLoss_G: 2.1671\tD(x): 0.7835\tD(G(z)): 0.1725 / 0.1145\n","[0/1][100/998]\tLoss_D: 0.2747\tLoss_G: 2.8147\tD(x): 0.8122\tD(G(z)): 0.0645 / 0.0599\n","[0/1][105/998]\tLoss_D: 0.1900\tLoss_G: 2.6668\tD(x): 0.9021\tD(G(z)): 0.0833 / 0.0695\n","[0/1][110/998]\tLoss_D: 0.5747\tLoss_G: 3.1049\tD(x): 0.9415\tD(G(z)): 0.4022 / 0.0448\n","[0/1][115/998]\tLoss_D: 2.2746\tLoss_G: 2.0468\tD(x): 0.1170\tD(G(z)): 0.1210 / 0.1291\n","[0/1][120/998]\tLoss_D: 1.9857\tLoss_G: 1.7850\tD(x): 0.1714\tD(G(z)): 0.1989 / 0.1678\n","[0/1][125/998]\tLoss_D: 2.0722\tLoss_G: 0.6943\tD(x): 0.3027\tD(G(z)): 0.5841 / 0.4994\n","[0/1][130/998]\tLoss_D: 1.3861\tLoss_G: 1.0058\tD(x): 0.4222\tD(G(z)): 0.4077 / 0.3658\n","[0/1][135/998]\tLoss_D: 0.6557\tLoss_G: 1.4681\tD(x): 0.6951\tD(G(z)): 0.2532 / 0.2304\n","[0/1][140/998]\tLoss_D: 0.7713\tLoss_G: 1.5311\tD(x): 0.7114\tD(G(z)): 0.3500 / 0.2163\n","[0/1][145/998]\tLoss_D: 2.3806\tLoss_G: 2.1029\tD(x): 0.0990\tD(G(z)): 0.0662 / 0.1221\n","[0/1][150/998]\tLoss_D: 1.6185\tLoss_G: 0.8379\tD(x): 0.6191\tD(G(z)): 0.6799 / 0.4326\n","[0/1][155/998]\tLoss_D: 1.4519\tLoss_G: 0.6888\tD(x): 0.7949\tD(G(z)): 0.7055 / 0.5022\n","[0/1][160/998]\tLoss_D: 2.6889\tLoss_G: 0.2422\tD(x): 0.3112\tD(G(z)): 0.7816 / 0.7849\n","[0/1][165/998]\tLoss_D: 0.8632\tLoss_G: 0.9116\tD(x): 0.7658\tD(G(z)): 0.4492 / 0.4019\n","[0/1][170/998]\tLoss_D: 1.2042\tLoss_G: 1.1611\tD(x): 0.4676\tD(G(z)): 0.3586 / 0.3131\n","[0/1][175/998]\tLoss_D: 0.7081\tLoss_G: 1.3999\tD(x): 0.7496\tD(G(z)): 0.3429 / 0.2466\n","[0/1][180/998]\tLoss_D: 0.8306\tLoss_G: 1.1954\tD(x): 0.7913\tD(G(z)): 0.4493 / 0.3026\n","[0/1][185/998]\tLoss_D: 0.5660\tLoss_G: 1.5476\tD(x): 0.8084\tD(G(z)): 0.2977 / 0.2128\n","[0/1][190/998]\tLoss_D: 2.0499\tLoss_G: 1.8156\tD(x): 0.1432\tD(G(z)): 0.1008 / 0.1627\n","[0/1][195/998]\tLoss_D: 2.3650\tLoss_G: 0.2019\tD(x): 0.9432\tD(G(z)): 0.9004 / 0.8172\n","[0/1][200/998]\tLoss_D: 2.1831\tLoss_G: 0.4694\tD(x): 0.8445\tD(G(z)): 0.8666 / 0.6254\n","[0/1][205/998]\tLoss_D: 0.9291\tLoss_G: 1.1275\tD(x): 0.7538\tD(G(z)): 0.4761 / 0.3238\n","[0/1][210/998]\tLoss_D: 0.4551\tLoss_G: 2.0187\tD(x): 0.7987\tD(G(z)): 0.2057 / 0.1328\n","[0/1][215/998]\tLoss_D: 0.3781\tLoss_G: 2.4462\tD(x): 0.9399\tD(G(z)): 0.2710 / 0.0866\n","[0/1][220/998]\tLoss_D: 0.6861\tLoss_G: 2.5609\tD(x): 0.8915\tD(G(z)): 0.4352 / 0.0772\n","[0/1][225/998]\tLoss_D: 0.2473\tLoss_G: 2.9479\tD(x): 0.9228\tD(G(z)): 0.1538 / 0.0524\n","[0/1][230/998]\tLoss_D: 0.1069\tLoss_G: 3.4796\tD(x): 0.9391\tD(G(z)): 0.0431 / 0.0308\n","[0/1][235/998]\tLoss_D: 0.1014\tLoss_G: 2.1362\tD(x): 0.9604\tD(G(z)): 0.0592 / 0.1181\n","[0/1][240/998]\tLoss_D: 0.1172\tLoss_G: 3.0730\tD(x): 0.9320\tD(G(z)): 0.0457 / 0.0463\n","[0/1][245/998]\tLoss_D: 1.5014\tLoss_G: 0.9561\tD(x): 0.5571\tD(G(z)): 0.6000 / 0.3844\n","[0/1][250/998]\tLoss_D: 0.5383\tLoss_G: 2.9928\tD(x): 0.6819\tD(G(z)): 0.1439 / 0.0501\n","[0/1][255/998]\tLoss_D: 0.3033\tLoss_G: 3.6378\tD(x): 0.7722\tD(G(z)): 0.0437 / 0.0263\n","[0/1][260/998]\tLoss_D: 0.6452\tLoss_G: 1.9575\tD(x): 0.9325\tD(G(z)): 0.4374 / 0.1412\n","[0/1][265/998]\tLoss_D: 1.6081\tLoss_G: 0.9893\tD(x): 0.9328\tD(G(z)): 0.7853 / 0.3719\n","[0/1][270/998]\tLoss_D: 1.0747\tLoss_G: 1.2570\tD(x): 0.4073\tD(G(z)): 0.1618 / 0.2845\n","[0/1][275/998]\tLoss_D: 2.4719\tLoss_G: 0.1719\tD(x): 0.9546\tD(G(z)): 0.9116 / 0.8421\n","[0/1][280/998]\tLoss_D: 1.4186\tLoss_G: 0.8517\tD(x): 0.7990\tD(G(z)): 0.6970 / 0.4267\n","[0/1][285/998]\tLoss_D: 0.4792\tLoss_G: 2.4412\tD(x): 0.6722\tD(G(z)): 0.0787 / 0.0871\n","[0/1][290/998]\tLoss_D: 0.8300\tLoss_G: 1.2644\tD(x): 0.7848\tD(G(z)): 0.4444 / 0.2824\n","[0/1][295/998]\tLoss_D: 0.2492\tLoss_G: 1.2975\tD(x): 0.9211\tD(G(z)): 0.1539 / 0.2732\n","[0/1][300/998]\tLoss_D: 0.6894\tLoss_G: 2.5266\tD(x): 0.5375\tD(G(z)): 0.0662 / 0.0799\n","[0/1][305/998]\tLoss_D: 0.1420\tLoss_G: 2.5567\tD(x): 0.9710\tD(G(z)): 0.1065 / 0.0776\n","[0/1][310/998]\tLoss_D: 2.2348\tLoss_G: 0.9521\tD(x): 0.9790\tD(G(z)): 0.8907 / 0.3859\n","[0/1][315/998]\tLoss_D: 1.2418\tLoss_G: 0.9963\tD(x): 0.8378\tD(G(z)): 0.6552 / 0.3692\n","[0/1][320/998]\tLoss_D: 2.1676\tLoss_G: 1.4836\tD(x): 0.5825\tD(G(z)): 0.8035 / 0.2268\n","[0/1][325/998]\tLoss_D: 0.8943\tLoss_G: 1.1763\tD(x): 0.5789\tD(G(z)): 0.2937 / 0.3084\n","[0/1][330/998]\tLoss_D: 0.8617\tLoss_G: 1.2666\tD(x): 0.7205\tD(G(z)): 0.4137 / 0.2818\n","[0/1][335/998]\tLoss_D: 0.2840\tLoss_G: 2.0278\tD(x): 0.9059\tD(G(z)): 0.1690 / 0.1316\n","[0/1][340/998]\tLoss_D: 0.1790\tLoss_G: 1.5766\tD(x): 0.9683\tD(G(z)): 0.1365 / 0.2067\n","[0/1][345/998]\tLoss_D: 0.8444\tLoss_G: 1.3373\tD(x): 0.7474\tD(G(z)): 0.4249 / 0.2625\n","[0/1][350/998]\tLoss_D: 0.8658\tLoss_G: 2.4882\tD(x): 0.4876\tD(G(z)): 0.1371 / 0.0831\n","[0/1][355/998]\tLoss_D: 0.5784\tLoss_G: 1.2392\tD(x): 0.9644\tD(G(z)): 0.4185 / 0.2896\n","[0/1][360/998]\tLoss_D: 0.1596\tLoss_G: 2.3119\tD(x): 0.9475\tD(G(z)): 0.1003 / 0.0991\n","[0/1][365/998]\tLoss_D: 0.1233\tLoss_G: 1.9647\tD(x): 0.9851\tD(G(z)): 0.1027 / 0.1402\n","[0/1][370/998]\tLoss_D: 1.4044\tLoss_G: 0.6080\tD(x): 0.3187\tD(G(z)): 0.2297 / 0.5444\n","[0/1][375/998]\tLoss_D: 0.1020\tLoss_G: 3.0436\tD(x): 0.9793\tD(G(z)): 0.0778 / 0.0477\n","[0/1][380/998]\tLoss_D: 3.8098\tLoss_G: 2.3084\tD(x): 0.0329\tD(G(z)): 0.3265 / 0.0994\n","[0/1][385/998]\tLoss_D: 2.1620\tLoss_G: 1.8993\tD(x): 0.1247\tD(G(z)): 0.0769 / 0.1497\n","[0/1][390/998]\tLoss_D: 0.4884\tLoss_G: 1.1351\tD(x): 0.9551\tD(G(z)): 0.3575 / 0.3214\n","[0/1][395/998]\tLoss_D: 1.0849\tLoss_G: 0.8420\tD(x): 0.6018\tD(G(z)): 0.4384 / 0.4308\n","[0/1][400/998]\tLoss_D: 0.7341\tLoss_G: 1.0990\tD(x): 0.7725\tD(G(z)): 0.3788 / 0.3332\n","[0/1][405/998]\tLoss_D: 0.3932\tLoss_G: 1.0256\tD(x): 0.9714\tD(G(z)): 0.3053 / 0.3586\n","[0/1][410/998]\tLoss_D: 1.6614\tLoss_G: 0.8486\tD(x): 0.4544\tD(G(z)): 0.5821 / 0.4280\n","[0/1][415/998]\tLoss_D: 0.6322\tLoss_G: 0.7376\tD(x): 0.9788\tD(G(z)): 0.4571 / 0.4782\n","[0/1][420/998]\tLoss_D: 0.5469\tLoss_G: 1.2680\tD(x): 0.8989\tD(G(z)): 0.3562 / 0.2814\n","[0/1][425/998]\tLoss_D: 0.3632\tLoss_G: 1.2977\tD(x): 0.9812\tD(G(z)): 0.2912 / 0.2732\n","[0/1][430/998]\tLoss_D: 0.7151\tLoss_G: 1.3768\tD(x): 0.9872\tD(G(z)): 0.5045 / 0.2524\n","[0/1][435/998]\tLoss_D: 0.4028\tLoss_G: 2.1609\tD(x): 0.7440\tD(G(z)): 0.1016 / 0.1152\n","[0/1][440/998]\tLoss_D: 2.5953\tLoss_G: 1.5699\tD(x): 0.0811\tD(G(z)): 0.0795 / 0.2081\n","[0/1][445/998]\tLoss_D: 0.0985\tLoss_G: 2.6746\tD(x): 0.9856\tD(G(z)): 0.0806 / 0.0689\n","[0/1][450/998]\tLoss_D: 2.6806\tLoss_G: 1.9633\tD(x): 0.0740\tD(G(z)): 0.0745 / 0.1404\n","[0/1][455/998]\tLoss_D: 0.6247\tLoss_G: 1.0634\tD(x): 0.6838\tD(G(z)): 0.2170 / 0.3453\n","[0/1][460/998]\tLoss_D: 0.3510\tLoss_G: 1.6937\tD(x): 0.9837\tD(G(z)): 0.2844 / 0.1838\n","[0/1][465/998]\tLoss_D: 1.8654\tLoss_G: 1.7143\tD(x): 0.1742\tD(G(z)): 0.1113 / 0.1801\n","[0/1][470/998]\tLoss_D: 0.2391\tLoss_G: 2.4811\tD(x): 0.9757\tD(G(z)): 0.1930 / 0.0836\n","[0/1][475/998]\tLoss_D: 0.1420\tLoss_G: 2.1425\tD(x): 0.9779\tD(G(z)): 0.1128 / 0.1174\n","[0/1][480/998]\tLoss_D: 0.0923\tLoss_G: 2.4884\tD(x): 0.9819\tD(G(z)): 0.0714 / 0.0830\n","[0/1][485/998]\tLoss_D: 0.1402\tLoss_G: 2.1737\tD(x): 0.9776\tD(G(z)): 0.1109 / 0.1138\n","[0/1][490/998]\tLoss_D: 1.3787\tLoss_G: 0.4322\tD(x): 0.7209\tD(G(z)): 0.6506 / 0.6491\n","[0/1][495/998]\tLoss_D: 1.8030\tLoss_G: 1.5253\tD(x): 0.2699\tD(G(z)): 0.3893 / 0.2175\n","[0/1][500/998]\tLoss_D: 1.3405\tLoss_G: 1.0320\tD(x): 0.4037\tD(G(z)): 0.3517 / 0.3563\n","[0/1][505/998]\tLoss_D: 1.6100\tLoss_G: 0.7876\tD(x): 0.4226\tD(G(z)): 0.5270 / 0.4549\n","[0/1][510/998]\tLoss_D: 1.5831\tLoss_G: 1.2365\tD(x): 0.2873\tD(G(z)): 0.2852 / 0.2904\n","[0/1][515/998]\tLoss_D: 1.4122\tLoss_G: 0.7010\tD(x): 0.4061\tD(G(z)): 0.4002 / 0.4961\n","[0/1][520/998]\tLoss_D: 0.3576\tLoss_G: 1.5317\tD(x): 0.8994\tD(G(z)): 0.2224 / 0.2162\n","[0/1][525/998]\tLoss_D: 0.8349\tLoss_G: 1.0693\tD(x): 0.5778\tD(G(z)): 0.2490 / 0.3433\n","[0/1][530/998]\tLoss_D: 0.8325\tLoss_G: 2.0971\tD(x): 0.5318\tD(G(z)): 0.1821 / 0.1228\n","[0/1][535/998]\tLoss_D: 1.4262\tLoss_G: 2.6172\tD(x): 0.2565\tD(G(z)): 0.0634 / 0.0730\n","[0/1][540/998]\tLoss_D: 1.4985\tLoss_G: 0.8648\tD(x): 0.3180\tD(G(z)): 0.2974 / 0.4211\n","[0/1][545/998]\tLoss_D: 0.7638\tLoss_G: 0.9299\tD(x): 0.7971\tD(G(z)): 0.4155 / 0.3946\n","[0/1][550/998]\tLoss_D: 0.2000\tLoss_G: 2.4511\tD(x): 0.9473\tD(G(z)): 0.1357 / 0.0862\n","[0/1][555/998]\tLoss_D: 0.6233\tLoss_G: 2.0216\tD(x): 0.8458\tD(G(z)): 0.3661 / 0.1324\n","[0/1][560/998]\tLoss_D: 1.5030\tLoss_G: 1.8292\tD(x): 0.9570\tD(G(z)): 0.7675 / 0.1605\n","[0/1][565/998]\tLoss_D: 2.4365\tLoss_G: 0.4399\tD(x): 0.2767\tD(G(z)): 0.6839 / 0.6441\n","[0/1][570/998]\tLoss_D: 1.0084\tLoss_G: 1.1009\tD(x): 0.5607\tD(G(z)): 0.3494 / 0.3326\n","[0/1][575/998]\tLoss_D: 0.4445\tLoss_G: 1.2248\tD(x): 0.9621\tD(G(z)): 0.3336 / 0.2938\n","[0/1][580/998]\tLoss_D: 0.7638\tLoss_G: 1.3563\tD(x): 0.8794\tD(G(z)): 0.4702 / 0.2576\n","[0/1][585/998]\tLoss_D: 3.5029\tLoss_G: 1.7531\tD(x): 0.0957\tD(G(z)): 0.6855 / 0.1732\n","[0/1][590/998]\tLoss_D: 1.5928\tLoss_G: 1.7326\tD(x): 0.2359\tD(G(z)): 0.1379 / 0.1768\n","[0/1][595/998]\tLoss_D: 0.5324\tLoss_G: 1.4254\tD(x): 0.9806\tD(G(z)): 0.4012 / 0.2404\n","[0/1][600/998]\tLoss_D: 0.1438\tLoss_G: 2.1698\tD(x): 0.9797\tD(G(z)): 0.1159 / 0.1142\n","[0/1][605/998]\tLoss_D: 2.4701\tLoss_G: 2.5232\tD(x): 0.0905\tD(G(z)): 0.0650 / 0.0802\n","[0/1][610/998]\tLoss_D: 0.1222\tLoss_G: 2.3557\tD(x): 0.9646\tD(G(z)): 0.0825 / 0.0948\n","[0/1][615/998]\tLoss_D: 1.6590\tLoss_G: 0.9404\tD(x): 0.3434\tD(G(z)): 0.4457 / 0.3905\n","[0/1][620/998]\tLoss_D: 0.3258\tLoss_G: 1.8780\tD(x): 0.8804\tD(G(z)): 0.1799 / 0.1529\n","[0/1][625/998]\tLoss_D: 0.1640\tLoss_G: 1.7588\tD(x): 0.9428\tD(G(z)): 0.0998 / 0.1723\n","[0/1][630/998]\tLoss_D: 3.8604\tLoss_G: 1.7860\tD(x): 0.9852\tD(G(z)): 0.9786 / 0.1676\n","[0/1][635/998]\tLoss_D: 0.1913\tLoss_G: 2.8880\tD(x): 0.8758\tD(G(z)): 0.0570 / 0.0557\n","[0/1][640/998]\tLoss_D: 0.9944\tLoss_G: 2.8965\tD(x): 0.3906\tD(G(z)): 0.0529 / 0.0552\n","[0/1][645/998]\tLoss_D: 0.3591\tLoss_G: 2.4677\tD(x): 0.9516\tD(G(z)): 0.2662 / 0.0848\n","[0/1][650/998]\tLoss_D: 1.6491\tLoss_G: 1.1810\tD(x): 0.2011\tD(G(z)): 0.0439 / 0.3070\n","[0/1][655/998]\tLoss_D: 0.0945\tLoss_G: 3.1477\tD(x): 0.9545\tD(G(z)): 0.0467 / 0.0429\n","[0/1][660/998]\tLoss_D: 0.5785\tLoss_G: 2.5429\tD(x): 0.9793\tD(G(z)): 0.4274 / 0.0786\n","[0/1][665/998]\tLoss_D: 0.9050\tLoss_G: 2.9068\tD(x): 0.9557\tD(G(z)): 0.5767 / 0.0547\n","[0/1][670/998]\tLoss_D: 0.1097\tLoss_G: 2.6858\tD(x): 0.9460\tD(G(z)): 0.0528 / 0.0682\n","[0/1][675/998]\tLoss_D: 0.1342\tLoss_G: 2.6363\tD(x): 0.9404\tD(G(z)): 0.0702 / 0.0716\n","[0/1][680/998]\tLoss_D: 0.0948\tLoss_G: 2.9093\tD(x): 0.9578\tD(G(z)): 0.0504 / 0.0545\n","[0/1][685/998]\tLoss_D: 0.1841\tLoss_G: 2.4469\tD(x): 0.8862\tD(G(z)): 0.0613 / 0.0866\n","[0/1][690/998]\tLoss_D: 2.1661\tLoss_G: 0.6409\tD(x): 0.1440\tD(G(z)): 0.2038 / 0.5268\n","[0/1][695/998]\tLoss_D: 3.2891\tLoss_G: 0.1960\tD(x): 0.9324\tD(G(z)): 0.9600 / 0.8220\n","[0/1][700/998]\tLoss_D: 0.3262\tLoss_G: 1.9069\tD(x): 0.8109\tD(G(z)): 0.1101 / 0.1485\n","[0/1][705/998]\tLoss_D: 1.5294\tLoss_G: 0.8810\tD(x): 0.8068\tD(G(z)): 0.7315 / 0.4144\n","[0/1][710/998]\tLoss_D: 0.9894\tLoss_G: 0.8384\tD(x): 0.6295\tD(G(z)): 0.4093 / 0.4324\n","[0/1][715/998]\tLoss_D: 0.4546\tLoss_G: 1.5063\tD(x): 0.9153\tD(G(z)): 0.3065 / 0.2217\n","[0/1][720/998]\tLoss_D: 0.1777\tLoss_G: 2.1652\tD(x): 0.9542\tD(G(z)): 0.1227 / 0.1147\n","[0/1][725/998]\tLoss_D: 0.7855\tLoss_G: 2.6438\tD(x): 0.5117\tD(G(z)): 0.1091 / 0.0711\n","[0/1][730/998]\tLoss_D: 0.2267\tLoss_G: 2.2328\tD(x): 0.9611\tD(G(z)): 0.1706 / 0.1072\n","[0/1][735/998]\tLoss_D: 0.1613\tLoss_G: 2.1933\tD(x): 0.9565\tD(G(z)): 0.1103 / 0.1115\n","[0/1][740/998]\tLoss_D: 0.1286\tLoss_G: 3.2455\tD(x): 0.9466\tD(G(z)): 0.0711 / 0.0389\n","[0/1][745/998]\tLoss_D: 0.0858\tLoss_G: 3.3250\tD(x): 0.9633\tD(G(z)): 0.0473 / 0.0360\n","[0/1][750/998]\tLoss_D: 0.1355\tLoss_G: 2.5584\tD(x): 0.9218\tD(G(z)): 0.0527 / 0.0774\n","[0/1][755/998]\tLoss_D: 0.1759\tLoss_G: 2.9868\tD(x): 0.9056\tD(G(z)): 0.0739 / 0.0505\n","[0/1][760/998]\tLoss_D: 0.7397\tLoss_G: 0.5311\tD(x): 0.6284\tD(G(z)): 0.2405 / 0.5880\n","[0/1][765/998]\tLoss_D: 0.8454\tLoss_G: 2.8354\tD(x): 0.5632\tD(G(z)): 0.2376 / 0.0587\n","[0/1][770/998]\tLoss_D: 0.0913\tLoss_G: 2.1698\tD(x): 0.9670\tD(G(z)): 0.0561 / 0.1142\n","[0/1][775/998]\tLoss_D: 0.0544\tLoss_G: 3.1597\tD(x): 0.9774\tD(G(z)): 0.0311 / 0.0424\n","[0/1][780/998]\tLoss_D: 3.4996\tLoss_G: 3.1563\tD(x): 0.0312\tD(G(z)): 0.0312 / 0.0426\n","[0/1][785/998]\tLoss_D: 0.0752\tLoss_G: 3.2184\tD(x): 0.9807\tD(G(z)): 0.0542 / 0.0400\n","[0/1][790/998]\tLoss_D: 0.0815\tLoss_G: 2.9602\tD(x): 0.9686\tD(G(z)): 0.0484 / 0.0518\n","[0/1][795/998]\tLoss_D: 0.6233\tLoss_G: 2.6956\tD(x): 0.5961\tD(G(z)): 0.1006 / 0.0675\n","[0/1][800/998]\tLoss_D: 0.1419\tLoss_G: 2.3624\tD(x): 0.9520\tD(G(z)): 0.0885 / 0.0942\n","[0/1][805/998]\tLoss_D: 1.0652\tLoss_G: 0.7723\tD(x): 0.9186\tD(G(z)): 0.6248 / 0.4620\n","[0/1][810/998]\tLoss_D: 1.2017\tLoss_G: 0.3914\tD(x): 0.7965\tD(G(z)): 0.6225 / 0.6761\n","[0/1][815/998]\tLoss_D: 1.7476\tLoss_G: 2.0200\tD(x): 0.1977\tD(G(z)): 0.1189 / 0.1327\n","[0/1][820/998]\tLoss_D: 0.2963\tLoss_G: 1.6759\tD(x): 0.9356\tD(G(z)): 0.2053 / 0.1871\n","[0/1][825/998]\tLoss_D: 0.2233\tLoss_G: 2.2356\tD(x): 0.9329\tD(G(z)): 0.1426 / 0.1069\n","[0/1][830/998]\tLoss_D: 0.1990\tLoss_G: 2.2762\tD(x): 0.8889\tD(G(z)): 0.0780 / 0.1027\n","[0/1][835/998]\tLoss_D: 0.1027\tLoss_G: 2.5075\tD(x): 0.9690\tD(G(z)): 0.0688 / 0.0815\n","[0/1][840/998]\tLoss_D: 0.0865\tLoss_G: 2.4908\tD(x): 0.9735\tD(G(z)): 0.0580 / 0.0828\n","[0/1][845/998]\tLoss_D: 1.0398\tLoss_G: 2.9123\tD(x): 0.3767\tD(G(z)): 0.0614 / 0.0543\n","[0/1][850/998]\tLoss_D: 0.1561\tLoss_G: 1.3116\tD(x): 0.9557\tD(G(z)): 0.1049 / 0.2694\n","[0/1][855/998]\tLoss_D: 0.0977\tLoss_G: 2.8410\tD(x): 0.9760\tD(G(z)): 0.0708 / 0.0584\n","[0/1][860/998]\tLoss_D: 0.1068\tLoss_G: 2.5076\tD(x): 0.9517\tD(G(z)): 0.0557 / 0.0815\n","[0/1][865/998]\tLoss_D: 0.9025\tLoss_G: 1.4059\tD(x): 0.5390\tD(G(z)): 0.2475 / 0.2451\n","[0/1][870/998]\tLoss_D: 0.2813\tLoss_G: 2.3809\tD(x): 0.9029\tD(G(z)): 0.1641 / 0.0925\n","[0/1][875/998]\tLoss_D: 0.4087\tLoss_G: 1.6878\tD(x): 0.8003\tD(G(z)): 0.1696 / 0.1849\n","[0/1][880/998]\tLoss_D: 0.2860\tLoss_G: 1.6434\tD(x): 0.9701\tD(G(z)): 0.2256 / 0.1933\n","[0/1][885/998]\tLoss_D: 1.4842\tLoss_G: 1.6423\tD(x): 0.2572\tD(G(z)): 0.1187 / 0.1935\n","[0/1][890/998]\tLoss_D: 0.8259\tLoss_G: 1.0578\tD(x): 0.7719\tD(G(z)): 0.4327 / 0.3472\n","[0/1][895/998]\tLoss_D: 0.6261\tLoss_G: 1.2940\tD(x): 0.8494\tD(G(z)): 0.3705 / 0.2742\n","[0/1][900/998]\tLoss_D: 0.3109\tLoss_G: 1.7462\tD(x): 0.9823\tD(G(z)): 0.2541 / 0.1744\n","[0/1][905/998]\tLoss_D: 0.2565\tLoss_G: 1.3450\tD(x): 0.9836\tD(G(z)): 0.2133 / 0.2605\n","[0/1][910/998]\tLoss_D: 1.0664\tLoss_G: 2.0568\tD(x): 0.3777\tD(G(z)): 0.0885 / 0.1279\n","[0/1][915/998]\tLoss_D: 0.1307\tLoss_G: 2.8933\tD(x): 0.9351\tD(G(z)): 0.0616 / 0.0554\n","[0/1][920/998]\tLoss_D: 0.2044\tLoss_G: 2.4066\tD(x): 0.9737\tD(G(z)): 0.1629 / 0.0901\n","[0/1][925/998]\tLoss_D: 1.9184\tLoss_G: 2.6526\tD(x): 0.1526\tD(G(z)): 0.0377 / 0.0705\n","[0/1][930/998]\tLoss_D: 0.6613\tLoss_G: 1.7702\tD(x): 0.9780\tD(G(z)): 0.4722 / 0.1703\n","[0/1][935/998]\tLoss_D: 3.0884\tLoss_G: 0.3132\tD(x): 0.9847\tD(G(z)): 0.9537 / 0.7311\n","[0/1][940/998]\tLoss_D: 2.5285\tLoss_G: 2.6473\tD(x): 0.0895\tD(G(z)): 0.1090 / 0.0708\n","[0/1][945/998]\tLoss_D: 0.1026\tLoss_G: 3.1964\tD(x): 0.9656\tD(G(z)): 0.0654 / 0.0409\n","[0/1][950/998]\tLoss_D: 0.5323\tLoss_G: 2.9657\tD(x): 0.7116\tD(G(z)): 0.1748 / 0.0515\n","[0/1][955/998]\tLoss_D: 0.6518\tLoss_G: 1.4100\tD(x): 0.9670\tD(G(z)): 0.4611 / 0.2441\n","[0/1][960/998]\tLoss_D: 0.7339\tLoss_G: 1.4239\tD(x): 0.8180\tD(G(z)): 0.4132 / 0.2408\n","[0/1][965/998]\tLoss_D: 1.1349\tLoss_G: 1.7700\tD(x): 0.3701\tD(G(z)): 0.1314 / 0.1703\n","[0/1][970/998]\tLoss_D: 1.0180\tLoss_G: 2.2245\tD(x): 0.4032\tD(G(z)): 0.1038 / 0.1081\n","[0/1][975/998]\tLoss_D: 0.1106\tLoss_G: 3.1203\tD(x): 0.9460\tD(G(z)): 0.0537 / 0.0441\n","[0/1][980/998]\tLoss_D: 0.2492\tLoss_G: 3.4321\tD(x): 0.8134\tD(G(z)): 0.0418 / 0.0323\n","[0/1][985/998]\tLoss_D: 0.1298\tLoss_G: 3.3772\tD(x): 0.9061\tD(G(z)): 0.0308 / 0.0341\n","[0/1][990/998]\tLoss_D: 0.1233\tLoss_G: 3.3739\tD(x): 0.9103\tD(G(z)): 0.0289 / 0.0343\n","[0/1][995/998]\tLoss_D: 0.5147\tLoss_G: 3.6426\tD(x): 0.9068\tD(G(z)): 0.3408 / 0.0262\n"]}]},{"cell_type":"code","source":["# ################ WORKING DO NOT TOUCH ####################\n","\n","# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i in range(len(train_data)):\n","#         data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.view(1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         inputs = train_df.iloc[i]['text']\n","#         data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"bZkK8xM0FBpM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QxIWu1TqEse1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","\n","# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# print(input.shape)\n","# m = nn.Upsample(size=(64, 64))\n","# output = m(input)\n","# output = output.reshape((1, 64, 64))\n","# print(output.shape)\n","\n","# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"id":"0zmQecWWiUWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"id":"0ZdysfkciVDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# m = nn.Upsample(size=(64, 64))\n","# intermediate = m(input)\n","# x = nn.Flatten(0, 1)\n","# output = x(intermediate)\n","# print(input.shape)\n","# print(intermediate.shape)\n","# print(output.shape)"],"metadata":{"id":"0P87XbnOkEOm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8BIW0Ev3m4b0"},"execution_count":null,"outputs":[]}]}