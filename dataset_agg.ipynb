{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVc62RP4hg0n84YTZSd1Ms"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1yYuBKo-ruvY","executionInfo":{"status":"ok","timestamp":1677824952863,"user_tz":480,"elapsed":23585,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"936f32ff-d90a-483b-a70d-9be3614b6f1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/CS 224N/CS 224N Project\n","'224N Project Brainstorm.gdoc'\t\t\t\t csvs\n","'224N Project Helpful Tutorials.gdoc'\t\t\t dataset_agg.ipynb\n","'224N Project Milestone Notes.gdoc'\t\t\t'first proposal OLD'\n"," aita_clean.csv\t\t\t\t\t\t gpt2-baseline.ipynb\n"," aita_comments.csv\t\t\t\t\t'Reddit Scraper.ipynb'\n"," bert-baseline\t\t\t\t\t\t T5-baseline.ipynb\n","'Copy of fine_tune_bart_summarization_two_langs.ipynb'\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/CS\\ 224N/CS\\ 224N\\ Project\n","! ls # verify that you are in the right directory"]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","path = os.listdir('csvs')\n","print(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U68RG61TtCRV","executionInfo":{"status":"ok","timestamp":1677749332127,"user_tz":480,"elapsed":716,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"7465ff5c-163a-4cb6-e885-2bc0fdd7779d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['comments_batch_8273.csv', 'comments_batch_11473.csv', 'comments_batch_4067.csv', 'comments_batch_15737.csv', 'comments_batch_19402.csv', 'comments_batch_21869.csv', 'comments_batch_60700.csv', 'comments_batch_62058.csv', 'comments_batch_24666.csv', 'comments_batch_62270.csv', 'comments_batch_63000.csv', 'comments_batch_25587.csv', 'comments_batch_63037.csv', 'comments_batch_64000.csv', 'comments_batch_65000.csv', 'comments_batch_26957.csv', 'comments_batch_33231.csv', 'comments_batch_65660.csv', 'comments_batch_66000.csv', 'comments_batch_27485.csv', 'comments_batch_66593.csv', 'comments_batch_33688.csv', 'comments_batch_67000.csv', 'comments_batch_68000.csv', 'comments_batch_69000.csv', 'comments_batch_69361.csv', 'comments_batch_70000.csv', 'comments_batch_37064.csv', 'comments_batch_71000.csv', 'comments_batch_72000.csv', 'comments_batch_73000.csv', 'comments_batch_74000.csv', 'comments_batch_75000.csv', 'comments_batch_76000.csv', 'comments_batch_77000.csv', 'comments_batch_78000.csv', 'comments_batch_79000.csv', 'comments_batch_32000.csv', 'comments_batch_42558.csv', 'comments_batch_47966.csv', 'comments_batch_80000.csv', 'comments_batch_81000.csv', 'comments_batch_82000.csv', 'comments_batch_83000.csv', 'comments_batch_84000.csv', 'comments_batch_60000.csv', 'comments_batch_85000.csv', 'comments_batch_86000.csv', 'comments_batch_87000.csv', 'comments_batch_88000.csv', 'comments_batch_89000.csv', 'comments_batch_90000.csv', 'comments_batch_91000.csv', 'comments_batch_92000.csv', 'comments_batch_93000.csv', 'comments_batch_94000.csv', 'comments_batch_95000.csv', 'comments_batch_96000.csv', 'comments_batch_97000.csv']\n"]}]},{"cell_type":"code","source":["df = pd.DataFrame()\n","# %cd csvs\n","# ! ls\n","for i, f in enumerate(path):\n","  df_new = pd.read_csv(f)\n","  # df_new = pd.read_csv(os.path.join(os.getcwd(), f))\n","\n","  df = pd.concat([df, df_new])\n","\n","# remove duplicate ids\n","df = df.drop_duplicates(subset=['id'])\n","print(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5d0skmGmsCeR","executionInfo":{"status":"ok","timestamp":1677749359449,"user_tz":480,"elapsed":17811,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"3bba8159-e00a-4e77-a8a2-9d8b5ef973ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS 224N/CS 224N Project/csvs\n","comments_batch_11473.csv  comments_batch_63037.csv  comments_batch_80000.csv\n","comments_batch_15737.csv  comments_batch_64000.csv  comments_batch_81000.csv\n","comments_batch_19402.csv  comments_batch_65000.csv  comments_batch_82000.csv\n","comments_batch_21869.csv  comments_batch_65660.csv  comments_batch_8273.csv\n","comments_batch_24666.csv  comments_batch_66000.csv  comments_batch_83000.csv\n","comments_batch_25587.csv  comments_batch_66593.csv  comments_batch_84000.csv\n","comments_batch_26957.csv  comments_batch_67000.csv  comments_batch_85000.csv\n","comments_batch_27485.csv  comments_batch_68000.csv  comments_batch_86000.csv\n","comments_batch_32000.csv  comments_batch_69000.csv  comments_batch_87000.csv\n","comments_batch_33231.csv  comments_batch_69361.csv  comments_batch_88000.csv\n","comments_batch_33688.csv  comments_batch_70000.csv  comments_batch_89000.csv\n","comments_batch_37064.csv  comments_batch_71000.csv  comments_batch_90000.csv\n","comments_batch_4067.csv   comments_batch_72000.csv  comments_batch_91000.csv\n","comments_batch_42558.csv  comments_batch_73000.csv  comments_batch_92000.csv\n","comments_batch_47966.csv  comments_batch_74000.csv  comments_batch_93000.csv\n","comments_batch_60000.csv  comments_batch_75000.csv  comments_batch_94000.csv\n","comments_batch_60700.csv  comments_batch_76000.csv  comments_batch_95000.csv\n","comments_batch_62058.csv  comments_batch_77000.csv  comments_batch_96000.csv\n","comments_batch_62270.csv  comments_batch_78000.csv  comments_batch_97000.csv\n","comments_batch_63000.csv  comments_batch_79000.csv\n","       id                                           comments\n","0  9m1gfn  NTA. That being said, I think that there are w...\n","1  9m1ihv  NTA while your motives are far from pure ultim...\n","2  9m1w76  You were the asshole here, but I don't think y...\n","3  9m2m9k  One person in the street isn't a protest, in m...\n","4  9m31uc  I'd say it's borderline asshole behaviour. You...\n"]}]},{"cell_type":"code","source":["print(len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fd6kkjv1xcW0","executionInfo":{"status":"ok","timestamp":1677749359450,"user_tz":480,"elapsed":4,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"b602ae7d-023f-43bc-b4c5-3e9e47126468"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["87215\n"]}]},{"cell_type":"code","source":["# Remove any elements that are [deleted] from the dataframe\n","# also remove [removed] posts --> these are posts the mods deleted\n","df = df[~df['comments'].str.contains('\\[deleted\\]')]\n","print(len(df))\n","df = df[~df['comments'].str.contains('\\[removed\\]')]\n","print(len(df))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjgLJLGGyieB","executionInfo":{"status":"ok","timestamp":1677749365602,"user_tz":480,"elapsed":629,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"b7eaa819-6324-4d26-a9cf-f2d87a173cb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["84197\n","83929\n"]}]},{"cell_type":"code","source":["# %cd ..\n","df_clean = pd.read_csv(\"aita_clean.csv\")\n","print(len(df_clean))\n","df_combined = pd.merge(df, df_clean, on='id', how='inner')\n","print(len(df_combined))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gsIIAJo5xdH6","executionInfo":{"status":"ok","timestamp":1677749377558,"user_tz":480,"elapsed":6484,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"7c362686-c4e2-40bc-8eb6-acb1a68fbfee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS 224N/CS 224N Project\n","97628\n","83929\n"]}]},{"cell_type":"code","source":["# save the new data frame in a file called \"aita_comments.csv\"\n","df_combined.to_csv(\"/content/drive/MyDrive/CS 224N/CS 224N Project/aita_comments.csv\", index=False) "],"metadata":{"id":"0Ib0itN6zQeL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Conduct final preprocessing on our dataset to structure it appropriately for our generative model"],"metadata":{"id":"Rz1je-sWKFEM"}},{"cell_type":"code","source":["import os\n","import pandas as pd"],"metadata":{"id":"B2zZZy_xKEwj","executionInfo":{"status":"ok","timestamp":1677824954117,"user_tz":480,"elapsed":536,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"aita_comments.csv\")\n"],"metadata":{"id":"mvwA8h7xKQL3","executionInfo":{"status":"ok","timestamp":1677827084740,"user_tz":480,"elapsed":2851,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["df[\"text\"] = df[\"title\"].astype(str) +\". \"+ df[\"body\"].astype(str)\n","\n","# create a one hot vector for the verdicts\n","# [\"asshole\", \"everyone sucks\", \"no assholes here\", \"not the asshole\"]\n","# this gets changed to [\"v_yta\", \"v_esh\", \"v_nah\", \"v_nta\"] --> v stands for verdict and the verdict after is abbreviated\n","one_hot = pd.get_dummies(df['verdict'])\n","one_hot = one_hot.rename(columns = {'asshole': 'v_yta', 'everyone sucks': 'v_esh', 'no assholes here': 'v_nah', 'not the asshole': 'v_nta'})\n","\n","df = pd.concat([df, one_hot], axis=1)\n","\n","df = df[[\"text\", \"comments\", \"is_asshole\", \"v_yta\", \"v_esh\", \"v_nah\", \"v_nta\"]] # drop unused columns \n"],"metadata":{"id":"zRgk13KHKVy2","executionInfo":{"status":"ok","timestamp":1677827084930,"user_tz":480,"elapsed":192,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# normalize text length based on average and mean length of posts + title combo\n","avg_words = df['comments'].str.split().str.len().mean()\n","avg_words_text = df['text'].str.split().str.len().mean()\n","\n","print(f'Average comment length is: ${avg_words}')\n","print(f'Average text length is: ${avg_words_text}')\n","\n","median_words = df['comments'].str.split().str.len().median()\n","median_words_text = df['text'].str.split().str.len().median()\n","print(f'Median comment length is: ${median_words}')\n","print(f'Median text length is: ${median_words_text}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pL3apiESMRwG","executionInfo":{"status":"ok","timestamp":1677827094894,"user_tz":480,"elapsed":9966,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"e04aa9aa-34b7-415d-a58f-eed3f088e9f3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Average comment length is: $49.38626696374316\n","Average text length is: $348.63994566836254\n","Median comment length is: $38.0\n","Median text length is: $320.0\n"]}]},{"cell_type":"code","source":["cutoff = 350\n","num_long_comments = (df['text'].apply(lambda x: len(x.split(' '))) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))\n","# if we were to set our cap at 400, these are the number of comments that'd be \n","# affected. We also display the percent of the total that will get truncated\n","cutoff = 400\n","num_long_comments = (df['text'].apply(lambda x: len(x.split())) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))\n","\n","cutoff = 450\n","num_long_comments = (df['text'].apply(lambda x: len(x.split())) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))\n","\n","cutoff = 500\n","num_long_comments = (df['text'].apply(lambda x: len(x.split())) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))\n","\n","cutoff = 550\n","num_long_comments = (df['text'].apply(lambda x: len(x.split())) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))\n","\n","cutoff = 600\n","num_long_comments = (df['text'].apply(lambda x: len(x.split())) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zhu5Sy50OtaT","executionInfo":{"status":"ok","timestamp":1677827105272,"user_tz":480,"elapsed":9614,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"8bddd04f-5f6a-4088-f883-6c116befbd26"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of comments that are truncated with cutoff: 350 and its percentage of the total dataset\n","36335\n","0.43292544889132484\n","The number of comments that are truncated with cutoff: 400 and its percentage of the total dataset\n","29045\n","0.34606631795922743\n","The number of comments that are truncated with cutoff: 450 and its percentage of the total dataset\n","22501\n","0.2680956522775203\n","The number of comments that are truncated with cutoff: 500 and its percentage of the total dataset\n","17035\n","0.20296917632761025\n","The number of comments that are truncated with cutoff: 550 and its percentage of the total dataset\n","11847\n","0.14115502388923973\n","The number of comments that are truncated with cutoff: 600 and its percentage of the total dataset\n","4981\n","0.059347782053878875\n"]}]},{"cell_type":"markdown","source":["We chose 508 as the cutoff because the T5 baseline can support at most 512 words. We wanted to include the last 4 words as the prompt \"Am I the Asshole\" because our research found that including a prompt at the end of the text sample greatly helped generative models generate text. \n","\n","508 is also a healthy cutoff because less than 1/5 of our training data will be truncated, it's 19.335% to be exact. \n"],"metadata":{"id":"zA6cHQ5JSAAz"}},{"cell_type":"code","source":["cutoff = 508\n","num_long_comments = (df['text'].apply(lambda x: len(x.split())) > cutoff).sum()\n","print(f'The number of comments that are truncated with cutoff: {cutoff} and its percentage of the total dataset')\n","print(num_long_comments)\n","print(num_long_comments / len(df))\n","\n","# Truncate all the strings in the dataset longer than cutoff \n","df = df[df['text'].apply(lambda x: len(x.split(' ')) < cutoff)]\n","\n","# add a prompt to help generative model with prompt engineering \n","question = \". Am I the asshole?\"\n","df[\"text\"] = df[\"text\"].astype(str) + question\n","\n","avg_words_text_final = df['text'].str.split().str.len().mean()\n","print(f'Average text length is: ${avg_words_text_final}')\n","\n","median_words_text_final = df['text'].str.split().str.len().median()\n","print(f'Median text length is: ${median_words_text_final}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFO65emjPFj5","executionInfo":{"status":"ok","timestamp":1677827114136,"user_tz":480,"elapsed":8866,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"57263e09-1868-4b57-a32f-c93d1e90e13a"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["The number of comments that are truncated with cutoff: 508 and its percentage of the total dataset\n","16228\n","0.1933539062779254\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-31-16c128f5d091>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[\"text\"] = df[\"text\"].astype(str) + question\n"]},{"output_type":"stream","name":"stdout","text":["Average text length is: $287.85849626497327\n","Median text length is: $281.0\n"]}]},{"cell_type":"code","source":["#Split validation and test set\n","valid_set = df.sample(n = 1000)\n","df = df.loc[~df.index.isin(valid_set.index)]\n","\n","#Reset the indexes\n","valid_set = valid_set.reset_index()\n","df = df.reset_index()\n","\n","test_set = df.sample(n = 1000)\n","df = df.loc[~df.index.isin(test_set.index)]\n","\n","#Reset the indexes\n","test_set = test_set.reset_index()\n","df = df.reset_index()"],"metadata":{"id":"dFRMSeolS-Xl","executionInfo":{"status":"ok","timestamp":1677827371984,"user_tz":480,"elapsed":178,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# save the new data frames \"\n","df.to_csv(\"/content/drive/MyDrive/CS 224N/CS 224N Project/aita_train_set.csv\", index=False) \n","valid_set.to_csv(\"/content/drive/MyDrive/CS 224N/CS 224N Project/aita_valid_set.csv\", index=False)\n","test_set.to_csv(\"/content/drive/MyDrive/CS 224N/CS 224N Project/aita_test_set.csv\", index=False)"],"metadata":{"id":"CL87_zDyTKz0","executionInfo":{"status":"ok","timestamp":1677827377147,"user_tz":480,"elapsed":2941,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":33,"outputs":[]}]}