{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"04ade13d9c56478486cc606beb781a9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c8436f3b4d4450598f3937c9c65f0cf","IPY_MODEL_3e6e362c1e5942d0a73a568ef5dd9cba","IPY_MODEL_1e1b69b6dd954ca9b7f7dfdc3bb9d0ad"],"layout":"IPY_MODEL_2b0c0112ece746e8a58c4dd5d559a9fa"}},"5c8436f3b4d4450598f3937c9c65f0cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3d52793e87646039f546725ccdf9c9d","placeholder":"​","style":"IPY_MODEL_0728eddba6a34031a5d251059ed09cfb","value":"Map: 100%"}},"3e6e362c1e5942d0a73a568ef5dd9cba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_089a0afa9b494356bb8a50285ad158ab","max":81614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12b8638d0782442ca3eecd0982121329","value":81614}},"1e1b69b6dd954ca9b7f7dfdc3bb9d0ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8657eff6fc8c4d968a4c1e957f9ec4c8","placeholder":"​","style":"IPY_MODEL_acbd366ee54d410aa28b31a14ba322f1","value":" 81614/81614 [03:19&lt;00:00, 375.83 examples/s]"}},"2b0c0112ece746e8a58c4dd5d559a9fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d3d52793e87646039f546725ccdf9c9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0728eddba6a34031a5d251059ed09cfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"089a0afa9b494356bb8a50285ad158ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12b8638d0782442ca3eecd0982121329":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8657eff6fc8c4d968a4c1e957f9ec4c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acbd366ee54d410aa28b31a14ba322f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb62ae81de3749579348a27cd05e1bdc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75b6d0b11a2f47579d9d350d3e5c99a0","IPY_MODEL_cc3f876ce9984309b4c98d4d29b4379b","IPY_MODEL_371b2ea9d7ae432ca47018be4144cd6f"],"layout":"IPY_MODEL_8a02289762df49b1b9003de04c463890"}},"75b6d0b11a2f47579d9d350d3e5c99a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6efd9df62e3470c868ed02bfccb7e8d","placeholder":"​","style":"IPY_MODEL_75e1e26a5a97488b9af8270b71aaffc0","value":"Map: 100%"}},"cc3f876ce9984309b4c98d4d29b4379b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_12de38e1862146f490daa9110d2853e5","max":998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a0178a35e5146309f1e2ecb44d61500","value":998}},"371b2ea9d7ae432ca47018be4144cd6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00875ca27bbf4bf2a7ce09c62b09dda8","placeholder":"​","style":"IPY_MODEL_fa8656a382114f86b5987d2d3b4be10b","value":" 998/998 [00:02&lt;00:00, 465.89 examples/s]"}},"8a02289762df49b1b9003de04c463890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"a6efd9df62e3470c868ed02bfccb7e8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75e1e26a5a97488b9af8270b71aaffc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12de38e1862146f490daa9110d2853e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a0178a35e5146309f1e2ecb44d61500":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00875ca27bbf4bf2a7ce09c62b09dda8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa8656a382114f86b5987d2d3b4be10b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### GAN Attempt!"],"metadata":{"id":"l2vionRRzF_O"}},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JADRaL5b276C","executionInfo":{"status":"ok","timestamp":1679202924423,"user_tz":420,"elapsed":32482,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"fc49e1e0-76ba-4afe-a632-f0c589c479fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Setup\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n",")\n","import pandas as pd\n","from datasets import Dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ESRs9D8S2gd3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/CS\\ 224N\\ Project\n","%ls # verify that you are in the right directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txGRbtkd4IWq","executionInfo":{"status":"ok","timestamp":1679202964635,"user_tz":420,"elapsed":34082,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"2137a175-53ff-4d41-80ae-5d91a628640f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1x7bmzM_qtbj3CPKzenuwvwocK9KiZzWU/CS 224N Project\n","'224N Experiments (GAN on 998 Samples).gsheet'\n","'224N Project Brainstorm.gdoc'\n","\u001b[0m\u001b[01;36m'224N Project Helpful Tutorials.gdoc'\u001b[0m@\n","'224N Project Milestone Notes.gdoc'\n"," Adversarial-T5_Structure_1.ipynb\n"," aita_clean.csv\n"," aita_comments.csv\n"," aita_test_set.csv\n"," aita_test_set.gsheet\n"," aita_train_set.csv\n"," aita_valid_set.csv\n"," banana.ipynb\n"," \u001b[01;34mbart-base-checkpoint-204000\u001b[0m/\n"," bart-baseline-attempt2.ipynb\n"," \u001b[01;34mbart-checkpoint-5000\u001b[0m/\n"," bert-baseline.ipynb\n"," checkpoint.txt\n"," config.json\n"," \u001b[01;34mcsvs\u001b[0m/\n"," dataset_agg.ipynb\n"," \u001b[01;34mdrive\u001b[0m/\n"," Evaluate.ipynb\n","'experimenting with gumbel.ipynb'\n"," \u001b[01;34mfinetune-gpt2\u001b[0m/\n","\u001b[01;34m'first proposal OLD'\u001b[0m/\n"," gan-gen-trial\n"," gpt-2-attempt2.ipynb\n"," gpt2-attempt3.ipynb\n"," gpt2-baseline.ipynb\n"," \u001b[01;34mgpt2-small-rationale-generation\u001b[0m/\n"," gpt2-wt-5.ipynb\n"," \u001b[01;34mgrape\u001b[0m/\n"," grape.ipynb\n"," \u001b[01;34mlogs\u001b[0m/\n"," \u001b[01;34mmango\u001b[0m/\n"," Mango.ipynb\n"," Orange.ipynb\n"," Pear.ipynb\n"," \u001b[01;34mpineapple\u001b[0m/\n"," Pineapple.ipynb\n"," \u001b[01;34mprocessed-set-gpt2\u001b[0m/\n","'Reddit Scraper.ipynb'\n"," \u001b[01;34mresults\u001b[0m/\n"," rouge_scores.txt\n","\u001b[01;34m'screenshots bart'\u001b[0m/\n","\u001b[01;34m'screenshots t5'\u001b[0m/\n"," T5_Attempt_2.ipynb\n"," t5_attempt3.ipynb\n"," T5-baseline.ipynb\n"," \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define the generator (use the pre-trained BART implementation)\n","\"\"\"\n","\n","# bart-base checkpoint pre-trained on our dataset\n","# (can also try generically pre-trained bart base)\n","model_dir = 'bart-base-checkpoint-204000'\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","print(netG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RgiUTBezH2V","executionInfo":{"status":"ok","timestamp":1679202976064,"user_tz":420,"elapsed":11433,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"5c14c575-4ea0-4df6-e3ef-d8d6277cdcaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define convolutional discriminator\n","\"\"\"\n","\n","nc = 1\n","ndf = 64\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            #Reshaping input\n","            nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 64 --> 1, 1, 64, 64\n","            # input is (nc) x 64 x 64 | our input is 1 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        #print(len(input.shape))\n","        return self.main(input)"],"metadata":{"id":"XBPd1v0Q34Jn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ngpu = 1\n","netD = Discriminator(ngpu).to(device)"],"metadata":{"id":"F4fElnOc_aAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Loss functions and optimizers\n","\"\"\"\n","# Size of generator input\n","nz = 512\n","# Optim params\n","lr = 0.0002\n","beta1 = 0.5\n","\n","# Initialize BCELoss function\n","criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"mLLWvDY-7M96"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA0gynyNom7B"},"source":["train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n","valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n","test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_txt = Dataset.from_pandas(train_df)\n","validation_data_txt = Dataset.from_pandas(valid_df)\n","test_data_txt = Dataset.from_pandas(test_df)\n","print(train_data_txt)\n","print(validation_data_txt)\n","print(test_data_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf4cgIQL9uCA","executionInfo":{"status":"ok","timestamp":1679202984640,"user_tz":420,"elapsed":561,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"71a966e1-a868-4a72-ae69-a8c8a6c5fb8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 81614\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n","Dataset({\n","    features: ['text', 'comments'],\n","    num_rows: 998\n","})\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Preprocess\n","\"\"\"\n","\n","encoder_max_length = 256  # changed from 256\n","decoder_max_length = 64  # changed from 64\n","\n","def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"comments\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["04ade13d9c56478486cc606beb781a9a","5c8436f3b4d4450598f3937c9c65f0cf","3e6e362c1e5942d0a73a568ef5dd9cba","1e1b69b6dd954ca9b7f7dfdc3bb9d0ad","2b0c0112ece746e8a58c4dd5d559a9fa","d3d52793e87646039f546725ccdf9c9d","0728eddba6a34031a5d251059ed09cfb","089a0afa9b494356bb8a50285ad158ab","12b8638d0782442ca3eecd0982121329","8657eff6fc8c4d968a4c1e957f9ec4c8","acbd366ee54d410aa28b31a14ba322f1","fb62ae81de3749579348a27cd05e1bdc","75b6d0b11a2f47579d9d350d3e5c99a0","cc3f876ce9984309b4c98d4d29b4379b","371b2ea9d7ae432ca47018be4144cd6f","8a02289762df49b1b9003de04c463890","a6efd9df62e3470c868ed02bfccb7e8d","75e1e26a5a97488b9af8270b71aaffc0","12de38e1862146f490daa9110d2853e5","4a0178a35e5146309f1e2ecb44d61500","00875ca27bbf4bf2a7ce09c62b09dda8","fa8656a382114f86b5987d2d3b4be10b"]},"id":"wvBpN-KNAJ4x","executionInfo":{"status":"ok","timestamp":1679203186341,"user_tz":420,"elapsed":201711,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"576b29df-dadc-46af-8531-11c51e8b08e7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/81614 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ade13d9c56478486cc606beb781a9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/998 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb62ae81de3749579348a27cd05e1bdc"}},"metadata":{}}]},{"cell_type":"code","source":["print(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fRueMmaYFamD","executionInfo":{"status":"ok","timestamp":1679203186342,"user_tz":420,"elapsed":15,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"a6e5337a-e9b2-41dd-bd68-0474ce813ff8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['input_ids', 'attention_mask', 'labels'],\n","    num_rows: 81614\n","})\n"]}]},{"cell_type":"code","source":["print(len(train_data[0]['input_ids']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVc3xgHXFdk4","executionInfo":{"status":"ok","timestamp":1679203186343,"user_tz":420,"elapsed":11,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"700530f8-2efa-401d-ad35-0c0d8f2fd108"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["256\n"]}]},{"cell_type":"code","source":["fixed_validation_index = 17\n","fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n","fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"aYSn2PZcA4Pa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# batch_size=4\n","# dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","#                                          shuffle=True)\n","# for i, data in enumerate(dataloader, 0):\n","#   print(torch.stack(data['attention_mask']).shape)\n","#   break"],"metadata":{"id":"OTM_7TRDEuwr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################ Changing the working data to validation ####################\n","\n","# Training Loop\n","\n","# Lists to keep track of progress\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","num_epochs = 1\n","max_input_length = 512\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # todo: batch this/use a dataloader\n","    for i in range(len(validation_data)):\n","        data = validation_data[i]\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        netD.zero_grad()\n","        # Format batch\n","        #print(len(data['labels']))\n","        real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","        #real_cpu = data['labels']\n","        #print(real_cpu.shape)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        # real_cpu = real_cpu.unsqueeze(0)\n","        real_cpu = real_cpu.view(1, 1, 1, 64) #these are the comment tokens\n","        #print(real_cpu.shape)\n","        real_cpu = real_cpu.to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","        #discriminator will train off of true comments in the real batch pass\n","        # Forward pass real batch through D\n","        output = netD(real_cpu).view(-1) \n","        # Calculate loss on all-real batch\n","        errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        # print(inputs['input_ids'].shape)\n","        # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","        # Generate fake image batch with G\n","\n","        inputs = valid_df.iloc[i]['text']\n","        data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        #print(fake.shape)\n","        fake = fake.type(torch.float32)\n","        fake = fake.view(1, 1, 1, -1)\n","        fake = fake.detach().to(device)\n","        output = netD(fake).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        if i % 5 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(validation_data),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        if iters == 5: netG.save_pretrained('grape/hf-save-initial')\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        if (iters != 0 and iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","            netG.save_pretrained('grape/hf-save-halfway')\n","            with torch.no_grad():\n","                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1\n","\n","netG.save_pretrained('grape/hf-save-final')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7CIqDPACJV9","outputId":"6507625b-10ce-45c8-bd56-c96a656aa1b3","executionInfo":{"status":"ok","timestamp":1679209464375,"user_tz":420,"elapsed":6178434,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training Loop...\n","[0/1][0/998]\tLoss_D: 1.4483\tLoss_G: 5.8057\tD(x): 0.3625\tD(G(z)): 0.3517 / 0.0030\n","[0/1][5/998]\tLoss_D: 4.1567\tLoss_G: 3.9315\tD(x): 0.0258\tD(G(z)): 0.3936 / 0.0196\n","[0/1][10/998]\tLoss_D: 2.4321\tLoss_G: 3.2507\tD(x): 0.0931\tD(G(z)): 0.0568 / 0.0387\n","[0/1][15/998]\tLoss_D: 0.2008\tLoss_G: 5.8874\tD(x): 0.8206\tD(G(z)): 0.0030 / 0.0028\n","[0/1][20/998]\tLoss_D: 3.7579\tLoss_G: 2.2513\tD(x): 0.9819\tD(G(z)): 0.9762 / 0.1053\n","[0/1][25/998]\tLoss_D: 1.9715\tLoss_G: 4.5579\tD(x): 0.4468\tD(G(z)): 0.6883 / 0.0105\n","[0/1][30/998]\tLoss_D: 3.1629\tLoss_G: 4.3383\tD(x): 0.3284\tD(G(z)): 0.8712 / 0.0131\n","[0/1][35/998]\tLoss_D: 2.7175\tLoss_G: 3.0825\tD(x): 0.2276\tD(G(z)): 0.7099 / 0.0458\n","[0/1][40/998]\tLoss_D: 1.9320\tLoss_G: 2.4351\tD(x): 0.1958\tD(G(z)): 0.2602 / 0.0876\n","[0/1][45/998]\tLoss_D: 4.2772\tLoss_G: 3.1137\tD(x): 0.0463\tD(G(z)): 0.7001 / 0.0444\n","[0/1][50/998]\tLoss_D: 0.4257\tLoss_G: 3.5196\tD(x): 0.8638\tD(G(z)): 0.2437 / 0.0296\n","[0/1][55/998]\tLoss_D: 2.0118\tLoss_G: 2.4506\tD(x): 0.2606\tD(G(z)): 0.4868 / 0.0862\n","[0/1][60/998]\tLoss_D: 4.2975\tLoss_G: 1.1179\tD(x): 0.3546\tD(G(z)): 0.9616 / 0.3270\n","[0/1][65/998]\tLoss_D: 4.8372\tLoss_G: 0.3893\tD(x): 0.6460\tD(G(z)): 0.9877 / 0.6775\n","[0/1][70/998]\tLoss_D: 3.3472\tLoss_G: 2.1701\tD(x): 0.0986\tD(G(z)): 0.6430 / 0.1142\n","[0/1][75/998]\tLoss_D: 0.6452\tLoss_G: 2.8214\tD(x): 0.9984\tD(G(z)): 0.4746 / 0.0595\n","[0/1][80/998]\tLoss_D: 0.8036\tLoss_G: 2.0120\tD(x): 0.9783\tD(G(z)): 0.5424 / 0.1337\n","[0/1][85/998]\tLoss_D: 0.8114\tLoss_G: 2.2540\tD(x): 0.8624\tD(G(z)): 0.4849 / 0.1050\n","[0/1][90/998]\tLoss_D: 4.2101\tLoss_G: 2.0731\tD(x): 0.0219\tD(G(z)): 0.3216 / 0.1258\n","[0/1][95/998]\tLoss_D: 0.3647\tLoss_G: 2.6133\tD(x): 0.9603\tD(G(z)): 0.2769 / 0.0733\n","[0/1][100/998]\tLoss_D: 0.1510\tLoss_G: 2.6218\tD(x): 0.9787\tD(G(z)): 0.1214 / 0.0727\n","[0/1][105/998]\tLoss_D: 0.0881\tLoss_G: 2.7700\tD(x): 0.9923\tD(G(z)): 0.0772 / 0.0627\n","[0/1][110/998]\tLoss_D: 2.5201\tLoss_G: 1.7377\tD(x): 0.2392\tD(G(z)): 0.6636 / 0.1759\n","[0/1][115/998]\tLoss_D: 0.3576\tLoss_G: 3.4759\tD(x): 0.7152\tD(G(z)): 0.0222 / 0.0309\n","[0/1][120/998]\tLoss_D: 0.7903\tLoss_G: 2.7152\tD(x): 0.5006\tD(G(z)): 0.0936 / 0.0662\n","[0/1][125/998]\tLoss_D: 1.7855\tLoss_G: 1.5355\tD(x): 0.3952\tD(G(z)): 0.5756 / 0.2153\n","[0/1][130/998]\tLoss_D: 1.4149\tLoss_G: 2.4406\tD(x): 0.2684\tD(G(z)): 0.0949 / 0.0871\n","[0/1][135/998]\tLoss_D: 0.5466\tLoss_G: 1.9687\tD(x): 0.8986\tD(G(z)): 0.3558 / 0.1396\n","[0/1][140/998]\tLoss_D: 0.8481\tLoss_G: 2.2649\tD(x): 0.5990\tD(G(z)): 0.2850 / 0.1038\n","[0/1][145/998]\tLoss_D: 0.6939\tLoss_G: 2.4346\tD(x): 0.5701\tD(G(z)): 0.1236 / 0.0876\n","[0/1][150/998]\tLoss_D: 0.1257\tLoss_G: 3.2906\tD(x): 0.9278\tD(G(z)): 0.0495 / 0.0372\n","[0/1][155/998]\tLoss_D: 1.8950\tLoss_G: 0.9029\tD(x): 0.9931\tD(G(z)): 0.8486 / 0.4054\n","[0/1][160/998]\tLoss_D: 1.2672\tLoss_G: 2.7912\tD(x): 0.2967\tD(G(z)): 0.0508 / 0.0613\n","[0/1][165/998]\tLoss_D: 0.3521\tLoss_G: 2.1661\tD(x): 0.9976\tD(G(z)): 0.2951 / 0.1146\n","[0/1][170/998]\tLoss_D: 2.7530\tLoss_G: 3.2364\tD(x): 0.0650\tD(G(z)): 0.0194 / 0.0393\n","[0/1][175/998]\tLoss_D: 0.1078\tLoss_G: 2.8072\tD(x): 0.9720\tD(G(z)): 0.0764 / 0.0604\n","[0/1][180/998]\tLoss_D: 1.0447\tLoss_G: 1.8137\tD(x): 0.9849\tD(G(z)): 0.6428 / 0.1631\n","[0/1][185/998]\tLoss_D: 0.1147\tLoss_G: 3.0721\tD(x): 0.9656\tD(G(z)): 0.0766 / 0.0463\n","[0/1][190/998]\tLoss_D: 0.3139\tLoss_G: 2.8592\tD(x): 0.7893\tD(G(z)): 0.0744 / 0.0573\n","[0/1][195/998]\tLoss_D: 0.2694\tLoss_G: 2.5401\tD(x): 0.9804\tD(G(z)): 0.2210 / 0.0789\n","[0/1][200/998]\tLoss_D: 0.0928\tLoss_G: 4.7852\tD(x): 0.9188\tD(G(z)): 0.0081 / 0.0084\n","[0/1][205/998]\tLoss_D: 0.3035\tLoss_G: 2.1118\tD(x): 0.9961\tD(G(z)): 0.2589 / 0.1210\n","[0/1][210/998]\tLoss_D: 1.9267\tLoss_G: 1.5238\tD(x): 0.9126\tD(G(z)): 0.8404 / 0.2179\n","[0/1][215/998]\tLoss_D: 0.0370\tLoss_G: 3.5825\tD(x): 0.9990\tD(G(z)): 0.0354 / 0.0278\n","[0/1][220/998]\tLoss_D: 0.0879\tLoss_G: 3.3276\tD(x): 0.9633\tD(G(z)): 0.0493 / 0.0359\n","[0/1][225/998]\tLoss_D: 0.0161\tLoss_G: 5.0804\tD(x): 0.9912\tD(G(z)): 0.0073 / 0.0062\n","[0/1][230/998]\tLoss_D: 0.0053\tLoss_G: 5.6573\tD(x): 0.9983\tD(G(z)): 0.0036 / 0.0035\n","[0/1][235/998]\tLoss_D: 0.0044\tLoss_G: 6.2331\tD(x): 0.9976\tD(G(z)): 0.0020 / 0.0020\n","[0/1][240/998]\tLoss_D: 0.0361\tLoss_G: 3.5479\tD(x): 0.9997\tD(G(z)): 0.0351 / 0.0288\n","[0/1][245/998]\tLoss_D: 0.2621\tLoss_G: 3.4042\tD(x): 0.8469\tD(G(z)): 0.0915 / 0.0332\n","[0/1][250/998]\tLoss_D: 1.8191\tLoss_G: 2.2366\tD(x): 0.1912\tD(G(z)): 0.1519 / 0.1068\n","[0/1][255/998]\tLoss_D: 0.0407\tLoss_G: 3.3221\tD(x): 0.9957\tD(G(z)): 0.0357 / 0.0361\n","[0/1][260/998]\tLoss_D: 0.5637\tLoss_G: 2.3761\tD(x): 0.9992\tD(G(z)): 0.4305 / 0.0929\n","[0/1][265/998]\tLoss_D: 0.1718\tLoss_G: 2.5457\tD(x): 0.9932\tD(G(z)): 0.1521 / 0.0784\n","[0/1][270/998]\tLoss_D: 0.3617\tLoss_G: 2.4358\tD(x): 0.8170\tD(G(z)): 0.1475 / 0.0875\n","[0/1][275/998]\tLoss_D: 0.2231\tLoss_G: 2.6249\tD(x): 0.9997\tD(G(z)): 0.1997 / 0.0724\n","[0/1][280/998]\tLoss_D: 0.9293\tLoss_G: 2.7408\tD(x): 0.4932\tD(G(z)): 0.1995 / 0.0645\n","[0/1][285/998]\tLoss_D: 2.3614\tLoss_G: 1.6938\tD(x): 0.2121\tD(G(z)): 0.5554 / 0.1838\n","[0/1][290/998]\tLoss_D: 0.9424\tLoss_G: 3.6030\tD(x): 0.3945\tD(G(z)): 0.0122 / 0.0272\n","[0/1][295/998]\tLoss_D: 0.4870\tLoss_G: 3.0724\tD(x): 0.9998\tD(G(z)): 0.3854 / 0.0463\n","[0/1][300/998]\tLoss_D: 0.0701\tLoss_G: 4.0874\tD(x): 0.9521\tD(G(z)): 0.0208 / 0.0168\n","[0/1][305/998]\tLoss_D: 0.0287\tLoss_G: 4.0186\tD(x): 0.9915\tD(G(z)): 0.0199 / 0.0180\n","[0/1][310/998]\tLoss_D: 0.0081\tLoss_G: 4.7444\tD(x): 0.9996\tD(G(z)): 0.0077 / 0.0087\n","[0/1][315/998]\tLoss_D: 1.9764\tLoss_G: 2.1325\tD(x): 0.9987\tD(G(z)): 0.8612 / 0.1185\n","[0/1][320/998]\tLoss_D: 0.2602\tLoss_G: 3.0239\tD(x): 0.8293\tD(G(z)): 0.0705 / 0.0486\n","[0/1][325/998]\tLoss_D: 0.6477\tLoss_G: 2.1136\tD(x): 0.9987\tD(G(z)): 0.4761 / 0.1208\n","[0/1][330/998]\tLoss_D: 0.0431\tLoss_G: 3.6427\tD(x): 0.9991\tD(G(z)): 0.0414 / 0.0262\n","[0/1][335/998]\tLoss_D: 0.0125\tLoss_G: 4.2028\tD(x): 0.9998\tD(G(z)): 0.0122 / 0.0150\n","[0/1][340/998]\tLoss_D: 0.0398\tLoss_G: 3.8443\tD(x): 0.9760\tD(G(z)): 0.0154 / 0.0214\n","[0/1][345/998]\tLoss_D: 0.4153\tLoss_G: 3.2428\tD(x): 0.7042\tD(G(z)): 0.0626 / 0.0391\n","[0/1][350/998]\tLoss_D: 0.9941\tLoss_G: 2.7063\tD(x): 0.9987\tD(G(z)): 0.6295 / 0.0668\n","[0/1][355/998]\tLoss_D: 1.1268\tLoss_G: 3.6013\tD(x): 0.6555\tD(G(z)): 0.5056 / 0.0273\n","[0/1][360/998]\tLoss_D: 3.1100\tLoss_G: 2.2392\tD(x): 0.9994\tD(G(z)): 0.9554 / 0.1065\n","[0/1][365/998]\tLoss_D: 0.4941\tLoss_G: 5.8824\tD(x): 0.6113\tD(G(z)): 0.0020 / 0.0028\n","[0/1][370/998]\tLoss_D: 1.3051\tLoss_G: 2.7779\tD(x): 0.2857\tD(G(z)): 0.0511 / 0.0622\n","[0/1][375/998]\tLoss_D: 0.1056\tLoss_G: 3.0049\tD(x): 0.9990\tD(G(z)): 0.0993 / 0.0495\n","[0/1][380/998]\tLoss_D: 3.4568\tLoss_G: 2.1341\tD(x): 0.0336\tD(G(z)): 0.0625 / 0.1183\n","[0/1][385/998]\tLoss_D: 5.7057\tLoss_G: 0.5321\tD(x): 0.3172\tD(G(z)): 0.9895 / 0.5874\n","[0/1][390/998]\tLoss_D: 0.4649\tLoss_G: 3.4030\tD(x): 0.8996\tD(G(z)): 0.3017 / 0.0333\n","[0/1][395/998]\tLoss_D: 0.3385\tLoss_G: 2.3658\tD(x): 0.9681\tD(G(z)): 0.2637 / 0.0939\n","[0/1][400/998]\tLoss_D: 0.0639\tLoss_G: 3.1278\tD(x): 0.9962\tD(G(z)): 0.0583 / 0.0438\n","[0/1][405/998]\tLoss_D: 0.2636\tLoss_G: 2.3340\tD(x): 0.9999\tD(G(z)): 0.2316 / 0.0969\n","[0/1][410/998]\tLoss_D: 0.3762\tLoss_G: 1.9698\tD(x): 0.9817\tD(G(z)): 0.3007 / 0.1395\n","[0/1][415/998]\tLoss_D: 0.0357\tLoss_G: 3.5439\tD(x): 0.9997\tD(G(z)): 0.0347 / 0.0289\n","[0/1][420/998]\tLoss_D: 3.5739\tLoss_G: 3.1896\tD(x): 0.9995\tD(G(z)): 0.9719 / 0.0412\n","[0/1][425/998]\tLoss_D: 0.0925\tLoss_G: 2.6240\tD(x): 0.9982\tD(G(z)): 0.0866 / 0.0725\n","[0/1][430/998]\tLoss_D: 0.0913\tLoss_G: 3.8549\tD(x): 0.9321\tD(G(z)): 0.0207 / 0.0212\n","[0/1][435/998]\tLoss_D: 0.3782\tLoss_G: 3.8030\tD(x): 0.7089\tD(G(z)): 0.0336 / 0.0223\n","[0/1][440/998]\tLoss_D: 0.9152\tLoss_G: 1.9803\tD(x): 0.8329\tD(G(z)): 0.5192 / 0.1380\n","[0/1][445/998]\tLoss_D: 0.1260\tLoss_G: 4.0575\tD(x): 0.8980\tD(G(z)): 0.0182 / 0.0173\n","[0/1][450/998]\tLoss_D: 3.1456\tLoss_G: 1.7928\tD(x): 0.0486\tD(G(z)): 0.1147 / 0.1665\n","[0/1][455/998]\tLoss_D: 2.7796\tLoss_G: 1.3479\tD(x): 0.9960\tD(G(z)): 0.9377 / 0.2598\n","[0/1][460/998]\tLoss_D: 1.8115\tLoss_G: 3.1089\tD(x): 0.1707\tD(G(z)): 0.0427 / 0.0447\n","[0/1][465/998]\tLoss_D: 0.0862\tLoss_G: 3.5059\tD(x): 0.9457\tD(G(z)): 0.0299 / 0.0300\n","[0/1][470/998]\tLoss_D: 0.2829\tLoss_G: 2.0713\tD(x): 0.9834\tD(G(z)): 0.2337 / 0.1260\n","[0/1][475/998]\tLoss_D: 0.3143\tLoss_G: 3.2677\tD(x): 0.7559\tD(G(z)): 0.0339 / 0.0381\n","[0/1][480/998]\tLoss_D: 0.2778\tLoss_G: 2.4335\tD(x): 0.9932\tD(G(z)): 0.2373 / 0.0877\n","[0/1][485/998]\tLoss_D: 0.0987\tLoss_G: 2.7098\tD(x): 0.9975\tD(G(z)): 0.0918 / 0.0666\n","[0/1][490/998]\tLoss_D: 0.0381\tLoss_G: 4.6058\tD(x): 0.9760\tD(G(z)): 0.0136 / 0.0100\n","[0/1][495/998]\tLoss_D: 0.0777\tLoss_G: 4.2099\tD(x): 0.9389\tD(G(z)): 0.0145 / 0.0148\n","[0/1][500/998]\tLoss_D: 0.0835\tLoss_G: 3.2528\tD(x): 0.9648\tD(G(z)): 0.0466 / 0.0387\n","[0/1][505/998]\tLoss_D: 1.0289\tLoss_G: 2.1978\tD(x): 0.4408\tD(G(z)): 0.1893 / 0.1110\n","[0/1][510/998]\tLoss_D: 0.2090\tLoss_G: 2.9645\tD(x): 0.8600\tD(G(z)): 0.0566 / 0.0516\n","[0/1][515/998]\tLoss_D: 2.4444\tLoss_G: 2.6162\tD(x): 0.0893\tD(G(z)): 0.0288 / 0.0731\n","[0/1][520/998]\tLoss_D: 0.5660\tLoss_G: 3.9423\tD(x): 0.9991\tD(G(z)): 0.4317 / 0.0194\n","[0/1][525/998]\tLoss_D: 0.2419\tLoss_G: 2.9433\tD(x): 0.8456\tD(G(z)): 0.0715 / 0.0527\n","[0/1][530/998]\tLoss_D: 0.0854\tLoss_G: 4.7804\tD(x): 0.9263\tD(G(z)): 0.0088 / 0.0084\n","[0/1][535/998]\tLoss_D: 0.4059\tLoss_G: 3.9013\tD(x): 0.6779\tD(G(z)): 0.0170 / 0.0202\n","[0/1][540/998]\tLoss_D: 2.1308\tLoss_G: 4.7850\tD(x): 0.1195\tD(G(z)): 0.0067 / 0.0084\n","[0/1][545/998]\tLoss_D: 0.1393\tLoss_G: 4.1995\tD(x): 0.8864\tD(G(z)): 0.0186 / 0.0150\n","[0/1][550/998]\tLoss_D: 0.0163\tLoss_G: 4.4046\tD(x): 0.9996\tD(G(z)): 0.0158 / 0.0122\n","[0/1][555/998]\tLoss_D: 0.0161\tLoss_G: 5.1195\tD(x): 0.9899\tD(G(z)): 0.0059 / 0.0060\n","[0/1][560/998]\tLoss_D: 0.0509\tLoss_G: 3.3361\tD(x): 0.9921\tD(G(z)): 0.0420 / 0.0356\n","[0/1][565/998]\tLoss_D: 2.8180\tLoss_G: 2.1921\tD(x): 0.0637\tD(G(z)): 0.0625 / 0.1117\n","[0/1][570/998]\tLoss_D: 1.2352\tLoss_G: 1.3549\tD(x): 0.9190\tD(G(z)): 0.6836 / 0.2580\n","[0/1][575/998]\tLoss_D: 0.6826\tLoss_G: 2.6990\tD(x): 0.9957\tD(G(z)): 0.4925 / 0.0673\n","[0/1][580/998]\tLoss_D: 0.5776\tLoss_G: 1.9018\tD(x): 0.9854\tD(G(z)): 0.4304 / 0.1493\n","[0/1][585/998]\tLoss_D: 0.7999\tLoss_G: 1.8862\tD(x): 0.5358\tD(G(z)): 0.1614 / 0.1517\n","[0/1][590/998]\tLoss_D: 0.0596\tLoss_G: 3.9110\tD(x): 0.9636\tD(G(z)): 0.0223 / 0.0200\n","[0/1][595/998]\tLoss_D: 0.0684\tLoss_G: 4.2964\tD(x): 0.9501\tD(G(z)): 0.0170 / 0.0136\n","[0/1][600/998]\tLoss_D: 0.0363\tLoss_G: 5.0269\tD(x): 0.9710\tD(G(z)): 0.0068 / 0.0066\n","[0/1][605/998]\tLoss_D: 0.0172\tLoss_G: 5.0856\tD(x): 0.9929\tD(G(z)): 0.0100 / 0.0062\n","[0/1][610/998]\tLoss_D: 0.0021\tLoss_G: 6.7465\tD(x): 0.9994\tD(G(z)): 0.0015 / 0.0012\n","[0/1][615/998]\tLoss_D: 0.1602\tLoss_G: 3.7688\tD(x): 0.8714\tD(G(z)): 0.0222 / 0.0231\n","[0/1][620/998]\tLoss_D: 0.9744\tLoss_G: 4.6454\tD(x): 0.3802\tD(G(z)): 0.0072 / 0.0096\n","[0/1][625/998]\tLoss_D: 0.2182\tLoss_G: 2.3758\tD(x): 0.9661\tD(G(z)): 0.1679 / 0.0929\n","[0/1][630/998]\tLoss_D: 0.1460\tLoss_G: 2.7989\tD(x): 0.9708\tD(G(z)): 0.1098 / 0.0609\n","[0/1][635/998]\tLoss_D: 0.0476\tLoss_G: 4.4711\tD(x): 0.9654\tD(G(z)): 0.0123 / 0.0114\n","[0/1][640/998]\tLoss_D: 0.0230\tLoss_G: 5.1873\tD(x): 0.9833\tD(G(z)): 0.0061 / 0.0056\n","[0/1][645/998]\tLoss_D: 0.2564\tLoss_G: 2.6011\tD(x): 0.9883\tD(G(z)): 0.2170 / 0.0742\n","[0/1][650/998]\tLoss_D: 3.7974\tLoss_G: 3.8490\tD(x): 0.0227\tD(G(z)): 0.0118 / 0.0213\n","[0/1][655/998]\tLoss_D: 0.1720\tLoss_G: 2.5983\tD(x): 0.9686\tD(G(z)): 0.1307 / 0.0744\n","[0/1][660/998]\tLoss_D: 0.0102\tLoss_G: 4.6129\tD(x): 0.9992\tD(G(z)): 0.0093 / 0.0099\n","[0/1][665/998]\tLoss_D: 0.1712\tLoss_G: 2.9108\tD(x): 0.9978\tD(G(z)): 0.1554 / 0.0544\n","[0/1][670/998]\tLoss_D: 0.2795\tLoss_G: 4.6125\tD(x): 0.7622\tD(G(z)): 0.0080 / 0.0099\n","[0/1][675/998]\tLoss_D: 0.0512\tLoss_G: 3.3522\tD(x): 0.9969\tD(G(z)): 0.0469 / 0.0350\n","[0/1][680/998]\tLoss_D: 1.8650\tLoss_G: 3.0320\tD(x): 0.9989\tD(G(z)): 0.8449 / 0.0482\n","[0/1][685/998]\tLoss_D: 0.1559\tLoss_G: 3.0329\tD(x): 0.9129\tD(G(z)): 0.0628 / 0.0482\n","[0/1][690/998]\tLoss_D: 2.5704\tLoss_G: 1.4710\tD(x): 0.0840\tD(G(z)): 0.0891 / 0.2297\n","[0/1][695/998]\tLoss_D: 0.1438\tLoss_G: 3.3450\tD(x): 1.0000\tD(G(z)): 0.1339 / 0.0353\n","[0/1][700/998]\tLoss_D: 0.0341\tLoss_G: 4.4681\tD(x): 0.9781\tD(G(z)): 0.0118 / 0.0115\n","[0/1][705/998]\tLoss_D: 0.0178\tLoss_G: 4.3486\tD(x): 0.9973\tD(G(z)): 0.0150 / 0.0129\n","[0/1][710/998]\tLoss_D: 1.9347\tLoss_G: 2.2713\tD(x): 0.9879\tD(G(z)): 0.8538 / 0.1032\n","[0/1][715/998]\tLoss_D: 0.1705\tLoss_G: 2.3981\tD(x): 1.0000\tD(G(z)): 0.1567 / 0.0909\n","[0/1][720/998]\tLoss_D: 0.0088\tLoss_G: 4.7996\tD(x): 0.9999\tD(G(z)): 0.0086 / 0.0082\n","[0/1][725/998]\tLoss_D: 0.2864\tLoss_G: 2.3910\tD(x): 0.8631\tD(G(z)): 0.1299 / 0.0915\n","[0/1][730/998]\tLoss_D: 0.0766\tLoss_G: 2.9626\tD(x): 0.9999\tD(G(z)): 0.0736 / 0.0517\n","[0/1][735/998]\tLoss_D: 0.0239\tLoss_G: 3.8775\tD(x): 1.0000\tD(G(z)): 0.0236 / 0.0207\n","[0/1][740/998]\tLoss_D: 1.0507\tLoss_G: 2.2461\tD(x): 0.9991\tD(G(z)): 0.6500 / 0.1058\n","[0/1][745/998]\tLoss_D: 0.0289\tLoss_G: 3.8408\tD(x): 0.9989\tD(G(z)): 0.0275 / 0.0215\n","[0/1][750/998]\tLoss_D: 0.0230\tLoss_G: 4.6606\tD(x): 0.9860\tD(G(z)): 0.0088 / 0.0095\n","[0/1][755/998]\tLoss_D: 0.0005\tLoss_G: 7.8727\tD(x): 0.9999\tD(G(z)): 0.0004 / 0.0004\n","[0/1][760/998]\tLoss_D: 0.2896\tLoss_G: 7.1812\tD(x): 0.7490\tD(G(z)): 0.0006 / 0.0008\n","[0/1][765/998]\tLoss_D: 0.0105\tLoss_G: 5.0954\tD(x): 0.9958\tD(G(z)): 0.0063 / 0.0061\n","[0/1][770/998]\tLoss_D: 0.0185\tLoss_G: 4.1997\tD(x): 0.9996\tD(G(z)): 0.0179 / 0.0150\n","[0/1][775/998]\tLoss_D: 0.0075\tLoss_G: 7.4455\tD(x): 0.9932\tD(G(z)): 0.0006 / 0.0006\n","[0/1][780/998]\tLoss_D: 2.2860\tLoss_G: 3.3421\tD(x): 0.1022\tD(G(z)): 0.0049 / 0.0354\n","[0/1][785/998]\tLoss_D: 0.0493\tLoss_G: 5.7254\tD(x): 0.9554\tD(G(z)): 0.0037 / 0.0033\n","[0/1][790/998]\tLoss_D: 0.0047\tLoss_G: 8.7627\tD(x): 0.9955\tD(G(z)): 0.0002 / 0.0002\n","[0/1][795/998]\tLoss_D: 2.4130\tLoss_G: 6.9601\tD(x): 0.0896\tD(G(z)): 0.0004 / 0.0009\n","[0/1][800/998]\tLoss_D: 0.6465\tLoss_G: 4.4046\tD(x): 0.5278\tD(G(z)): 0.0074 / 0.0122\n","[0/1][805/998]\tLoss_D: 0.0529\tLoss_G: 3.3659\tD(x): 0.9888\tD(G(z)): 0.0408 / 0.0345\n","[0/1][810/998]\tLoss_D: 0.9070\tLoss_G: 2.8040\tD(x): 0.9959\tD(G(z)): 0.5946 / 0.0606\n","[0/1][815/998]\tLoss_D: 1.0152\tLoss_G: 2.5432\tD(x): 0.9696\tD(G(z)): 0.6263 / 0.0786\n","[0/1][820/998]\tLoss_D: 0.2266\tLoss_G: 2.3275\tD(x): 0.9958\tD(G(z)): 0.1994 / 0.0975\n","[0/1][825/998]\tLoss_D: 0.0290\tLoss_G: 3.8779\tD(x): 0.9958\tD(G(z)): 0.0245 / 0.0207\n","[0/1][830/998]\tLoss_D: 0.3649\tLoss_G: 2.5204\tD(x): 0.9779\tD(G(z)): 0.2901 / 0.0804\n","[0/1][835/998]\tLoss_D: 0.1272\tLoss_G: 2.9754\tD(x): 0.9960\tD(G(z)): 0.1159 / 0.0510\n","[0/1][840/998]\tLoss_D: 0.2676\tLoss_G: 2.5229\tD(x): 0.9995\tD(G(z)): 0.2344 / 0.0802\n","[0/1][845/998]\tLoss_D: 0.1317\tLoss_G: 3.0839\tD(x): 0.9537\tD(G(z)): 0.0809 / 0.0458\n","[0/1][850/998]\tLoss_D: 0.0862\tLoss_G: 2.5718\tD(x): 0.9926\tD(G(z)): 0.0758 / 0.0764\n","[0/1][855/998]\tLoss_D: 0.0010\tLoss_G: 7.2329\tD(x): 0.9999\tD(G(z)): 0.0009 / 0.0007\n","[0/1][860/998]\tLoss_D: 0.0244\tLoss_G: 4.2116\tD(x): 0.9944\tD(G(z)): 0.0186 / 0.0148\n","[0/1][865/998]\tLoss_D: 0.0255\tLoss_G: 6.2270\tD(x): 0.9768\tD(G(z)): 0.0020 / 0.0020\n","[0/1][870/998]\tLoss_D: 0.0196\tLoss_G: 6.1563\tD(x): 0.9826\tD(G(z)): 0.0021 / 0.0021\n","[0/1][875/998]\tLoss_D: 0.0116\tLoss_G: 4.6577\tD(x): 0.9984\tD(G(z)): 0.0099 / 0.0095\n","[0/1][880/998]\tLoss_D: 0.0037\tLoss_G: 6.1198\tD(x): 0.9986\tD(G(z)): 0.0023 / 0.0022\n","[0/1][885/998]\tLoss_D: 0.0355\tLoss_G: 3.8369\tD(x): 0.9897\tD(G(z)): 0.0249 / 0.0216\n","[0/1][890/998]\tLoss_D: 0.0876\tLoss_G: 3.8986\tD(x): 0.9368\tD(G(z)): 0.0220 / 0.0203\n","[0/1][895/998]\tLoss_D: 0.0370\tLoss_G: 4.0305\tD(x): 0.9905\tD(G(z)): 0.0271 / 0.0178\n","[0/1][900/998]\tLoss_D: 2.6778\tLoss_G: 2.3363\tD(x): 0.2209\tD(G(z)): 0.6890 / 0.0967\n","[0/1][905/998]\tLoss_D: 0.5141\tLoss_G: 2.1068\tD(x): 0.9998\tD(G(z)): 0.4018 / 0.1216\n","[0/1][910/998]\tLoss_D: 0.1339\tLoss_G: 3.6848\tD(x): 0.9016\tD(G(z)): 0.0298 / 0.0251\n","[0/1][915/998]\tLoss_D: 0.1249\tLoss_G: 2.7298\tD(x): 0.9870\tD(G(z)): 0.1058 / 0.0652\n","[0/1][920/998]\tLoss_D: 0.0194\tLoss_G: 4.6130\tD(x): 0.9931\tD(G(z)): 0.0124 / 0.0099\n","[0/1][925/998]\tLoss_D: 0.0100\tLoss_G: 5.6835\tD(x): 0.9940\tD(G(z)): 0.0040 / 0.0034\n","[0/1][930/998]\tLoss_D: 0.0231\tLoss_G: 4.9734\tD(x): 0.9854\tD(G(z)): 0.0084 / 0.0069\n","[0/1][935/998]\tLoss_D: 0.0405\tLoss_G: 3.4250\tD(x): 0.9995\tD(G(z)): 0.0392 / 0.0325\n","[0/1][940/998]\tLoss_D: 0.3124\tLoss_G: 2.9327\tD(x): 0.9971\tD(G(z)): 0.2662 / 0.0533\n","[0/1][945/998]\tLoss_D: 0.0033\tLoss_G: 5.8312\tD(x): 0.9997\tD(G(z)): 0.0030 / 0.0029\n","[0/1][950/998]\tLoss_D: 0.3442\tLoss_G: 3.8309\tD(x): 0.7209\tD(G(z)): 0.0167 / 0.0217\n","[0/1][955/998]\tLoss_D: 6.3560\tLoss_G: 0.0439\tD(x): 0.9985\tD(G(z)): 0.9983 / 0.9571\n","[0/1][960/998]\tLoss_D: 4.3331\tLoss_G: 1.9356\tD(x): 0.5907\tD(G(z)): 0.9778 / 0.1443\n","[0/1][965/998]\tLoss_D: 0.3272\tLoss_G: 3.5641\tD(x): 0.7421\tD(G(z)): 0.0285 / 0.0283\n","[0/1][970/998]\tLoss_D: 0.2197\tLoss_G: 5.1038\tD(x): 0.8067\tD(G(z)): 0.0049 / 0.0061\n","[0/1][975/998]\tLoss_D: 0.0602\tLoss_G: 3.2815\tD(x): 0.9958\tD(G(z)): 0.0545 / 0.0376\n","[0/1][980/998]\tLoss_D: 0.1079\tLoss_G: 5.1951\tD(x): 0.9024\tD(G(z)): 0.0052 / 0.0055\n","[0/1][985/998]\tLoss_D: 2.5291\tLoss_G: 5.5781\tD(x): 0.0798\tD(G(z)): 0.0014 / 0.0038\n","[0/1][990/998]\tLoss_D: 0.0386\tLoss_G: 4.7040\tD(x): 0.9713\tD(G(z)): 0.0094 / 0.0091\n","[0/1][995/998]\tLoss_D: 0.2053\tLoss_G: 4.9733\tD(x): 0.8200\tD(G(z)): 0.0068 / 0.0069\n"]}]},{"cell_type":"code","source":["# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i, data in enumerate(dataloader, 0):\n","#         #data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         #print(data)\n","#         print(data['labels'])\n","#         real_cpu = torch.stack(data['labels'])\n","#         #real_cpu = torch.unsqueeze(real_cpu, dim=0)\n","#         #real_cpu = torch.cat(real_cpu, dim=0)\n","#         #real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.type(torch.FloatTensor).view(-1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         #inputs = train_df.iloc[i]['text']\n","#         #data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         data = {k : torch.stack(v) for k, v in data.items()}\n","#         fake = netG(**data)\n","\n","#         # fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"id":"kpQNOHLX7dL_","executionInfo":{"status":"error","timestamp":1679097807475,"user_tz":420,"elapsed":2532,"user":{"displayName":"Poojan Pandya","userId":"17515591504675531297"}},"outputId":"329155dd-eee5-486e-8f65-b9c87bd2dff7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training Loop...\n","[tensor([0, 0, 0, 0]), tensor([ 4444,  7199, 34956,   487]), tensor([ 725,    5,    4, 3847]), tensor([    4, 43870,   370,   111]), tensor([1437,    6,  206,  370]), tensor([1437,   53,    5,  399]), tensor([2486,    5, 2178,   75]), tensor([2761,  129,   16,  216]), tensor([4428,  169,   22,   14]), tensor([ 101,   47, 3463,   79]), tensor([   10,   214, 37013,   938]), tensor([269, 164, 113,  75]), tensor([4613,    7,    8,  602]), tensor([621,  28, 110,  39]), tensor([   6,  441, 2472,   94]), tensor([ 53,   7,  16, 766]), tensor([ 38, 542,   7,   8]), tensor([  218,  4506, 10914,    24]), tensor([75, 14, 24, 21]), tensor([  206, 10342,    55,    10]), tensor([   24,    16, 10727,   205]), tensor([  817,     7, 38564,  4085]), tensor([  47,  464,  116, 1114]), tensor([  10,  110, 1437,    4]), tensor([ 1099,   346, 50118,   318]), tensor([  621,     8, 50118,    47]), tensor([ 114,   45,  243, 3127]), tensor([ 47, 492,  18, 399]), tensor([218,  24,  10,  75]), tensor([   75,     7, 12103,   128]), tensor([  236,  1268,  2178, 23242]), tensor([   7,   23,    4, 4636]), tensor([  432,   173, 16225,   108]), tensor([ 19,  36, 197,  11]), tensor([  10, 7443,   28, 1263]), tensor([4153,   87,  441,    8]), tensor([ 4607, 11683,     7,    95]), tensor([    4,    73,  1067, 11184]), tensor([ 1437, 16625,    59,    47]), tensor([  38, 3200,   49,  214]), tensor([ 216, 2870, 1074, 1153]), tensor([  47,  322,    4, 2051]), tensor([619, 252,   2,   4]), tensor([1099,  348, -100,    2]), tensor([   6,  416, -100, -100]), tensor([  53, 5401, -100, -100]), tensor([  47,   51, -100, -100]), tensor([ 399,  214, -100, -100]), tensor([  75,   45, -100, -100]), tensor([1203,  164, -100, -100]), tensor([  62,    7, -100, -100]), tensor([   7, 2098, -100, -100]), tensor([ 185,   24, -100, -100]), tensor([  42,    4, -100, -100]), tensor([4607, 1437, -100, -100]), tensor([  15, 1437, -100, -100]), tensor([   4,    2, -100, -100]), tensor([1437, -100, -100, -100]), tensor([50118,  -100,  -100,  -100]), tensor([50118,  -100,  -100,  -100]), tensor([6209, -100, -100, -100]), tensor([  37, -100, -100, -100]), tensor([  11, -100, -100, -100]), tensor([   2, -100, -100, -100])]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-1563fea6a206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1371\u001b[0m                 )\n\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1256\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                 )\n\u001b[1;32m   1112\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1114\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n\u001b[0m\u001b[1;32m    446\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0mkey_value_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    247\u001b[0m                     \u001b[0;34mf\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 )\n","\u001b[0;31mValueError\u001b[0m: Attention mask should be of size (64, 1, 4, 16), but is torch.Size([256, 1, 4, 4])"]}]},{"cell_type":"code","source":["# ################ WORKING DO NOT TOUCH ####################\n","\n","# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i in range(len(train_data)):\n","#         data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.view(1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         inputs = train_df.iloc[i]['text']\n","#         data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"bZkK8xM0FBpM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QxIWu1TqEse1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","\n","# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# print(input.shape)\n","# m = nn.Upsample(size=(64, 64))\n","# output = m(input)\n","# output = output.reshape((1, 64, 64))\n","# print(output.shape)\n","\n","# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zmQecWWiUWa","executionInfo":{"status":"ok","timestamp":1678955908751,"user_tz":420,"elapsed":4,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"4cadc926-a2e4-4e1e-9d58-cca67eba9de9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 1, 64])\n","torch.Size([1, 64, 64])\n","torch.Size([1, 3, 24, 24])\n"]}]},{"cell_type":"code","source":["# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZdysfkciVDS","executionInfo":{"status":"ok","timestamp":1678955791919,"user_tz":420,"elapsed":262,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"5be6611a-1854-424a-c18f-68023f87d982"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3, 24, 24])\n"]}]},{"cell_type":"code","source":["# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# m = nn.Upsample(size=(64, 64))\n","# intermediate = m(input)\n","# x = nn.Flatten(0, 1)\n","# output = x(intermediate)\n","# print(input.shape)\n","# print(intermediate.shape)\n","# print(output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0P87XbnOkEOm","executionInfo":{"status":"ok","timestamp":1678956597151,"user_tz":420,"elapsed":331,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"d552bbfe-cac2-4cac-cc78-a99e015bd387"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 1, 64])\n","torch.Size([1, 1, 64, 64])\n","torch.Size([1, 64, 64])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8BIW0Ev3m4b0"},"execution_count":null,"outputs":[]}]}