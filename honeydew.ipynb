{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1d3jmXGxX-N1FQPcRPb5lCLHkjqSoR-Pc","timestamp":1679218528678},{"file_id":"1RZzlzBJW5PHbrD96lZfq-lb4aMVIJ3pB","timestamp":1679128823449}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bf4091de68c6454ab4f48258c7dd2839":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_27ff44ae73af4920a53eff6ef86c3040","IPY_MODEL_d45b9783f57941f395d2fa3d4715928a","IPY_MODEL_28ca1037022b4c27a24d31aaaef2ae3e"],"layout":"IPY_MODEL_9e23c9c18ccb4974ad23a09bd850501a"}},"27ff44ae73af4920a53eff6ef86c3040":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69b73270e9f642098ccb95d8502df80f","placeholder":"​","style":"IPY_MODEL_323ce418f859413a9702ba4a45dce668","value":"Downloading (…)lve/main/config.json: 100%"}},"d45b9783f57941f395d2fa3d4715928a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6566eb1c22f04cf68524afb6609eace5","max":949,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a922591cebc64df188f1453e845e8873","value":949}},"28ca1037022b4c27a24d31aaaef2ae3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f11c73c1c8cf41acb93c175f070175a7","placeholder":"​","style":"IPY_MODEL_b3b7aab84c9040f692f8e0f85dbdaf1d","value":" 949/949 [00:00&lt;00:00, 28.5kB/s]"}},"9e23c9c18ccb4974ad23a09bd850501a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69b73270e9f642098ccb95d8502df80f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"323ce418f859413a9702ba4a45dce668":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6566eb1c22f04cf68524afb6609eace5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a922591cebc64df188f1453e845e8873":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f11c73c1c8cf41acb93c175f070175a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b7aab84c9040f692f8e0f85dbdaf1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31519269ae2745609738776796331a5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80bd83607afc4d288c905b7b3344bf10","IPY_MODEL_68fe0573ca0546a28984578a053c44de","IPY_MODEL_142c225748374da5890400315b8cc76d"],"layout":"IPY_MODEL_73382dee59ab4ddc85d09bfe9c73fe65"}},"80bd83607afc4d288c905b7b3344bf10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ad93f4ef9484ed49ad6d60fc242ec2a","placeholder":"​","style":"IPY_MODEL_9c8af36054fb48f5bff01fc0a1edf2d6","value":"Downloading pytorch_model.bin: 100%"}},"68fe0573ca0546a28984578a053c44de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a6e5ca5471d4afd88a0644e704e7dc8","max":539679413,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0166a25a0c7e460bbbc91e99efe9fb2e","value":539679413}},"142c225748374da5890400315b8cc76d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a85403736824aa3ba8b13fd637b0663","placeholder":"​","style":"IPY_MODEL_5c11246228d64f0b8bd2a22eeca80bd4","value":" 540M/540M [00:02&lt;00:00, 207MB/s]"}},"73382dee59ab4ddc85d09bfe9c73fe65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ad93f4ef9484ed49ad6d60fc242ec2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c8af36054fb48f5bff01fc0a1edf2d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a6e5ca5471d4afd88a0644e704e7dc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0166a25a0c7e460bbbc91e99efe9fb2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a85403736824aa3ba8b13fd637b0663":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c11246228d64f0b8bd2a22eeca80bd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c7cd87678c0454592ae1a18b740ec0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_556f682ce285473b99fa2b5abe2f0f72","IPY_MODEL_ed8656ac823a4e10ac1b258cb1276ea0","IPY_MODEL_9e8a835db2014ca9b2850b03669941ff"],"layout":"IPY_MODEL_b59ea4f0f8f54bc6a6875e48446c2674"}},"556f682ce285473b99fa2b5abe2f0f72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4047999f87d9450d8096a941e8628f64","placeholder":"​","style":"IPY_MODEL_b1013e25a4914962a9000e96342dcbc3","value":"Downloading (…)okenizer_config.json: 100%"}},"ed8656ac823a4e10ac1b258cb1276ea0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b55d0abe9454046a193fd49d8415eaa","max":338,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c67ee68a87a042d09df6782ff79eef48","value":338}},"9e8a835db2014ca9b2850b03669941ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926872a5e4484e7b9c1fcf8310c52686","placeholder":"​","style":"IPY_MODEL_5bb93023d5cf4d2eae64f9b831f941b3","value":" 338/338 [00:00&lt;00:00, 6.18kB/s]"}},"b59ea4f0f8f54bc6a6875e48446c2674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4047999f87d9450d8096a941e8628f64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1013e25a4914962a9000e96342dcbc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b55d0abe9454046a193fd49d8415eaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c67ee68a87a042d09df6782ff79eef48":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"926872a5e4484e7b9c1fcf8310c52686":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb93023d5cf4d2eae64f9b831f941b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ca42b4042b04b3da998ef6e227933b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e4d4d59ee1342e9b5cf90aebec012c7","IPY_MODEL_00789a1b56584f849a1ed588155eae37","IPY_MODEL_7d58d540c4ce4471a2bf35143d36d5cb"],"layout":"IPY_MODEL_6bd46666f47246cd851fb35afa2cc99e"}},"7e4d4d59ee1342e9b5cf90aebec012c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5afdc4bc2b04480bcd6879504f95a75","placeholder":"​","style":"IPY_MODEL_cd1969d3642748c5945c2ce4947caa3b","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"00789a1b56584f849a1ed588155eae37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74c61fb18e34ed69efe819f1807bb76","max":843438,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bf401aaffed45529892cc39ff9125cc","value":843438}},"7d58d540c4ce4471a2bf35143d36d5cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a3135f844f940d88808e4bbf28fc172","placeholder":"​","style":"IPY_MODEL_66ce1666ae1143c0a842107e406c2b03","value":" 843k/843k [00:00&lt;00:00, 1.97MB/s]"}},"6bd46666f47246cd851fb35afa2cc99e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5afdc4bc2b04480bcd6879504f95a75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd1969d3642748c5945c2ce4947caa3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b74c61fb18e34ed69efe819f1807bb76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bf401aaffed45529892cc39ff9125cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a3135f844f940d88808e4bbf28fc172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ce1666ae1143c0a842107e406c2b03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6bb894cb795f475aa4351fff902e33e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31d5df99b9844c89a9b2b1eb40f64700","IPY_MODEL_15a3aec93d894edd8f532fc15b6bcf22","IPY_MODEL_763ababed79a4afc926ff309cce609ce"],"layout":"IPY_MODEL_cbbd8be35fd64021876e997fa6351dd1"}},"31d5df99b9844c89a9b2b1eb40f64700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b60e120c7c494ca5ba452d87a7c9c5a2","placeholder":"​","style":"IPY_MODEL_06c3d9bac3844e6e986495206b1603c9","value":"Downloading (…)solve/main/bpe.codes: 100%"}},"15a3aec93d894edd8f532fc15b6bcf22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d174f91bc8f4afcaad4ff3c4e599afa","max":1078931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2374093c8ff147409f2532089e98356a","value":1078931}},"763ababed79a4afc926ff309cce609ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7d18ad25cbe4a05a9d29635629e4ff2","placeholder":"​","style":"IPY_MODEL_737c8ed893834e19a2cb477c4e8e0578","value":" 1.08M/1.08M [00:00&lt;00:00, 2.51MB/s]"}},"cbbd8be35fd64021876e997fa6351dd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b60e120c7c494ca5ba452d87a7c9c5a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06c3d9bac3844e6e986495206b1603c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d174f91bc8f4afcaad4ff3c4e599afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2374093c8ff147409f2532089e98356a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7d18ad25cbe4a05a9d29635629e4ff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"737c8ed893834e19a2cb477c4e8e0578":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82eecd43aa7d49d5b96247bd6d212ab1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85b3436da3da4110a78c2f79039ed4e8","IPY_MODEL_025477562f4646cb89407e8ccd121b77","IPY_MODEL_8880a7024e7648148943a3aac7c6e9bc"],"layout":"IPY_MODEL_0f4d3039face432185cbb3aba49099fd"}},"85b3436da3da4110a78c2f79039ed4e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c69586ab69d34f7387d1a9f7daf8962c","placeholder":"​","style":"IPY_MODEL_f8a746bc1627421d9bcb3606b6fa5c5e","value":"Downloading (…)in/added_tokens.json: 100%"}},"025477562f4646cb89407e8ccd121b77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1039dd687c4b4934b9e2c5422584d73c","max":22,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94059d0084e3445eae101b9811199037","value":22}},"8880a7024e7648148943a3aac7c6e9bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_363406f3612348fd982b9951601b0e1c","placeholder":"​","style":"IPY_MODEL_2f8f861dd8444ebbba07f1cd35eb6874","value":" 22.0/22.0 [00:00&lt;00:00, 534B/s]"}},"0f4d3039face432185cbb3aba49099fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c69586ab69d34f7387d1a9f7daf8962c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8a746bc1627421d9bcb3606b6fa5c5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1039dd687c4b4934b9e2c5422584d73c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94059d0084e3445eae101b9811199037":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"363406f3612348fd982b9951601b0e1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f8f861dd8444ebbba07f1cd35eb6874":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14b8936eb7f34d7886107c9e8d8eb534":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e265d89306364d199e2ffee5c17244c7","IPY_MODEL_e2a1ba13694d44379606d6cb07b17368","IPY_MODEL_58695ade42f94f7f940876689d6adf64"],"layout":"IPY_MODEL_6ac67bc047224787a4a0b7dd7b18bd60"}},"e265d89306364d199e2ffee5c17244c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62fc2f99aa704a3ca2d699b38ecc3a3d","placeholder":"​","style":"IPY_MODEL_a83a6aa33a7040738c58f8dad0b009df","value":"Downloading (…)cial_tokens_map.json: 100%"}},"e2a1ba13694d44379606d6cb07b17368":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_621607c128544167a6795de1285a52cc","max":167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca828656c1484b33a0109754a2cd5790","value":167}},"58695ade42f94f7f940876689d6adf64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05457a61a8274366839b6be76aac5c0d","placeholder":"​","style":"IPY_MODEL_0a91a2ba5c65434ab240b5cff58e852f","value":" 167/167 [00:00&lt;00:00, 2.87kB/s]"}},"6ac67bc047224787a4a0b7dd7b18bd60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62fc2f99aa704a3ca2d699b38ecc3a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a83a6aa33a7040738c58f8dad0b009df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"621607c128544167a6795de1285a52cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca828656c1484b33a0109754a2cd5790":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05457a61a8274366839b6be76aac5c0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a91a2ba5c65434ab240b5cff58e852f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["### GAN Attempt!"],"metadata":{"id":"l2vionRRzF_O"}},{"cell_type":"code","source":["# Colab pip installs\n","!pip install transformers\n","!pip install datasets"],"metadata":{"id":"JADRaL5b276C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679263454951,"user_tz":300,"elapsed":37666,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"75f98fbb-d65a-44c7-860d-0539bd940725"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.2 tokenizers-0.13.2 transformers-4.27.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.4)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.3.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.13.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.22.4)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.8.2\n"]}]},{"cell_type":"code","source":["# AWS pip installs\n","!pip install torch\n","!pip install pandas"],"metadata":{"id":"OF75rc8BBssA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679263469436,"user_tz":300,"elapsed":14489,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"89f415ca-abe8-4ecc-a055-bdf5cfb4921d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Setup\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from transformers import (\n","    AutoModelForSeq2SeqLM,\n","    AutoTokenizer,\n",")\n","import pandas as pd\n","from datasets import Dataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"ESRs9D8S2gd3","executionInfo":{"status":"ok","timestamp":1679263474204,"user_tz":300,"elapsed":4773,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/CS\\ 224N/CS\\ 224N\\ Project\n","%ls # verify that you are in the right directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txGRbtkd4IWq","executionInfo":{"status":"ok","timestamp":1679263687830,"user_tz":300,"elapsed":2027,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"cbd32bba-4f26-4495-c769-c8bf16a979b2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/CS 224N/CS 224N Project\n","'224N Experiments (GAN on 998 Samples).gsheet'\n","'224N Project Brainstorm.gdoc'\n","'224N Project Helpful Tutorials.gdoc'\n","'224N Project Milestone Notes.gdoc'\n"," Adversarial-T5_Structure_1.ipynb\n"," aita_clean.csv\n"," aita_comments.csv\n"," aita_test_set.csv\n"," aita_test_set.gsheet\n"," aita_train_set.csv\n"," aita_valid_set.csv\n"," \u001b[0m\u001b[01;34mbanana\u001b[0m/\n"," banana.ipynb\n"," \u001b[01;34mbart-base-checkpoint-204000\u001b[0m/\n"," bart-baseline-attempt2.ipynb\n"," \u001b[01;34mbart-checkpoint-5000\u001b[0m/\n"," bert-baseline.ipynb\n"," blueberry.ipynb\n"," checkpoint.txt\n"," config.json\n"," \u001b[01;34mcsvs\u001b[0m/\n"," dataset_agg.ipynb\n"," \u001b[01;34mdrive\u001b[0m/\n"," Evaluate.ipynb\n","'experimenting with gumbel.ipynb'\n"," \u001b[01;34mfinetune-gpt2\u001b[0m/\n","\u001b[01;34m'first proposal OLD'\u001b[0m/\n"," gan-gen-trial\n"," gan-halfway-gen-transformer-d\n"," gpt-2-attempt2.ipynb\n"," gpt2-attempt3.ipynb\n"," gpt2-baseline.ipynb\n"," \u001b[01;34mgpt2-small-rationale-generation\u001b[0m/\n"," gpt2-wt-5.ipynb\n"," \u001b[01;34mgrape\u001b[0m/\n"," grape-exploration.ipynb\n"," grape.ipynb\n"," honeydew.ipynb\n"," \u001b[01;34mlogs\u001b[0m/\n"," \u001b[01;34mmango\u001b[0m/\n"," Mango.ipynb\n"," \u001b[01;34mmango-old\u001b[0m/\n"," orange-halfway\n"," Orange.ipynb\n"," orange-trial\n","'Pear (1).ipynb'\n"," Pear.ipynb\n"," \u001b[01;34mpineapple\u001b[0m/\n"," Pineapple.ipynb\n"," \u001b[01;34mpineapple-old\u001b[0m/\n"," \u001b[01;34mprocessed-set-gpt2\u001b[0m/\n","'Reddit Scraper.ipynb'\n"," \u001b[01;34mresults\u001b[0m/\n"," rouge_scores_baseline.txt\n"," rouge_scores.txt\n","\u001b[01;34m'screenshots bart'\u001b[0m/\n","\u001b[01;34m'screenshots t5'\u001b[0m/\n"," T5_Attempt_2.ipynb\n"," t5_attempt3.ipynb\n"," T5-baseline.ipynb\n"," \u001b[01;34mwandb\u001b[0m/\n"," wmd_scores_baseline.txt\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define the generator (use the pre-trained BART implementation)\n","\"\"\"\n","\n","# bart-base checkpoint pre-trained on our dataset\n","# (can also try generically pre-trained bart base)\n","model_dir = 'bart-base-checkpoint-204000'\n","tokenizer = AutoTokenizer.from_pretrained(model_dir)\n","netG = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n","print(netG)"],"metadata":{"id":"0RgiUTBezH2V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679263825850,"user_tz":300,"elapsed":12374,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"28879e52-c248-4384-9a29-cfe54a0b6e52"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["BartForConditionalGeneration(\n","  (model): BartModel(\n","    (shared): Embedding(50265, 768, padding_idx=1)\n","    (encoder): BartEncoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartEncoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): GELUActivation()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): BartDecoder(\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n","      (layers): ModuleList(\n","        (0): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): BartDecoderLayer(\n","          (self_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (activation_fn): GELUActivation()\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): BartAttention(\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",")\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","sentiment = pipeline(model='finiteautomata/bertweet-base-sentiment-analysis')\n","#sentiment = AutoModel.from_pretrained('finiteautomata/bertweet-base-sentiment-analysis')"],"metadata":{"id":"fkszxZGJOuyZ","colab":{"base_uri":"https://localhost:8080/","height":259,"referenced_widgets":["bf4091de68c6454ab4f48258c7dd2839","27ff44ae73af4920a53eff6ef86c3040","d45b9783f57941f395d2fa3d4715928a","28ca1037022b4c27a24d31aaaef2ae3e","9e23c9c18ccb4974ad23a09bd850501a","69b73270e9f642098ccb95d8502df80f","323ce418f859413a9702ba4a45dce668","6566eb1c22f04cf68524afb6609eace5","a922591cebc64df188f1453e845e8873","f11c73c1c8cf41acb93c175f070175a7","b3b7aab84c9040f692f8e0f85dbdaf1d","31519269ae2745609738776796331a5a","80bd83607afc4d288c905b7b3344bf10","68fe0573ca0546a28984578a053c44de","142c225748374da5890400315b8cc76d","73382dee59ab4ddc85d09bfe9c73fe65","0ad93f4ef9484ed49ad6d60fc242ec2a","9c8af36054fb48f5bff01fc0a1edf2d6","7a6e5ca5471d4afd88a0644e704e7dc8","0166a25a0c7e460bbbc91e99efe9fb2e","2a85403736824aa3ba8b13fd637b0663","5c11246228d64f0b8bd2a22eeca80bd4","3c7cd87678c0454592ae1a18b740ec0a","556f682ce285473b99fa2b5abe2f0f72","ed8656ac823a4e10ac1b258cb1276ea0","9e8a835db2014ca9b2850b03669941ff","b59ea4f0f8f54bc6a6875e48446c2674","4047999f87d9450d8096a941e8628f64","b1013e25a4914962a9000e96342dcbc3","0b55d0abe9454046a193fd49d8415eaa","c67ee68a87a042d09df6782ff79eef48","926872a5e4484e7b9c1fcf8310c52686","5bb93023d5cf4d2eae64f9b831f941b3","3ca42b4042b04b3da998ef6e227933b1","7e4d4d59ee1342e9b5cf90aebec012c7","00789a1b56584f849a1ed588155eae37","7d58d540c4ce4471a2bf35143d36d5cb","6bd46666f47246cd851fb35afa2cc99e","c5afdc4bc2b04480bcd6879504f95a75","cd1969d3642748c5945c2ce4947caa3b","b74c61fb18e34ed69efe819f1807bb76","0bf401aaffed45529892cc39ff9125cc","6a3135f844f940d88808e4bbf28fc172","66ce1666ae1143c0a842107e406c2b03","6bb894cb795f475aa4351fff902e33e0","31d5df99b9844c89a9b2b1eb40f64700","15a3aec93d894edd8f532fc15b6bcf22","763ababed79a4afc926ff309cce609ce","cbbd8be35fd64021876e997fa6351dd1","b60e120c7c494ca5ba452d87a7c9c5a2","06c3d9bac3844e6e986495206b1603c9","6d174f91bc8f4afcaad4ff3c4e599afa","2374093c8ff147409f2532089e98356a","e7d18ad25cbe4a05a9d29635629e4ff2","737c8ed893834e19a2cb477c4e8e0578","82eecd43aa7d49d5b96247bd6d212ab1","85b3436da3da4110a78c2f79039ed4e8","025477562f4646cb89407e8ccd121b77","8880a7024e7648148943a3aac7c6e9bc","0f4d3039face432185cbb3aba49099fd","c69586ab69d34f7387d1a9f7daf8962c","f8a746bc1627421d9bcb3606b6fa5c5e","1039dd687c4b4934b9e2c5422584d73c","94059d0084e3445eae101b9811199037","363406f3612348fd982b9951601b0e1c","2f8f861dd8444ebbba07f1cd35eb6874","14b8936eb7f34d7886107c9e8d8eb534","e265d89306364d199e2ffee5c17244c7","e2a1ba13694d44379606d6cb07b17368","58695ade42f94f7f940876689d6adf64","6ac67bc047224787a4a0b7dd7b18bd60","62fc2f99aa704a3ca2d699b38ecc3a3d","a83a6aa33a7040738c58f8dad0b009df","621607c128544167a6795de1285a52cc","ca828656c1484b33a0109754a2cd5790","05457a61a8274366839b6be76aac5c0d","0a91a2ba5c65434ab240b5cff58e852f"]},"executionInfo":{"status":"ok","timestamp":1679263846221,"user_tz":300,"elapsed":20373,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"9d62dff5-c800-4db3-899b-a1b4bc04a5fe"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/949 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf4091de68c6454ab4f48258c7dd2839"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31519269ae2745609738776796331a5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c7cd87678c0454592ae1a18b740ec0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ca42b4042b04b3da998ef6e227933b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb894cb795f475aa4351fff902e33e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82eecd43aa7d49d5b96247bd6d212ab1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14b8936eb7f34d7886107c9e8d8eb534"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Define convolutional discriminator\n","\"\"\"\n","\n","nc = 1\n","ndf = 64\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            #Reshaping input\n","            nn.Upsample(size=(64, 64)), #bring image from 1, 1, 1, 320 --> 1, 1, 64, 64\n","            # input is (nc) x 64 x 64 | our input is 1 x 64\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf) x 32 x 32\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*2) x 16 x 16\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*4) x 8 x 8\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            # state size. (ndf*8) x 4 x 4\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        #print(len(input.shape))\n","        return self.main(input)"],"metadata":{"id":"XBPd1v0Q34Jn","executionInfo":{"status":"ok","timestamp":1679263846452,"user_tz":300,"elapsed":5,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ngpu = 1\n","netD = Discriminator(ngpu).to(device)"],"metadata":{"id":"F4fElnOc_aAR","executionInfo":{"status":"error","timestamp":1679263852756,"user_tz":300,"elapsed":6308,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"colab":{"base_uri":"https://localhost:8080/","height":336},"outputId":"9974dd3e-0b7c-46fd-9615-3c0ad07eddda"},"execution_count":10,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-005b083b593b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mngpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnetD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["\"\"\"\n","Loss functions and optimizers\n","\"\"\"\n","# Size of generator input\n","nz = 512\n","# Optim params\n","lr = 0.0002\n","beta1 = 0.5\n","\n","# Initialize BCELoss function\n","criterion = nn.BCELoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"],"metadata":{"id":"mLLWvDY-7M96","executionInfo":{"status":"aborted","timestamp":1679263852757,"user_tz":300,"elapsed":6,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zA0gynyNom7B","executionInfo":{"status":"aborted","timestamp":1679263852757,"user_tz":300,"elapsed":6,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"source":["train_df = pd.read_csv('aita_train_set.csv')[['text', 'comments']]\n","valid_df = pd.read_csv('aita_valid_set.csv')[['text', 'comments']]\n","test_df = pd.read_csv('aita_test_set.csv')[['text', 'comments']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data_txt = Dataset.from_pandas(train_df)\n","validation_data_txt = Dataset.from_pandas(valid_df)\n","test_data_txt = Dataset.from_pandas(test_df)\n","print(train_data_txt)\n","print(validation_data_txt)\n","print(test_data_txt)"],"metadata":{"id":"Qf4cgIQL9uCA","executionInfo":{"status":"aborted","timestamp":1679263852757,"user_tz":300,"elapsed":6,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Preprocess\n","\"\"\"\n","\n","encoder_max_length = 256  # changed from 256\n","decoder_max_length = 64  # changed from 64\n","\n","def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n","    source, target = batch[\"text\"], batch[\"comments\"]\n","    source_tokenized = tokenizer(\n","        source, padding=\"max_length\", truncation=True, max_length=max_source_length, return_tensors=\"pt\"\n","    )\n","    target_tokenized = tokenizer(\n","        target, padding=\"max_length\", truncation=True, max_length=max_target_length, return_tensors=\"pt\"\n","    )\n","\n","    batch = {k: v for k, v in source_tokenized.items()}\n","    # Ignore padding in the loss\n","    batch[\"labels\"] = [\n","        [-100 if token == tokenizer.pad_token_id else token for token in l]\n","        for l in target_tokenized[\"input_ids\"]\n","    ]\n","    return batch\n","\n","\n","train_data = train_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=train_data_txt.column_names,\n",")\n","\n","validation_data = validation_data_txt.map(\n","    lambda batch: batch_tokenize_preprocess(\n","        batch, tokenizer, encoder_max_length, decoder_max_length\n","    ),\n","    batched=True,\n","    remove_columns=validation_data_txt.column_names,\n",")"],"metadata":{"id":"wvBpN-KNAJ4x","executionInfo":{"status":"aborted","timestamp":1679263852758,"user_tz":300,"elapsed":7,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_data)"],"metadata":{"id":"fRueMmaYFamD","executionInfo":{"status":"aborted","timestamp":1679263852758,"user_tz":300,"elapsed":6,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_data[0]['input_ids']))"],"metadata":{"id":"MVc3xgHXFdk4","executionInfo":{"status":"aborted","timestamp":1679263852759,"user_tz":300,"elapsed":7,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_sentiment_tokens(comment):\n","  max_input_length = 128\n","  if len(comment) > 128:\n","    comment = comment[:128]\n","  comment_sentiment = sentiment([comment])[0]\n","  comment_sentiment = comment_sentiment['label'] + ': ' + str(comment_sentiment['score'])\n","  comment_sentiment_tokens = tokenizer(comment_sentiment, max_length=128, padding='max_length', truncation=True, return_tensors=\"pt\")\n","  return comment_sentiment_tokens['input_ids'].tolist()"],"metadata":{"id":"VVZAe30YO7nc","executionInfo":{"status":"aborted","timestamp":1679263852759,"user_tz":300,"elapsed":7,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fixed_validation_index = 17\n","fixed_validation_inputs = valid_df.iloc[fixed_validation_index]['text']\n","fixed_validation_data = tokenizer(fixed_validation_inputs, max_length=512, padding='max_length', truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"aYSn2PZcA4Pa","executionInfo":{"status":"aborted","timestamp":1679263852759,"user_tz":300,"elapsed":7,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=4\n","dataloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n","                                         shuffle=True)\n","for i, data in enumerate(dataloader, 0):\n","  print(torch.stack(data['attention_mask']).shape)\n","  break\n"],"metadata":{"id":"OTM_7TRDEuwr","executionInfo":{"status":"aborted","timestamp":1679263852760,"user_tz":300,"elapsed":8,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["################ Changing the working data to validation ####################\n","\n","# Training Loop\n","\n","# Lists to keep track of progress\n","img_list = []\n","G_losses = []\n","D_losses = []\n","iters = 0\n","num_epochs = 1\n","max_input_length = 512\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # todo: batch this/use a dataloader\n","    for i in range(len(validation_data)):\n","        data = validation_data[i]\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        netD.zero_grad()\n","        # Format batch\n","        sentiment_tokens = get_sentiment_tokens(str(valid_df.iloc[i]['comments']))\n","        real_cpu = torch.tensor(data['input_ids'] + data['labels'] + sentiment_tokens[0], dtype=torch.float32)\n","        real_cpu = real_cpu.view(1, 1, 1, 64 + 256 + 128) # label size + encoder size\n","        real_cpu = real_cpu.to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","        #discriminator will train off of true comments in the real batch pass\n","\n","        # Forward pass real batch through D\n","        output = netD(real_cpu).view(-1) \n","        # Calculate loss on all-real batch\n","        errD_real = criterion(output, label)\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","\n","        inputs = valid_df.iloc[i]['text']\n","        generator_input = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","        fake = netG.generate(**generator_input, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","        decoded_fake_comment = tokenizer.batch_decode(fake, skip_special_tokens=True)\n","        sentiment_tokens = get_sentiment_tokens(decoded_fake_comment[0])\n","        inp_tensor_1 = torch.tensor(sentiment_tokens[0], dtype=torch.long).unsqueeze(0)\n","        fake = torch.cat((fake, inp_tensor_1), dim=1)\n","        inp_tensor = torch.tensor(data['input_ids'], dtype=torch.long).unsqueeze(0)\n","        fake = torch.cat((inp_tensor, fake), dim=1)\n","        label.fill_(fake_label)\n","        # Classify all fake batch with D\n","        #print(fake.shape)\n","        fake = fake.type(torch.float32)\n","        fake = fake.view(1, 1, 1, -1)\n","        fake = fake.detach().to(device)\n","        output = netD(fake).view(-1)\n","        # Calculate D's loss on the all-fake batch\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output = netD(fake).view(-1)\n","        # Calculate G's loss based on this output\n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        if i % 5 == 0:\n","            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","                  % (epoch, num_epochs, i, len(validation_data),\n","                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        if iters == 5: netG.save_pretrained('honeydew/hf-save-initial')\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","            netG.save_pretrained('honeydew/hf-save-initial')\n","            with torch.no_grad():\n","                fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1\n","\n","netG.save_pretrained('honeydew/hf-save-initial')"],"metadata":{"id":"e7CIqDPACJV9","executionInfo":{"status":"aborted","timestamp":1679263852760,"user_tz":300,"elapsed":8,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i, data in enumerate(dataloader, 0):\n","#         #data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         #print(data)\n","#         print(data['labels'])\n","#         real_cpu = torch.stack(data['labels'])\n","#         #real_cpu = torch.unsqueeze(real_cpu, dim=0)\n","#         #real_cpu = torch.cat(real_cpu, dim=0)\n","#         #real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.type(torch.FloatTensor).view(-1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         #inputs = train_df.iloc[i]['text']\n","#         #data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         data = {k : torch.stack(v) for k, v in data.items()}\n","#         fake = netG(**data)\n","\n","#         # fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"kpQNOHLX7dL_","executionInfo":{"status":"aborted","timestamp":1679263508473,"user_tz":300,"elapsed":49,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ################ WORKING DO NOT TOUCH ####################\n","\n","# # Training Loop\n","\n","# # Lists to keep track of progress\n","# img_list = []\n","# G_losses = []\n","# D_losses = []\n","# iters = 0\n","# num_epochs = 1\n","# max_input_length = 512\n","\n","# print(\"Starting Training Loop...\")\n","# # For each epoch\n","# for epoch in range(num_epochs):\n","#     # todo: batch this/use a dataloader\n","#     for i in range(len(train_data)):\n","#         data = train_data[i]\n","#         ############################\n","#         # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","#         ###########################\n","#         ## Train with all-real batch\n","#         netD.zero_grad()\n","#         # Format batch\n","#         #print(len(data['labels']))\n","#         real_cpu = torch.tensor(data['labels'], dtype=torch.float32)\n","#         #real_cpu = data['labels']\n","#         #print(real_cpu.shape)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         # real_cpu = real_cpu.unsqueeze(0)\n","#         real_cpu = real_cpu.view(1, 1, 1, 64) #these are the comment tokens\n","#         #print(real_cpu.shape)\n","#         real_cpu = real_cpu.to(device)\n","#         b_size = real_cpu.size(0)\n","#         label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","\n","#         #discriminator will train off of true comments in the real batch pass\n","#         # Forward pass real batch through D\n","#         output = netD(real_cpu).view(-1) \n","#         # Calculate loss on all-real batch\n","#         errD_real = criterion(output, label)\n","#         # Calculate gradients for D in backward pass\n","#         errD_real.backward()\n","#         D_x = output.mean().item()\n","\n","#         ## Train with all-fake batch\n","#         # Generate batch of latent vectors\n","#         # noise = torch.randn(b_size, nz, 1, 1, device=device)\n","#         # print(inputs['input_ids'].shape)\n","#         # output = model.generate(**inputs, num_beams=8, do_sample=True, min_length=10, max_length=64)\n","#         # Generate fake image batch with G\n","\n","#         inputs = train_df.iloc[i]['text']\n","#         data = tokenizer(inputs, max_length=max_input_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n","#         fake = netG.generate(**data, num_beams=8, do_sample=True, min_length=10, max_length=64) #generate a fake comment\n","#         label.fill_(fake_label)\n","#         # Classify all fake batch with D\n","#         #print(fake.shape)\n","#         fake = fake.type(torch.float32)\n","#         fake = fake.view(1, 1, 1, -1)\n","#         fake = fake.detach().to(device)\n","#         output = netD(fake).view(-1)\n","#         # Calculate D's loss on the all-fake batch\n","#         errD_fake = criterion(output, label)\n","#         # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","#         errD_fake.backward()\n","#         D_G_z1 = output.mean().item()\n","#         # Compute error of D as sum over the fake and the real batches\n","#         errD = errD_real + errD_fake\n","#         # Update D\n","#         optimizerD.step()\n","\n","#         ############################\n","#         # (2) Update G network: maximize log(D(G(z)))\n","#         ###########################\n","#         netG.zero_grad()\n","#         label.fill_(real_label)  # fake labels are real for generator cost\n","#         # Since we just updated D, perform another forward pass of all-fake batch through D\n","#         output = netD(fake).view(-1)\n","#         # Calculate G's loss based on this output\n","#         errG = criterion(output, label)\n","#         # Calculate gradients for G\n","#         errG.backward()\n","#         D_G_z2 = output.mean().item()\n","#         # Update G\n","#         optimizerG.step()\n","\n","#         # Output training stats\n","#         if i % 5 == 0:\n","#             print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","#                   % (epoch, num_epochs, i, len(train_data),\n","#                      errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","#         # Save Losses for plotting later\n","#         G_losses.append(errG.item())\n","#         D_losses.append(errD.item())\n","\n","#         # Check how the generator is doing by saving G's output on fixed_noise\n","#         if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_data)-1)):\n","#             with torch.no_grad():\n","#                 fake = netG.generate(**fixed_validation_data, num_beams=8, do_sample=True, min_length=10, max_length=64).detach()\n","#             # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","#         iters += 1"],"metadata":{"id":"bZkK8xM0FBpM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QxIWu1TqEse1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","\n","# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# print(input.shape)\n","# m = nn.Upsample(size=(64, 64))\n","# output = m(input)\n","# output = output.reshape((1, 64, 64))\n","# print(output.shape)\n","\n","# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zmQecWWiUWa","executionInfo":{"status":"ok","timestamp":1678955908751,"user_tz":420,"elapsed":4,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"4cadc926-a2e4-4e1e-9d58-cca67eba9de9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 1, 64])\n","torch.Size([1, 64, 64])\n","torch.Size([1, 3, 24, 24])\n"]}]},{"cell_type":"code","source":["# up = nn.Upsample(size=(24, 24))\n","\n","# x = torch.randn(1, 3, 10, 10)\n","# print(up(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZdysfkciVDS","executionInfo":{"status":"ok","timestamp":1678955791919,"user_tz":420,"elapsed":262,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"5be6611a-1854-424a-c18f-68023f87d982"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 3, 24, 24])\n"]}]},{"cell_type":"code","source":["# input = torch.randn(1, 64).view(1, 1, 1, 64)\n","# m = nn.Upsample(size=(64, 64))\n","# intermediate = m(input)\n","# x = nn.Flatten(0, 1)\n","# output = x(intermediate)\n","# print(input.shape)\n","# print(intermediate.shape)\n","# print(output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0P87XbnOkEOm","executionInfo":{"status":"ok","timestamp":1678956597151,"user_tz":420,"elapsed":331,"user":{"displayName":"Priya Khandelwal","userId":"03711845755022262656"}},"outputId":"d552bbfe-cac2-4cac-cc78-a99e015bd387"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 1, 64])\n","torch.Size([1, 1, 64, 64])\n","torch.Size([1, 64, 64])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8BIW0Ev3m4b0"},"execution_count":null,"outputs":[]}]}