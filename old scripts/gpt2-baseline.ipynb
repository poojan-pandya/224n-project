{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22334,"status":"ok","timestamp":1677839439160,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"},"user_tz":480},"id":"1d8lostUWdPe","outputId":"3ac16d1f-b1d8-4fbc-d690-12a2a6008a1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["!pip install transformers\n","\n","import pandas as pd\n","import os\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import numpy as np\n","import random\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n","from tqdm import tqdm, trange\n","import torch.nn.functional as F\n","import csv"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19409,"status":"ok","timestamp":1677839458564,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"},"user_tz":480},"id":"hCTbAVlfZv2o","outputId":"a9a61fbd-e3d4-46a5-9d7c-309635f070ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/CS 224N/CS 224N Project\n","'224N Project Brainstorm.gdoc'\t        dataset_agg.ipynb\n","'224N Project Helpful Tutorials.gdoc'  'first proposal OLD'\n","'224N Project Milestone Notes.gdoc'     gpt2-baseline.ipynb\n"," aita_clean.csv\t\t\t        logs\n"," aita_comments.csv\t\t       'Reddit Scraper.ipynb'\n"," aita_test_set.csv\t\t        results\n"," aita_train_set.csv\t\t        T5-baseline.ipynb\n"," aita_valid_set.csv\t\t        t5_checkpoints\n"," bart-baseline-attempt2.ipynb\t        train.pt\n"," bert-baseline.ipynb\t\t        wandb\n"," csvs\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/CS\\ 224N/CS\\ 224N\\ Project\n","! ls # verify that you are in the right directory"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3504,"status":"ok","timestamp":1677839462065,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"},"user_tz":480},"id":"14zmAgtRjYGp"},"outputs":[],"source":["train_data = pd.read_csv('aita_train_set.csv')\n","valid_data = pd.read_csv('aita_valid_set.csv')\n","test_data = pd.read_csv('aita_test_set.csv')"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"u18wfzvmk6To","executionInfo":{"status":"ok","timestamp":1677840536549,"user_tz":480,"elapsed":8041,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"outputs":[],"source":["# class RedditText(Dataset):  \n","#     def __init__(self,control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n","\n","#         self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n","#         self.texts = []\n","#         self.comments = []\n","\n","#         for row in valid_data['text']:\n","#           self.comments.append(torch.tensor(\n","#                 self.tokenizer.encode(f\"<|{control_code}|>{row[:max_length]}<|endoftext|>\")\n","#             ))               \n","\n","#         # for index, row in valid_data.iterrows():\n","#           #  self.texts.append(torch.tensor(\n","#           #       self.tokenizer.encode(f\"<|start|>{row['text'][:max_length]}<|endoftext|>\")\n","#           #   ))  \n","#           #  self.comments.append(torch.tensor(\n","#           #       self.tokenizer.encode(f\"<|start|>{row['comments'][:max_length]}<|endoftext|>\")\n","#           #   ))  \n","#           # self.texts.append(torch.tensor(\n","#           #       self.tokenizer.encode(f\"<|{control_code}|>{row['text']}<|endoftext|>\"[:max_length])\n","#           #   ))  \n","#           # self.comments.append(torch.tensor(\n","#           #       self.tokenizer.encode(f\"<|{control_code}|>{row['comments'][:max_length]}<|endoftext|>\")\n","#           #   ))  \n","          \n","#         if truncate:\n","#             self.texts = self.texts[:20000]\n","#         self.texts_count = len(self.texts)\n","        \n","#     def __len__(self):\n","#         return self.texts_count\n","\n","#     def __getitem__(self, item):\n","#         comment = self.comments[item]\n","#         text = self.texts[item]\n","#         return text\n","    \n","# dataset = RedditText(valid_data[\"text\"], truncate=False, gpt2_type=\"gpt2\")  "]},{"cell_type":"code","source":["\n","class RedditText(Dataset):  \n","    def __init__(self, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=1024):\n","\n","        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n","        self.texts = []\n","        self.comments = []\n","        self.comments_len = []\n","\n","        for row in valid_data['text']:\n","          s = f\"<start>{row[:max_length - 20]}<|endoftext|>\"\n","          s += '.' * int(max_length - len(s))\n","          self.texts.append(torch.tensor(\n","                self.tokenizer.encode(s)\n","            ))   \n","          # print(self.texts[-1].size())\n","          # break\n","        for row in valid_data['comments']:\n","          \n","          s = f\"<|start|>{row[:max_length]}<|endofcomment|>\"\n","          s += '.' * int(max_length - len(s))\n","          self.comments.append(torch.tensor(\n","                self.tokenizer.encode(s)\n","            ))   \n","          # print(self.comments[-1].size())\n","        if truncate:\n","            self.texts = self.texts[:20000]\n","        self.texts_count = len(self.texts)\n","        \n","    def __len__(self):\n","        return self.texts_coun\n","\n","    def __getitem__(self, item):\n","        return self.texts[item], self.comments[item]\n","    \n","dataset = RedditText(valid_data['text'], truncate=False, gpt2_type=\"gpt2\")      "],"metadata":{"id":"OjH_X4CZF29y","executionInfo":{"status":"ok","timestamp":1677843615259,"user_tz":480,"elapsed":6950,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":108,"outputs":[]},{"cell_type":"code","source":["# # torch.save(dataset, './train.pt')\n","# # from train import RedditText\n","# data = RedditText()\n","# data = torch.load('./train.pt') \n","# print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["9bc3be5bf1a64e96af542b7c4e0cf1ac","d74dbd6da83d4430bfef2bc62ae3ebbe","30975fc4a5cb45f6828e72a0a239e1c2","4f972619f1bb45b3a129b730d97d8ba2","85e156f3813042648854d78b4f5ecad7","cec00a91c4d44da89456fc09d73a0b50","659e7da23b8f43c0912d4d637c4c2940","cc614771c27f408291a8ec6fa659a3c1","8dc66e9592ef4621bb2c7deb58f9a5ad","a8c0cfa239204a0fab13cf1a8b4e78de","82efec08036843289d7cb5f131272f7d","aeebbd597fe240bcaebecfd4797172e8","c6b762e9e98b4efdbfb7aa22c8afafd5","83bec30bfaea43fc80960d1e56ee9d1e","02aa46c3d86741c89b4376fb1c798ce6","204ab89a0f88482eae86e4b328ac516f","c27fbd4711224662ad21c0d7fb49c0e8","151a327fef0f496faae301e916b33fc0","cdd02a47286845b7a015ba6b8cb60c02","168f3ea25c83400b9502d39a3d175816","fbda971c4dfd4215862e945631f7b83f","943ec51dfb5e4e01971e29567214fb45","f6409dbae5d445c68cb44a7f412562c4","6a5fcd0eb2f0480b860ff030d3326623","51f9c47549884fd2a2d97a795cad7428","2884b159246141a6a05aaf032ddce675","123883af342f42e3abc41fc6f9cc6e58","90e716662ec64aaa8db79a2c5b23c1d5","440479195a9745d182aa93e4c5372a78","326977284c3347b8a91c8dcc710e1b48","9753760d7cae4c89a2aa1fb487615cf4","512f8a835dbb4d15835955892712b25d","bdaf3a41bf7048bd8c6a155d549759b4"]},"id":"Ot6kO4-v_VN7","executionInfo":{"status":"ok","timestamp":1677839753243,"user_tz":480,"elapsed":34804,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}},"outputId":"5148e86a-8b1f-4a58-c1a3-e50501f51e9e"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bc3be5bf1a64e96af542b7c4e0cf1ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeebbd597fe240bcaebecfd4797172e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6409dbae5d445c68cb44a7f412562c4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<__main__.RedditText object at 0x7fcb554f9850>\n"]}]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":3174,"status":"ok","timestamp":1677843533130,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"},"user_tz":480},"id":"hAtoQs6RlMMk"},"outputs":[],"source":["#Get the tokenizer and model\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","#Accumulated batch size (since GPT2 is so big)\n","def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n","    if packed_tensor is None:\n","        return new_tensor, True, None\n","    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n","        return packed_tensor, False, new_tensor\n","    else:\n","        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n","        return packed_tensor, True, None"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"-tYXLgcflWM1","executionInfo":{"status":"ok","timestamp":1677840320459,"user_tz":480,"elapsed":102,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"outputs":[],"source":["# def train(\n","#     dataset, model, tokenizer,\n","#     batch_size=16, epochs=5, lr=2e-5,\n","#     max_seq_len=400, warmup_steps=200,\n","#     gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n","#     test_mode=False,save_model_on_epoch=False,\n","# ):\n","#     acc_steps = 100\n","#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#     # if on gpu uncomment the below two lines\n","#     model = model.to(device)\n","#     model.train()\n","\n","#     optimizer = AdamW(model.parameters(), lr=lr)\n","#     scheduler = get_linear_schedule_with_warmup(\n","#         optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n","#     )\n","\n","#     train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n","#     loss=0\n","#     accumulating_batch_count = 0\n","#     input_tensor = None\n","\n","#     for epoch in range(epochs):\n","\n","#         print(f\"Training epoch {epoch}\")\n","#         print(loss)\n","#         for idx, entry in tqdm(enumerate(train_dataloader)):\n","#             (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n","\n","#             if carry_on and idx != len(train_dataloader) - 1:\n","#                 continue\n","\n","#             # if on cuda gpu uncomment the below line\n","#             input_tensor = input_tensor.to(device)\n","#             # print(input_tensor)\n","#             # print(outputs)\n","#             outputs = model(input_tensor, labels=entry)\n","#             loss = outputs[0]\n","#             loss.backward()\n","#             if idx % 100 == 0:\n","#               print(f'index number: {idx} and loss: {loss.item()}')\n","\n","#             if (accumulating_batch_count % batch_size) == 0:\n","#                 optimizer.step()\n","#                 scheduler.step()\n","#                 optimizer.zero_grad()\n","#                 model.zero_grad()\n","\n","#             accumulating_batch_count += 1\n","#             input_tensor = None\n","#         if save_model_on_epoch:\n","#             torch.save(\n","#                 model.state_dict(),\n","#                 os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n","#             )\n","#     return model"]},{"cell_type":"code","source":["def train(\n","    dataset, model, tokenizer,\n","    batch_size=16, epochs=5, lr=2e-5,\n","    max_seq_len=400, warmup_steps=200,\n","    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n","    test_mode=False,save_model_on_epoch=False,\n","):\n","    acc_steps = 100\n","    # device=torch.device(\"cuda\")\n","    # model = model.cuda()\n","    model.train()\n","\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n","    )\n","\n","    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n","    loss=0\n","    accumulating_batch_count = 0\n","    input_tensor = None\n","\n","    for epoch in range(epochs):\n","\n","        print(f\"Training epoch {epoch}\")\n","        print(loss)\n","        for idx, entry in tqdm(enumerate(train_dataloader)):\n","            (input_tensor, carry_on, remainder) = pack_tensor(entry[0], input_tensor, 768)\n","\n","            if carry_on and idx != len(train_dataloader) - 1:\n","                continue\n","\n","            # input_tensor = input_tensor.to(device)\n","            print(input_tensor.size())\n","            print(entry[1].size())\n","            outputs = model(input_tensor, labels=entry[1])\n","            loss = outputs[0]\n","            loss.backward()\n","            if idx % 10 ==0:\n","              print(loss.item())\n","\n","            if (accumulating_batch_count % batch_size) == 0:\n","                optimizer.step()\n","                scheduler.step()\n","                optimizer.zero_grad()\n","                model.zero_grad()\n","\n","            accumulating_batch_count += 1\n","            input_tensor = None\n","        if save_model_on_epoch:\n","            torch.save(\n","                model.state_dict(),\n","                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n","            )\n","    return model"],"metadata":{"id":"3gR69PZuFAJ7","executionInfo":{"status":"ok","timestamp":1677843620955,"user_tz":480,"elapsed":162,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"K2iecPHYlsj5","outputId":"cb3cc0c9-98f6-4cab-cde6-7b0c8528cca5","executionInfo":{"status":"error","timestamp":1677843641345,"user_tz":480,"elapsed":104,"user":{"displayName":"Kavin Anand","userId":"15878202627142921242"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-18f74d663d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_model_on_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"]}],"source":["model = train(dataset, model, tokenizer, epochs=1, save_model_on_epoch=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6vZDIavmXWq"},"outputs":[],"source":["def generate(\n","    model,\n","    tokenizer,\n","    prompt,\n","    entry_count=10,\n","    entry_length=50, #maximum number of words to generate based on avg comment length\n","    top_p=0.8,\n","    temperature=1.,\n","):\n","    model.eval()\n","    generated_num = 0\n","    generated_list = []\n","\n","    filter_value = -float(\"Inf\")\n","\n","    with torch.no_grad():\n","\n","        for entry_idx in trange(entry_count):\n","\n","            entry_finished = False\n","            generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n","\n","            for i in range(entry_length):\n","                outputs = model(generated, labels=generated)\n","                loss, logits = outputs[:2]\n","                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n","\n","                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n","                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n","\n","                sorted_indices_to_remove = cumulative_probs > top_p\n","                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[\n","                    ..., :-1\n","                ].clone()\n","                sorted_indices_to_remove[..., 0] = 0\n","\n","                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n","                logits[:, indices_to_remove] = filter_value\n","\n","                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n","                generated = torch.cat((generated, next_token), dim=1)\n","\n","                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n","                    entry_finished = True\n","\n","                if entry_finished:\n","\n","                    generated_num = generated_num + 1\n","\n","                    output_list = list(generated.squeeze().numpy())\n","                    output_text = tokenizer.decode(output_list)\n","                    generated_list.append(output_text)\n","                    break\n","            \n","            if not entry_finished:\n","              output_list = list(generated.squeeze().numpy())\n","              output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n","              generated_list.append(output_text)\n","                \n","    return generated_list\n","\n","#Function to generate multiple sentences. Test data should be a dataframe\n","def text_generation(test_data):\n","  generated_texts = []\n","  for i in range(len(test_data)):\n","    x = generate(model.to('cpu'), tokenizer, test_data['text'][i], entry_count=1)\n","    generated_texts.append(x)\n","  return generated_texts\n","\n","#Run the functions to generate the texts\n","generated_texts = text_generation(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBlZ8PqWndZp"},"outputs":[],"source":["my_generations=[]\n","\n","# for i in range(len(generated_texts)):\n","#   # a = test_data['Lyric'][i].split()[-30:] #Get the matching string we want (30 words)\n","#   a = test_data['comments'][i] #Get the matching string we want (30 words)\n","\n","  # b = ' '.join(a)\n","  # c = ' '.join(generated_texts[i]) #Get all that comes after the matching string\n","  # my_generations.append(c.split(b)[-1])\n","my_generations = generated_texts\n","test_data['generated_comments'] = my_generations\n","\n","\n","#Finish the sentences when there is a point, remove after that\n","final=[]\n","\n","for i in range(len(test_data)):\n","  to_remove = test_data['generated_comments'][i].split('.')[-1]\n","  final.append(test_data['generated_comments'][i].replace(to_remove,''))\n","\n","test_data['generated_comments'] = final"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WGUR-M0Ony-7"},"outputs":[],"source":["import statistics\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","scores=[]\n","\n","for i in range(len(test_data)):\n","  reference = test_data['comments'][i]\n","  candidate = test_data['generated_comments'][i]\n","  scores.append(sentence_bleu(reference, candidate))\n","\n","statistics.mean(scores)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"9bc3be5bf1a64e96af542b7c4e0cf1ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d74dbd6da83d4430bfef2bc62ae3ebbe","IPY_MODEL_30975fc4a5cb45f6828e72a0a239e1c2","IPY_MODEL_4f972619f1bb45b3a129b730d97d8ba2"],"layout":"IPY_MODEL_85e156f3813042648854d78b4f5ecad7"}},"d74dbd6da83d4430bfef2bc62ae3ebbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cec00a91c4d44da89456fc09d73a0b50","placeholder":"​","style":"IPY_MODEL_659e7da23b8f43c0912d4d637c4c2940","value":"Downloading (…)olve/main/vocab.json: 100%"}},"30975fc4a5cb45f6828e72a0a239e1c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc614771c27f408291a8ec6fa659a3c1","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8dc66e9592ef4621bb2c7deb58f9a5ad","value":1042301}},"4f972619f1bb45b3a129b730d97d8ba2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8c0cfa239204a0fab13cf1a8b4e78de","placeholder":"​","style":"IPY_MODEL_82efec08036843289d7cb5f131272f7d","value":" 1.04M/1.04M [00:00&lt;00:00, 5.59MB/s]"}},"85e156f3813042648854d78b4f5ecad7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cec00a91c4d44da89456fc09d73a0b50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"659e7da23b8f43c0912d4d637c4c2940":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc614771c27f408291a8ec6fa659a3c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dc66e9592ef4621bb2c7deb58f9a5ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8c0cfa239204a0fab13cf1a8b4e78de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82efec08036843289d7cb5f131272f7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeebbd597fe240bcaebecfd4797172e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6b762e9e98b4efdbfb7aa22c8afafd5","IPY_MODEL_83bec30bfaea43fc80960d1e56ee9d1e","IPY_MODEL_02aa46c3d86741c89b4376fb1c798ce6"],"layout":"IPY_MODEL_204ab89a0f88482eae86e4b328ac516f"}},"c6b762e9e98b4efdbfb7aa22c8afafd5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c27fbd4711224662ad21c0d7fb49c0e8","placeholder":"​","style":"IPY_MODEL_151a327fef0f496faae301e916b33fc0","value":"Downloading (…)olve/main/merges.txt: 100%"}},"83bec30bfaea43fc80960d1e56ee9d1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdd02a47286845b7a015ba6b8cb60c02","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_168f3ea25c83400b9502d39a3d175816","value":456318}},"02aa46c3d86741c89b4376fb1c798ce6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbda971c4dfd4215862e945631f7b83f","placeholder":"​","style":"IPY_MODEL_943ec51dfb5e4e01971e29567214fb45","value":" 456k/456k [00:00&lt;00:00, 2.96MB/s]"}},"204ab89a0f88482eae86e4b328ac516f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c27fbd4711224662ad21c0d7fb49c0e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"151a327fef0f496faae301e916b33fc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdd02a47286845b7a015ba6b8cb60c02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"168f3ea25c83400b9502d39a3d175816":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbda971c4dfd4215862e945631f7b83f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"943ec51dfb5e4e01971e29567214fb45":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6409dbae5d445c68cb44a7f412562c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a5fcd0eb2f0480b860ff030d3326623","IPY_MODEL_51f9c47549884fd2a2d97a795cad7428","IPY_MODEL_2884b159246141a6a05aaf032ddce675"],"layout":"IPY_MODEL_123883af342f42e3abc41fc6f9cc6e58"}},"6a5fcd0eb2f0480b860ff030d3326623":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90e716662ec64aaa8db79a2c5b23c1d5","placeholder":"​","style":"IPY_MODEL_440479195a9745d182aa93e4c5372a78","value":"Downloading (…)lve/main/config.json: 100%"}},"51f9c47549884fd2a2d97a795cad7428":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_326977284c3347b8a91c8dcc710e1b48","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9753760d7cae4c89a2aa1fb487615cf4","value":665}},"2884b159246141a6a05aaf032ddce675":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_512f8a835dbb4d15835955892712b25d","placeholder":"​","style":"IPY_MODEL_bdaf3a41bf7048bd8c6a155d549759b4","value":" 665/665 [00:00&lt;00:00, 13.2kB/s]"}},"123883af342f42e3abc41fc6f9cc6e58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90e716662ec64aaa8db79a2c5b23c1d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"440479195a9745d182aa93e4c5372a78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"326977284c3347b8a91c8dcc710e1b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9753760d7cae4c89a2aa1fb487615cf4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"512f8a835dbb4d15835955892712b25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdaf3a41bf7048bd8c6a155d549759b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}